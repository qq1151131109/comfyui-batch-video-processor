"""
æ‰¹é‡è§†é¢‘å¤„ç†èŠ‚ç‚¹å®ç° - æ”¹è¿›ç‰ˆ
"""

import os
import tempfile
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import List
from typing_extensions import override
import torch
import av
import torchaudio
import numpy as np
from PIL import Image, ImageOps, ImageSequence
import node_helpers

import folder_paths
from comfy_api.input import VideoInput, AudioInput, ImageInput
from comfy_api.input_impl import VideoFromFile
from comfy_api.latest import ComfyExtension, io, ui

from .utils import (
    get_video_duration, get_video_info, scan_video_files, scan_media_files,
    create_batch_folder, create_output_folder, prepare_end_video,
    cut_single_segment_with_end, create_download_archive,
    clean_old_batches, format_file_size
)

# éŸ³é¢‘åŠ è½½è¾…åŠ©å‡½æ•°ï¼ˆä»ComfyUIçš„nodes_audio.pyå€Ÿç”¨ï¼‰
def f32_pcm(wav: torch.Tensor) -> torch.Tensor:
    """Convert audio to float 32 bits PCM format."""
    if wav.dtype.is_floating_point:
        return wav
    elif wav.dtype == torch.int16:
        return wav.float() / (2 ** 15)
    elif wav.dtype == torch.int32:
        return wav.float() / (2 ** 31)
    raise ValueError(f"Unsupported wav dtype: {wav.dtype}")

def load_audio(filepath: str) -> tuple[torch.Tensor, int]:
    """åŠ è½½éŸ³é¢‘æ–‡ä»¶å¹¶è¿”å›waveformå’Œsample_rate"""
    with av.open(filepath) as af:
        if not af.streams.audio:
            raise ValueError("No audio stream found in the file.")
        stream = af.streams.audio[0]
        sr = stream.codec_context.sample_rate
        n_channels = stream.channels
        frames = []
        length = 0
        for frame in af.decode(streams=stream.index):
            buf = torch.from_numpy(frame.to_ndarray())
            if buf.shape[0] != n_channels:
                buf = buf.view(-1, n_channels).t()
            frames.append(buf)
            length += buf.shape[1]
        if not frames:
            raise ValueError("No audio frames decoded.")
        wav = torch.cat(frames, dim=1)  # [C, T]
        wav = f32_pcm(wav)
        return wav, sr

def load_image(filepath: str) -> torch.Tensor:
    """åŠ è½½å›¾ç‰‡æ–‡ä»¶å¹¶è¿”å›torch tensor (ä»ComfyUIçš„LoadImageå€Ÿç”¨)"""
    img = node_helpers.pillow(Image.open, filepath)
    # åªå–ç¬¬ä¸€å¸§
    for i in ImageSequence.Iterator(img):
        i = node_helpers.pillow(ImageOps.exif_transpose, i)
        if i.mode == 'I':
            i = i.point(lambda i: i * (1 / 255))
        image = i.convert("RGB")
        image = np.array(image).astype(np.float32) / 255.0
        image = torch.from_numpy(image)[None,]  # [1, H, W, C]
        return image
    # å¦‚æœæ²¡æœ‰å›¾åƒï¼Œè¿”å›ç©ºå›¾åƒ
    return torch.zeros((1, 1, 1, 3), dtype=torch.float32)


class BatchVideoLoader(io.ComfyNode):
    """æ‰¹é‡ç´ æåŠ è½½å™¨ - æ”¯æŒè§†é¢‘ã€éŸ³é¢‘ã€å›¾åƒç­‰å¤šç§ç´ ææ‰¹é‡ä¸Šä¼ """
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="BatchVideoLoader",
            display_name="æ‰¹é‡ç´ æåŠ è½½å™¨",
            category="batch_video",
            description="æ‰¹é‡ä¸Šä¼ å’ŒåŠ è½½ç´ ææ–‡ä»¶ - æ”¯æŒè§†é¢‘ã€éŸ³é¢‘ã€å›¾åƒç­‰å¤šç§æ ¼å¼",
            inputs=[
                io.String.Input(
                    "input_folder_path", 
                    default="",
                    tooltip="æ–‡ä»¶å¤¹è·¯å¾„ - å¯ä»¥æ˜¯ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹äºinputç›®å½•çš„è·¯å¾„ï¼Œæˆ–ä½¿ç”¨ä¸Šä¼ æŒ‰é’®è‡ªåŠ¨å¤„ç†"
                ),
            ],
            outputs=[
                io.String.Output("output_folder_path", display_name="æ–‡ä»¶å¤¹è·¯å¾„"),
                io.Int.Output("file_count", display_name="æ–‡ä»¶æ•°é‡"),
                io.String.Output("file_list", display_name="æ–‡ä»¶åˆ—è¡¨"),
                io.String.Output("preview_file", display_name="é¢„è§ˆæ–‡ä»¶"),
                io.Video.Output("preview_video", display_name="è§†é¢‘é¢„è§ˆ"),
                io.Audio.Output("preview_audio", display_name="éŸ³é¢‘é¢„è§ˆ"),
                io.Image.Output("preview_image", display_name="å›¾ç‰‡é¢„è§ˆ"),
            ],
        )

    @classmethod
    def execute(cls, input_folder_path: str = "") -> io.NodeOutput:
        print(f"ğŸ¬ BatchVideoLoaderæ‰§è¡Œå¼€å§‹ï¼Œè¾“å…¥è·¯å¾„: '{input_folder_path}'")
        try:
            # ä¼˜å…ˆçº§1: æ‰‹åŠ¨æŒ‡å®šè·¯å¾„
            if input_folder_path and input_folder_path.strip():
                target_folder = input_folder_path.strip()
                
                # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äºinputç›®å½•
                if not os.path.isabs(target_folder):
                    input_dir = folder_paths.get_input_directory()
                    target_folder = os.path.join(input_dir, target_folder)
                
                source_type = "æ‰‹åŠ¨è·¯å¾„"
                
                # éªŒè¯è·¯å¾„å­˜åœ¨
                if not os.path.exists(target_folder):
                    file_list = f"""âŒ è·¯å¾„ä¸å­˜åœ¨

æŒ‡å®šè·¯å¾„: {target_folder}

è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæˆ–è€…ï¼š
1. ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼ˆå¦‚: /full/path/to/folderï¼‰
2. ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ˆå¦‚: subfolderï¼Œç›¸å¯¹äºinputç›®å½•ï¼‰
3. æˆ–è€…ä½¿ç”¨ä¸Šä¼ æŒ‰é’®ä¸Šä¼ æ–‡ä»¶"""
                    # åˆ›å»ºç©ºçš„åª’ä½“å¯¹è±¡
                    import io as python_io
                    empty_video = VideoFromFile(python_io.BytesIO(b''))
                    empty_audio = {"waveform": torch.zeros((1, 1, 1), dtype=torch.float32), "sample_rate": 44100}
                    empty_image = torch.zeros((1, 1, 1, 3), dtype=torch.float32)
                    return io.NodeOutput("", 0, file_list, "", empty_video, empty_audio, empty_image)
            
            # ä¼˜å…ˆçº§2: æŸ¥æ‰¾æœ€æ–°çš„ä¸Šä¼ ä¼šè¯
            else:
                input_dir = folder_paths.get_input_directory()
                batch_upload_dir = os.path.join(input_dir, "batch_uploads")
                
                # æŸ¥æ‰¾æœ€æ–°çš„ä¼šè¯æ–‡ä»¶å¤¹
                if os.path.exists(batch_upload_dir):
                    session_folders = [f for f in os.listdir(batch_upload_dir) 
                                     if os.path.isdir(os.path.join(batch_upload_dir, f))]
                    if session_folders:
                        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
                        session_folders.sort(key=lambda x: os.path.getmtime(os.path.join(batch_upload_dir, x)), reverse=True)
                        target_folder = os.path.join(batch_upload_dir, session_folders[0])
                        source_type = f"æœ€æ–°ä¸Šä¼ ä¼šè¯"
                    else:
                        return cls._return_waiting_status()
                else:
                    return cls._return_waiting_status()
                
                # éªŒè¯ä¼šè¯è·¯å¾„å­˜åœ¨
                if not os.path.exists(target_folder):
                    return cls._return_waiting_status()
            
            # æ‰«æç›®æ ‡æ–‡ä»¶å¤¹ä¸­çš„ç´ ææ–‡ä»¶ (è§†é¢‘+éŸ³é¢‘+å›¾åƒ)
            print(f"ğŸ“ å¼€å§‹æ‰«æç›®å½•: {target_folder}")
            media_result = scan_media_files(target_folder)
            media_files = []
            for file_type, files in media_result.items():
                media_files.extend(files)
            print(f"ğŸ“‹ æ‰¾åˆ° {len(media_files)} ä¸ªåª’ä½“æ–‡ä»¶: {[os.path.basename(f) for f in media_files[:5]]}")
            if len(media_files) > 5:
                print(f"    ... è¿˜æœ‰ {len(media_files) - 5} ä¸ªæ–‡ä»¶")
            
            if not media_files:
                file_list = f"""ğŸ“‚ æ–‡ä»¶å¤¹æ‰«æå®Œæˆ - æœªæ‰¾åˆ°åª’ä½“æ–‡ä»¶

æ‰«æè·¯å¾„: {target_folder}

æ”¯æŒçš„æ–‡ä»¶æ ¼å¼:
â€¢ è§†é¢‘: mp4, avi, mov, mkv, flv, wmv, m4v, webm
â€¢ éŸ³é¢‘: mp3, wav, aac, flac, ogg, m4a, wma  
â€¢ å›¾åƒ: jpg, jpeg, png, gif, bmp, tiff, webp"""
                
                # åˆ›å»ºç©ºçš„è§†é¢‘å¯¹è±¡  
                import io as python_io
                empty_video = VideoFromFile(python_io.BytesIO(b''))
                empty_audio = {"waveform": torch.zeros((1, 1, 1), dtype=torch.float32), "sample_rate": 44100}
                empty_image = torch.zeros((1, 1, 1, 3), dtype=torch.float32)
                return io.NodeOutput(target_folder, 0, file_list, "", empty_video, empty_audio, empty_image)
            
            # ç”Ÿæˆè¯¦ç»†çš„æ–‡ä»¶åˆ—è¡¨
            print(f"ğŸ“‹ æ‰¾åˆ° {len(media_files)} ä¸ªåª’ä½“æ–‡ä»¶")
            
            # æŒ‰ç±»å‹åˆ†ç»„æ–‡ä»¶
            file_types = {}
            for file_path in media_files:
                ext = os.path.splitext(file_path)[1].lower().lstrip('.')
                if ext in ['mp4', 'avi', 'mov', 'mkv', 'flv', 'wmv', 'm4v', 'webm']:
                    file_type = 'ğŸ¬ è§†é¢‘'
                elif ext in ['mp3', 'wav', 'aac', 'flac', 'ogg', 'm4a', 'wma']:
                    file_type = 'ğŸµ éŸ³é¢‘'
                elif ext in ['jpg', 'jpeg', 'png', 'gif', 'bmp', 'tiff', 'webp']:
                    file_type = 'ğŸ–¼ï¸ å›¾ç‰‡'
                else:
                    file_type = 'ğŸ“„ å…¶ä»–'
                
                if file_type not in file_types:
                    file_types[file_type] = []
                file_types[file_type].append(file_path)
            
            # ç”Ÿæˆè¯¦ç»†çš„æ–‡ä»¶åˆ—è¡¨
            file_list_parts = [
                f"âœ… æ‰¹é‡ç´ æåŠ è½½å®Œæˆ",
                f"",
                f"ğŸ“ æ–‡ä»¶å¤¹è·¯å¾„: {target_folder}",
                f"ğŸ“Š æ¥æºç±»å‹: {source_type}",
                f"ğŸ“‹ æ–‡ä»¶ç»Ÿè®¡: {len(media_files)} ä¸ªæ–‡ä»¶",
                f""
            ]
            
            # æŒ‰ç±»å‹æ˜¾ç¤ºæ–‡ä»¶
            for file_type, files in file_types.items():
                file_list_parts.append(f"{file_type} ({len(files)} ä¸ª):")
                for i, file_path in enumerate(files[:10]):  # æ¯ä¸ªç±»å‹æœ€å¤šæ˜¾ç¤º10ä¸ª
                    filename = os.path.basename(file_path)
                    file_size = os.path.getsize(file_path)
                    size_str = cls._format_file_size(file_size)
                    file_list_parts.append(f"  â€¢ {filename} ({size_str})")
                if len(files) > 10:
                    file_list_parts.append(f"  ... è¿˜æœ‰ {len(files) - 10} ä¸ªæ–‡ä»¶")
                file_list_parts.append("")
            
            # é¢„è§ˆç¬¬ä¸€ä¸ªæ–‡ä»¶å’Œå¤šåª’ä½“é¢„è§ˆ
            preview_file = media_files[0] if media_files else ""
            preview_video = None
            preview_audio = None  
            preview_image = None
            
            # æŸ¥æ‰¾å„ç±»å‹æ–‡ä»¶ç”¨äºé¢„è§ˆ
            for media_file in media_files:
                ext = os.path.splitext(media_file)[1].lower().lstrip('.')
                
                # è§†é¢‘é¢„è§ˆ
                if preview_video is None and ext in ['mp4', 'avi', 'mov', 'mkv', 'flv', 'wmv', 'm4v', 'webm']:
                    try:
                        preview_video = VideoFromFile(media_file)
                        print(f"ğŸ¬ è§†é¢‘é¢„è§ˆ: {os.path.basename(media_file)}")
                        file_list_parts.append(f"ğŸ¬ è§†é¢‘é¢„è§ˆ: {os.path.basename(media_file)}")
                    except Exception as e:
                        print(f"âš ï¸ è§†é¢‘é¢„è§ˆå¤±è´¥ {os.path.basename(media_file)}: {e}")
                
                # éŸ³é¢‘é¢„è§ˆ
                elif preview_audio is None and ext in ['mp3', 'wav', 'aac', 'flac', 'ogg', 'm4a', 'wma']:
                    try:
                        waveform, sample_rate = load_audio(media_file)
                        preview_audio = {"waveform": waveform.unsqueeze(0), "sample_rate": sample_rate}
                        print(f"ğŸµ éŸ³é¢‘é¢„è§ˆ: {os.path.basename(media_file)}")
                        file_list_parts.append(f"ğŸµ éŸ³é¢‘é¢„è§ˆ: {os.path.basename(media_file)}")
                    except Exception as e:
                        print(f"âš ï¸ éŸ³é¢‘é¢„è§ˆå¤±è´¥ {os.path.basename(media_file)}: {e}")
                
                # å›¾ç‰‡é¢„è§ˆ
                elif preview_image is None and ext in ['jpg', 'jpeg', 'png', 'gif', 'bmp', 'tiff', 'webp']:
                    try:
                        preview_image = load_image(media_file)
                        print(f"ğŸ–¼ï¸ å›¾ç‰‡é¢„è§ˆ: {os.path.basename(media_file)}")
                        file_list_parts.append(f"ğŸ–¼ï¸ å›¾ç‰‡é¢„è§ˆ: {os.path.basename(media_file)}")
                    except Exception as e:
                        print(f"âš ï¸ å›¾ç‰‡é¢„è§ˆå¤±è´¥ {os.path.basename(media_file)}: {e}")
            
            # ä¸ºæ²¡æœ‰æ‰¾åˆ°çš„åª’ä½“ç±»å‹åˆ›å»ºç©ºå¯¹è±¡
            if preview_video is None:
                import io as python_io
                preview_video = VideoFromFile(python_io.BytesIO(b''))
                
            if preview_audio is None:
                preview_audio = {"waveform": torch.zeros((1, 1, 1), dtype=torch.float32), "sample_rate": 44100}
                
            if preview_image is None:
                preview_image = torch.zeros((1, 1, 1, 3), dtype=torch.float32)
            
            if preview_file:
                preview_name = os.path.basename(preview_file)
                print(f"ğŸ” é¢„è§ˆæ–‡ä»¶: {preview_name}")
                file_list_parts.append(f"ğŸ” é¢„è§ˆæ–‡ä»¶: {preview_name}")
            
            file_list = "\n".join(file_list_parts)
            
            print(f"âœ… BatchVideoLoaderå®Œæˆ: {len(media_files)} ä¸ªæ–‡ä»¶ï¼Œé¢„è§ˆ: {os.path.basename(preview_file) if preview_file else 'æ— '}")
            
            return io.NodeOutput(target_folder, len(media_files), file_list, preview_file, preview_video, preview_audio, preview_image)
            
        except Exception as e:
            error_msg = f"âŒ æ‰¹é‡ç´ æåŠ è½½å¤±è´¥: {str(e)}"
            print(error_msg)
            # åˆ›å»ºç©ºçš„è§†é¢‘å¯¹è±¡
            import io as python_io
            error_video = VideoFromFile(python_io.BytesIO(b''))
            error_audio = {"waveform": torch.zeros((1, 1, 1), dtype=torch.float32), "sample_rate": 44100}
            error_image = torch.zeros((1, 1, 1, 3), dtype=torch.float32)
            return io.NodeOutput("", 0, error_msg, "", error_video, error_audio, error_image)
    
    @classmethod
    def _format_file_size(cls, size_bytes):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        elif size_bytes < 1024 * 1024 * 1024:
            return f"{size_bytes / (1024 * 1024):.1f} MB"
        else:
            return f"{size_bytes / (1024 * 1024 * 1024):.1f} GB"
    
    @classmethod
    def _return_waiting_status(cls):
        """è¿”å›ç­‰å¾…è¾“å…¥çŠ¶æ€"""
        file_list = """æ‰¹é‡ç´ æåŠ è½½å™¨ - å‡†å¤‡å°±ç»ª

ä½¿ç”¨æ–¹å¼:
1. ğŸ“ ç‚¹å‡»ã€Œé€‰æ‹©å¤šä¸ªç´ ææ–‡ä»¶ã€æˆ–ã€Œé€‰æ‹©ç´ ææ–‡ä»¶å¤¹ã€è‡ªåŠ¨ä¸Šä¼ 
2. ğŸ“ æˆ–åœ¨ã€Œinput_folder_pathã€ä¸­è¾“å…¥ç°æœ‰æ–‡ä»¶å¤¹è·¯å¾„

è‡ªåŠ¨ä¸Šä¼ è¯´æ˜:
â€¢ é€‰æ‹©æ–‡ä»¶åè‡ªåŠ¨ä¸Šä¼ åˆ° input/batch_uploads/ ç›®å½•
â€¢ ä¼šè‡ªåŠ¨åˆ›å»ºæ—¶é—´æˆ³ä¼šè¯æ–‡ä»¶å¤¹
â€¢ ä¸Šä¼ å®ŒæˆåèŠ‚ç‚¹è‡ªåŠ¨åŠ è½½æœ€æ–°ä¼šè¯

æ‰‹åŠ¨è·¯å¾„ç¤ºä¾‹:
â€¢ ç»å¯¹è·¯å¾„: /shenglin/comfyui-dingzhiban/input/1
â€¢ ç›¸å¯¹è·¯å¾„: 1 (ç›¸å¯¹äºinputç›®å½•)

æ”¯æŒæ ¼å¼:
â€¢ è§†é¢‘: mp4, avi, mov, mkv, flv, wmv, m4v, webm
â€¢ éŸ³é¢‘: mp3, wav, aac, flac, ogg, m4a, wma
â€¢ å›¾åƒ: jpg, jpeg, png, gif, bmp, tiff, webp"""
        
        # åˆ›å»ºç©ºçš„è§†é¢‘å¯¹è±¡
        import io as python_io
        empty_video = VideoFromFile(python_io.BytesIO(b''))
        empty_audio = {"waveform": torch.zeros((1, 1, 1), dtype=torch.float32), "sample_rate": 44100}
        empty_image = torch.zeros((1, 1, 1, 3), dtype=torch.float32)
        return io.NodeOutput("", 0, file_list, "", empty_video, empty_audio, empty_image)


class RandomVideoConcatenator(io.ComfyNode):
    """å®Œå…¨éšæœºè§†é¢‘æ‹¼æ¥å™¨ - ä»å¤šä¸ªæ–‡ä»¶å¤¹éšæœºé€‰æ‹©è§†é¢‘è¿›è¡Œæ‹¼æ¥"""
    
    @classmethod
    def define_schema(cls):
        # åˆ›å»º20ä¸ªæ–‡ä»¶å¤¹è¾“å…¥
        inputs = []
        for i in range(1, 21):
            optional = i > 2  # å‰ä¸¤ä¸ªå¿…å¡«ï¼Œå…¶ä»–å¯é€‰
            inputs.append(io.String.Input(f"folder{i}", optional=optional, tooltip=f"æ–‡ä»¶å¤¹{i}è·¯å¾„{'(å¯é€‰)' if optional else ''}"))
        
        inputs.extend([
            io.Int.Input(
                "output_count", 
                default=10, 
                min=1, 
                max=500,
                tooltip="è¾“å‡ºè§†é¢‘æ•°é‡"
            ),
            io.String.Input(
                "output_prefix", 
                default="éšæœºæ‹¼æ¥", 
                tooltip="è¾“å‡ºå‰ç¼€"
            ),
        ])
        
        return io.Schema(
            node_id="RandomVideoConcatenator",
            display_name="è§†é¢‘æ‹¼æ¥-å®Œå…¨éšæœº",
            category="batch_video", 
            description="ä»å¤šä¸ªæ–‡ä»¶å¤¹ä¸­å®Œå…¨éšæœºé€‰æ‹©è§†é¢‘è¿›è¡Œæ‹¼æ¥",
            inputs=inputs,
            outputs=[
                io.String.Output("output_folder", display_name="æ–‡ä»¶å¤¹è·¯å¾„"),
                io.Int.Output("video_count", display_name="ç”Ÿæˆæ•°é‡"),
                io.String.Output("summary", display_name="æ‹¼æ¥æ‘˜è¦"),
            ],
        )
    
    @classmethod
    def execute(cls, output_count: int = 10, output_prefix: str = "éšæœºæ‹¼æ¥", **kwargs) -> io.NodeOutput:
        import random
        import ffmpeg
        
        # æ”¶é›†æœ‰æ•ˆæ–‡ä»¶å¤¹
        folders = []
        for i in range(1, 21):
            folder_key = f"folder{i}"
            if folder_key in kwargs and kwargs[folder_key]:
                folders.append(kwargs[folder_key])
        
        if len(folders) < 2:
            error_msg = f"é”™è¯¯ï¼šè‡³å°‘éœ€è¦2ä¸ªæ–‡ä»¶å¤¹ï¼Œä½†åªæ”¶é›†åˆ°{len(folders)}ä¸ªæœ‰æ•ˆæ–‡ä»¶å¤¹"
            print(f"âŒ {error_msg}")
            return io.NodeOutput("", 0, error_msg)
        
        print(f"ğŸ“Š æ€»å…±æ”¶é›†åˆ° {len(folders)} ä¸ªæœ‰æ•ˆæ–‡ä»¶å¤¹")
        
        # éªŒè¯æ–‡ä»¶å¤¹å¹¶æ‰«æè§†é¢‘
        folder_videos = {}
        for i, folder in enumerate(folders):
            if not os.path.exists(folder):
                return io.NodeOutput("", 0, f"é”™è¯¯ï¼šæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder}")
            
            videos = scan_video_files(folder)
            if not videos:
                return io.NodeOutput("", 0, f"é”™è¯¯ï¼šæ–‡ä»¶å¤¹ä¸­æ²¡æœ‰è§†é¢‘æ–‡ä»¶: {folder}")
            
            folder_videos[i] = videos
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
        output_dir = folder_paths.get_output_directory()
        output_folder = create_output_folder(output_dir, output_prefix)
        
        print(f"å¼€å§‹å®Œå…¨éšæœºè§†é¢‘æ‹¼æ¥ï¼Œä½¿ç”¨{len(folders)}ä¸ªæ–‡ä»¶å¤¹")
        
        successful_count = 0
        
        # å®Œå…¨éšæœºæ¨¡å¼ï¼šæ¯æ¬¡ä»æ¯ä¸ªæ–‡ä»¶å¤¹éšæœºé€‰ä¸€ä¸ªè§†é¢‘
        for i in range(output_count):
            try:
                selected_videos = []
                for folder_idx in folder_videos:
                    selected_videos.append(random.choice(folder_videos[folder_idx]))
                
                output_filename = f"random_concat_{i+1:04d}.mp4"
                output_path = os.path.join(output_folder, output_filename)
                
                if cls._concatenate_videos(selected_videos, output_path):
                    successful_count += 1
                    print(f"âœ“ å®Œæˆéšæœºæ‹¼æ¥ {i+1}/{output_count}")
                
            except Exception as e:
                print(f"âœ— éšæœºæ‹¼æ¥å¤±è´¥ {i+1}: {e}")
        
        summary = f"""å®Œå…¨éšæœºè§†é¢‘æ‹¼æ¥å®Œæˆï¼
è¾“å‡ºæ–‡ä»¶å¤¹: {output_folder}
ä½¿ç”¨æ–‡ä»¶å¤¹æ•°: {len(folders)}
æˆåŠŸç”Ÿæˆ: {successful_count} ä¸ªè§†é¢‘
æ€»å…±å°è¯•: {output_count} æ¬¡"""
        
        return io.NodeOutput(output_folder, successful_count, summary)
    
    @staticmethod
    def _concatenate_videos(video_paths: List[str], output_path: str) -> bool:
        """æ‹¼æ¥å¤šä¸ªè§†é¢‘æ–‡ä»¶ - ä½¿ç”¨concat demuxeræ–¹æ³•"""
        try:
            import ffmpeg
            import tempfile
            import os
            
            if len(video_paths) < 2:
                return False
            
            # ä½¿ç”¨concat demuxeræ–¹æ³•ï¼Œåˆ›å»ºä¸´æ—¶æ–‡ä»¶åˆ—è¡¨
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                for video_path in video_paths:
                    f.write(f"file '{video_path}'\n")
                concat_file = f.name
            
            try:
                # ä½¿ç”¨concat demuxerè¿›è¡Œæ‹¼æ¥
                (
                    ffmpeg
                    .input(concat_file, format='concat', safe=0)
                    .output(output_path, c='copy')  # æµæ‹·è´ï¼Œä¸é‡ç¼–ç 
                    .overwrite_output()
                    .run(quiet=True)
                )
                
                return True
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(concat_file)
                except:
                    pass
            
        except ffmpeg.Error as e:
            print(f"æ‹¼æ¥è§†é¢‘å¤±è´¥ {output_path}: {e}")
            if e.stderr:
                try:
                    error_msg = e.stderr.decode('utf-8')
                    print(f"FFmpeg stderr: {error_msg}")
                except:
                    pass
            return False
        except Exception as e:
            print(f"æ‹¼æ¥è§†é¢‘å¤±è´¥ {output_path}: {e}")
            return False


class TraverseVideoConcatenator(io.ComfyNode):
    """éå†è§†é¢‘æ‹¼æ¥å™¨ - éå†æŸä¸ªæ–‡ä»¶å¤¹ï¼Œå…¶ä»–æ–‡ä»¶å¤¹éšæœºé€‰æ‹©"""
    
    @classmethod
    def define_schema(cls):
        # åˆ›å»º20ä¸ªæ–‡ä»¶å¤¹è¾“å…¥
        inputs = []
        for i in range(1, 21):
            optional = i > 2  # å‰ä¸¤ä¸ªå¿…å¡«ï¼Œå…¶ä»–å¯é€‰
            inputs.append(io.String.Input(f"folder{i}", optional=optional, tooltip=f"æ–‡ä»¶å¤¹{i}è·¯å¾„{'(å¯é€‰)' if optional else ''}"))
        
        inputs.extend([
            io.Int.Input(
                "traverse_folder_index", 
                default=1, 
                min=1, 
                max=20,
                tooltip="è¦éå†çš„æ–‡ä»¶å¤¹åºå·"
            ),
            io.String.Input(
                "output_prefix", 
                default="éå†æ‹¼æ¥", 
                tooltip="è¾“å‡ºå‰ç¼€"
            ),
        ])
        
        return io.Schema(
            node_id="TraverseVideoConcatenator",
            display_name="ğŸ² æ‰¹é‡è§†é¢‘æ‹¼æ¥å™¨",
            category="batch_video", 
            description="éå†æŒ‡å®šæ–‡ä»¶å¤¹çš„æ‰€æœ‰è§†é¢‘ï¼Œå…¶ä»–æ–‡ä»¶å¤¹éšæœºé€‰æ‹©è¿›è¡Œæ‹¼æ¥",
            inputs=inputs,
            outputs=[
                io.String.Output("output_folder", display_name="æ–‡ä»¶å¤¹è·¯å¾„"),
                io.Int.Output("video_count", display_name="ç”Ÿæˆæ•°é‡"),
                io.String.Output("summary", display_name="æ‹¼æ¥æ‘˜è¦"),
            ],
        )
    
    @classmethod
    def execute(cls, traverse_folder_index: int = 1, output_prefix: str = "éå†æ‹¼æ¥", **kwargs) -> io.NodeOutput:
        import random
        import ffmpeg
        
        print(f"ğŸ² TraverseVideoConcatenatoræ‰§è¡Œå¼€å§‹ï¼Œéå†åºå·: {traverse_folder_index}, è¾“å‡ºå‰ç¼€: '{output_prefix}'")
        
        # æ”¶é›†æœ‰æ•ˆæ–‡ä»¶å¤¹
        folders = []
        for i in range(1, 21):
            folder_key = f"folder{i}"
            if folder_key in kwargs and kwargs[folder_key]:
                folder_path = kwargs[folder_key]
                folders.append(folder_path)
                print(f"ğŸ“ æ”¶é›†åˆ°æ–‡ä»¶å¤¹{i}: {folder_path}")
        
        if len(folders) < 2:
            error_msg = f"é”™è¯¯ï¼šè‡³å°‘éœ€è¦2ä¸ªæ–‡ä»¶å¤¹ï¼Œä½†åªæ”¶é›†åˆ°{len(folders)}ä¸ªæœ‰æ•ˆæ–‡ä»¶å¤¹"
            print(f"âŒ {error_msg}")
            return io.NodeOutput("", 0, error_msg)
        
        if traverse_folder_index > len(folders):
            error_msg = f"é”™è¯¯ï¼šéå†æ–‡ä»¶å¤¹åºå·{traverse_folder_index}è¶…å‡ºèŒƒå›´(æœ€å¤§{len(folders)})"
            print(f"âŒ {error_msg}")
            return io.NodeOutput("", 0, error_msg)
        
        print(f"ğŸ“Š æ€»å…±æ”¶é›†åˆ° {len(folders)} ä¸ªæœ‰æ•ˆæ–‡ä»¶å¤¹")
        
        # éªŒè¯æ–‡ä»¶å¤¹å¹¶æ‰«æè§†é¢‘
        folder_videos = {}
        for i, folder in enumerate(folders):
            if not os.path.exists(folder):
                error_msg = f"é”™è¯¯ï¼šæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder}"
                print(f"âŒ {error_msg}")
                return io.NodeOutput("", 0, error_msg)
            
            videos = scan_video_files(folder)
            if not videos:
                error_msg = f"é”™è¯¯ï¼šæ–‡ä»¶å¤¹ä¸­æ²¡æœ‰è§†é¢‘æ–‡ä»¶: {folder}"
                print(f"âŒ {error_msg}")
                return io.NodeOutput("", 0, error_msg)
            
            print(f"ğŸ“¹ æ–‡ä»¶å¤¹{i+1} ({folder}) æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘æ–‡ä»¶")
            folder_videos[i] = videos
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
        output_dir = folder_paths.get_output_directory()
        output_folder = create_output_folder(output_dir, output_prefix)
        
        print(f"å¼€å§‹éå†è§†é¢‘æ‹¼æ¥ï¼Œéå†æ–‡ä»¶å¤¹{traverse_folder_index}ï¼Œä½¿ç”¨{len(folders)}ä¸ªæ–‡ä»¶å¤¹")
        
        successful_count = 0
        
        # éå†+éšæœºæ¨¡å¼ï¼šéå†æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œå…¶ä»–æ–‡ä»¶å¤¹éšæœºé€‰æ‹©
        traverse_videos = folder_videos[traverse_folder_index - 1]  # è½¬æ¢ä¸º0ç´¢å¼•
        other_folders = {k: v for k, v in folder_videos.items() if k != traverse_folder_index - 1}
        
        for i, traverse_video in enumerate(traverse_videos):
            try:
                selected_videos = [traverse_video]
                
                # ä»å…¶ä»–æ–‡ä»¶å¤¹éšæœºé€‰æ‹©
                for folder_idx in sorted(other_folders.keys()):
                    selected_videos.append(random.choice(other_folders[folder_idx]))
                
                output_filename = f"traverse_concat_{i+1:04d}.mp4"
                output_path = os.path.join(output_folder, output_filename)
                
                if cls._concatenate_videos(selected_videos, output_path):
                    successful_count += 1
                    print(f"âœ“ å®Œæˆéå†æ‹¼æ¥ {i+1}/{len(traverse_videos)}")
                
            except Exception as e:
                print(f"âœ— éå†æ‹¼æ¥å¤±è´¥ {i+1}: {e}")
        
        summary = f"""éå†è§†é¢‘æ‹¼æ¥å®Œæˆï¼
è¾“å‡ºæ–‡ä»¶å¤¹: {output_folder}
éå†æ–‡ä»¶å¤¹: {traverse_folder_index} (å…±{len(traverse_videos)}ä¸ªè§†é¢‘)
ä½¿ç”¨æ–‡ä»¶å¤¹æ•°: {len(folders)}
æˆåŠŸç”Ÿæˆ: {successful_count} ä¸ªè§†é¢‘"""
        
        return io.NodeOutput(output_folder, successful_count, summary)
    
    @staticmethod
    def _concatenate_videos(video_paths: List[str], output_path: str) -> bool:
        """æ‹¼æ¥å¤šä¸ªè§†é¢‘æ–‡ä»¶ - ä½¿ç”¨concat demuxeræ–¹æ³•"""
        try:
            import ffmpeg
            import tempfile
            import os
            
            if len(video_paths) < 2:
                return False
            
            # ä½¿ç”¨concat demuxeræ–¹æ³•ï¼Œåˆ›å»ºä¸´æ—¶æ–‡ä»¶åˆ—è¡¨
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                for video_path in video_paths:
                    f.write(f"file '{video_path}'\n")
                concat_file = f.name
            
            try:
                # ä½¿ç”¨concat demuxerè¿›è¡Œæ‹¼æ¥
                (
                    ffmpeg
                    .input(concat_file, format='concat', safe=0)
                    .output(output_path, c='copy')  # æµæ‹·è´ï¼Œä¸é‡ç¼–ç 
                    .overwrite_output()
                    .run(quiet=True)
                )
                
                return True
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(concat_file)
                except:
                    pass
            
        except ffmpeg.Error as e:
            print(f"æ‹¼æ¥è§†é¢‘å¤±è´¥ {output_path}: {e}")
            if e.stderr:
                try:
                    error_msg = e.stderr.decode('utf-8')
                    print(f"FFmpeg stderr: {error_msg}")
                except:
                    pass
            return False
        except Exception as e:
            print(f"æ‹¼æ¥è§†é¢‘å¤±è´¥ {output_path}: {e}")
            return False



class BatchVideoCutter(io.ComfyNode):
    """æ‰¹é‡è§†é¢‘åˆ‡åˆ†å™¨ - ç®€åŒ–ç‰ˆ"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="BatchVideoCutter",
            display_name="æ‰¹é‡åˆ‡åˆ†è§†é¢‘",
            category="batch_video",
            description="æ‰¹é‡åˆ‡åˆ†è§†é¢‘æ–‡ä»¶",
            inputs=[
                io.String.Input(
                    "input_folder", 
                    tooltip="è¾“å…¥è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„"
                ),
                io.Float.Input(
                    "cut_duration", 
                    default=30.0, 
                    min=1.0, 
                    max=300.0,
                    step=0.5,
                    tooltip="æ¯æ®µæ—¶é•¿(ç§’)"
                ),
                io.String.Input(
                    "output_prefix", 
                    default="å·²å¤„ç†", 
                    tooltip="è¾“å‡ºå‰ç¼€"
                ),
            ],
            outputs=[
                io.String.Output("output_folder", display_name="æ–‡ä»¶å¤¹è·¯å¾„"),
                io.Int.Output("total_segments", display_name="æ€»ç‰‡æ®µæ•°"),
                io.String.Output("summary", display_name="å¤„ç†æ‘˜è¦"),
            ],
        )

    @classmethod
    def execute(cls, input_folder: str, cut_duration: float, output_prefix: str) -> io.NodeOutput:
        print(f"âœ‚ï¸ BatchVideoCutteræ‰§è¡Œå¼€å§‹ï¼Œè¾“å…¥æ–‡ä»¶å¤¹: '{input_folder}', åˆ‡åˆ†æ—¶é•¿: {cut_duration}ç§’")
        
        # è·å–è¾“å‡ºç›®å½•
        output_dir = folder_paths.get_output_directory()
        output_folder = create_output_folder(output_dir, output_prefix)
        
        # æ‰«æè¾“å…¥æ–‡ä»¶å¤¹
        if not os.path.exists(input_folder):
            return io.NodeOutput(output_folder, 0, f"é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨")
        
        # åªæ‰«æè§†é¢‘æ–‡ä»¶ (BatchVideoCutteråªèƒ½å¤„ç†è§†é¢‘)
        media_result = scan_media_files(input_folder)
        video_files = media_result.get('video', [])
        
        if not video_files:
            return io.NodeOutput(output_folder, 0, f"æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
        
        print(f"æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶å¼€å§‹å¤„ç†")
        for i, video_file in enumerate(video_files, 1):
            filename = os.path.basename(video_file)
            print(f"  {i}. {filename}")
        
        total_segments = 0
        processed_videos = 0
        
        # ç®€åŒ–å¤„ç†ï¼šå•çº¿ç¨‹ï¼ŒåŸºæœ¬åˆ‡åˆ†
        for i, video_file in enumerate(video_files, 1):
            filename = os.path.basename(video_file)
            print(f"ğŸ”„ æ­£åœ¨å¤„ç† ({i}/{len(video_files)}): {filename}")
            
            try:
                segments_count = cls._process_single_video_simple(
                    video_file, cut_duration, output_folder
                )
                if segments_count > 0:
                    total_segments += segments_count
                    processed_videos += 1
                    print(f"âœ“ å®Œæˆ: {filename} â†’ {segments_count} ä¸ªç‰‡æ®µ")
                else:
                    print(f"âš ï¸ è·³è¿‡: {filename} (æ—¶é•¿ä¸è¶³æˆ–å¤„ç†å¤±è´¥)")
            except Exception as e:
                print(f"âœ— å¤±è´¥: {filename} - é”™è¯¯: {str(e)}")
                import traceback
                print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        
        summary = f"""å¤„ç†å®Œæˆï¼
è¾“å‡º: {output_folder}
å¤„ç†: {processed_videos}/{len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶
æ€»æ®µæ•°: {total_segments}
æ—¶é•¿: {cut_duration}ç§’/æ®µ"""
        
        return io.NodeOutput(output_folder, total_segments, summary)
    
    @staticmethod
    def _process_single_video_simple(video_path: str, cut_duration: float, output_folder: str) -> int:
        """ç®€åŒ–çš„å•è§†é¢‘å¤„ç†"""
        video_name = Path(video_path).stem
        filename = os.path.basename(video_path)
        
        print(f"    ğŸ“¹ è·å–è§†é¢‘ä¿¡æ¯: {filename}")
        video_duration = get_video_duration(video_path)
        print(f"    â±ï¸ è§†é¢‘æ—¶é•¿: {video_duration:.2f} ç§’")
        
        if video_duration < cut_duration:
            print(f"    âš ï¸ è§†é¢‘æ—¶é•¿({video_duration:.2f}s) < åˆ‡åˆ†æ—¶é•¿({cut_duration}s)ï¼Œè·³è¿‡")
            return 0
        
        num_segments = int(video_duration // cut_duration)
        if num_segments == 0:
            print(f"    âš ï¸ æ— æ³•ç”Ÿæˆç‰‡æ®µï¼Œè·³è¿‡")
            return 0
        
        print(f"    ğŸ“Š è®¡åˆ’ç”Ÿæˆ {num_segments} ä¸ªç‰‡æ®µï¼Œæ¯æ®µ {cut_duration} ç§’")
        
        # ç›´æ¥ä½¿ç”¨çˆ¶ç›®å½•ä½œä¸ºè¾“å‡ºç›®å½•ï¼Œæ–‡ä»¶åæ·»åŠ è§†é¢‘åå‰ç¼€
        video_output_dir = output_folder
        print(f"    ğŸ“ è¾“å‡ºç›®å½•: {video_output_dir}")
        
        segments_created = 0
        
        # ç®€å•åˆ‡åˆ†ï¼ˆä¸æ·»åŠ ç»“å°¾è§†é¢‘ï¼‰
        import ffmpeg
        for i in range(num_segments):
            start_time = i * cut_duration
            end_time = (i + 1) * cut_duration
            
            if end_time > video_duration:
                end_time = video_duration
            
            segment_duration = end_time - start_time
            # ä½¿ç”¨è§†é¢‘åç§°ä½œä¸ºå‰ç¼€ï¼Œé¿å…æ–‡ä»¶åå†²çª
            output_filename = f"{video_name}_segment_{i+1:03d}.mp4"
            output_path = os.path.join(video_output_dir, output_filename)
            
            print(f"    ğŸ”„ åˆ‡åˆ†ç‰‡æ®µ {i+1}/{num_segments}: {start_time:.1f}s - {end_time:.1f}s ({segment_duration:.1f}s)")
            
            try:
                (
                    ffmpeg
                    .input(video_path, ss=start_time, t=segment_duration)
                    .output(output_path, vcodec='libx264', acodec='aac')
                    .overwrite_output()
                    .run(quiet=True)
                )
                
                # éªŒè¯è¾“å‡ºæ–‡ä»¶
                if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                    segments_created += 1
                    output_size = os.path.getsize(output_path)
                    print(f"    âœ“ ç‰‡æ®µ {i+1} å®Œæˆ: {output_filename} ({output_size} bytes)")
                else:
                    print(f"    âŒ ç‰‡æ®µ {i+1} ç”Ÿæˆå¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º")
                    
            except Exception as e:
                print(f"    âŒ åˆ‡åˆ†å¤±è´¥ {output_filename}: {str(e)}")
        
        print(f"    ğŸ“‹ {filename} å¤„ç†å®Œæˆ: {segments_created}/{num_segments} ä¸ªç‰‡æ®µæˆåŠŸ")
        return segments_created


class VideoStaticCleaner(io.ComfyNode):
    """è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨ - è‡ªåŠ¨æ£€æµ‹å¹¶ç§»é™¤å¡å¸§å’Œé™æ­¢ç‰‡æ®µ"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="VideoStaticCleaner",
            display_name="âš¡ å¡é¡¿ä¿®å¤å™¨",
            category="batch_video",
            description="è‡ªåŠ¨æ£€æµ‹å¹¶ç§»é™¤è§†é¢‘ä¸­çš„å¡å¸§ã€é™æ­¢ç‰‡æ®µï¼Œæå‡è§†é¢‘æµç•…åº¦",
            inputs=[
                io.String.Input("video_folder", tooltip="è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„"),
                io.Float.Input("static_threshold", default=0.02, tooltip="é™æ­¢åˆ¤å®šé˜ˆå€¼(0-1ï¼Œè¶Šå°è¶Šæ•æ„Ÿ)"),
                io.Int.Input("min_static_duration", default=3, tooltip="æœ€å°é™æ­¢æ—¶é•¿(ç§’)"),
                io.Boolean.Input("enable_preview", default=True, tooltip="ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"),
                io.String.Input("output_prefix", default="æ¸…ç†ç‰ˆ", tooltip="è¾“å‡ºå‰ç¼€"),
            ],
            outputs=[
                io.String.Output("output_folder", display_name="è¾“å‡ºæ–‡ä»¶å¤¹"),
                io.Int.Output("processed_count", display_name="å¤„ç†æ•°é‡"),
                io.String.Output("cleaning_report", display_name="æ¸…ç†æŠ¥å‘Š"),
            ],
        )
    
    @classmethod
    def execute(cls, video_folder, static_threshold=0.02, min_static_duration=3, 
                enable_preview=True, output_prefix="æ¸…ç†ç‰ˆ"):
        import os
        import time
        import json
        from pathlib import Path
        
        try:
            # éªŒè¯è¾“å…¥æ–‡ä»¶å¤¹
            if not os.path.exists(video_folder):
                raise ValueError(f"è§†é¢‘æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {video_folder}")
            
            # æ‰«æè§†é¢‘æ–‡ä»¶
            video_files = []
            for ext in ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm', '.m4v']:
                pattern = os.path.join(video_folder, f"*{ext}")
                import glob
                video_files.extend(glob.glob(pattern))
                video_files.extend(glob.glob(pattern.upper()))
            
            if not video_files:
                raise ValueError(f"åœ¨æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {video_folder}")
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
            timestamp = int(time.time())
            output_folder = os.path.join(folder_paths.get_temp_directory(), f"{output_prefix}_é™æ­¢æ¸…ç†_{timestamp}")
            os.makedirs(output_folder, exist_ok=True)
            
            processed_count = 0
            failed_files = []
            cleaning_stats = []
            
            print(f"[è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨] å¼€å§‹å¤„ç† {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
            print(f"[è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨] é™æ­¢é˜ˆå€¼: {static_threshold}, æœ€å°æ—¶é•¿: {min_static_duration}ç§’")
            
            for video_file in video_files:
                try:
                    video_name = Path(video_file).stem
                    output_filename = f"{video_name}_{output_prefix}.mp4"
                    output_path = os.path.join(output_folder, output_filename)
                    
                    print(f"[è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨] å¤„ç†: {video_name}")
                    
                    # æ£€æµ‹é™æ­¢ç‰‡æ®µ
                    static_segments = cls._detect_static_segments(
                        video_file, static_threshold, min_static_duration
                    )
                    
                    if static_segments:
                        print(f"[è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨] {video_name}: å‘ç° {len(static_segments)} ä¸ªé™æ­¢ç‰‡æ®µ")
                        
                        # ç§»é™¤é™æ­¢ç‰‡æ®µå¹¶å¯¼å‡º
                        success = cls._export_video_without_segments(video_file, static_segments, output_path)
                        
                        if success:
                            # è®¡ç®—æ¸…ç†ç»Ÿè®¡
                            total_removed = sum(end - start for start, end in static_segments)
                            original_duration = cls._get_video_duration(video_file)
                            cleaned_duration = original_duration - total_removed if original_duration else 0
                            
                            cleaning_stats.append({
                                "file": video_name,
                                "original_duration": round(original_duration, 2),
                                "cleaned_duration": round(cleaned_duration, 2),
                                "removed_duration": round(total_removed, 2),
                                "static_segments": len(static_segments),
                                "compression_ratio": round((1 - total_removed / original_duration) * 100, 1) if original_duration > 0 else 0
                            })
                            
                            processed_count += 1
                            print(f"[è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨] å®Œæˆ: {output_filename} (ç§»é™¤ {total_removed:.1f}ç§’)")
                        else:
                            failed_files.append(video_name)
                            print(f"[è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨] å¯¼å‡ºå¤±è´¥: {video_name}")
                    else:
                        # æ²¡æœ‰é™æ­¢ç‰‡æ®µï¼Œç›´æ¥å¤åˆ¶
                        print(f"[è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨] {video_name}: æœªå‘ç°é™æ­¢ç‰‡æ®µï¼Œç›´æ¥å¤åˆ¶")
                        import shutil
                        shutil.copy2(video_file, output_path)
                        
                        original_duration = cls._get_video_duration(video_file)
                        cleaning_stats.append({
                            "file": video_name,
                            "original_duration": round(original_duration, 2),
                            "cleaned_duration": round(original_duration, 2),
                            "removed_duration": 0,
                            "static_segments": 0,
                            "compression_ratio": 100.0
                        })
                        processed_count += 1
                        
                except Exception as e:
                    failed_files.append(video_name)
                    print(f"[è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨] å¤„ç†å¤±è´¥: {video_name}, é”™è¯¯: {str(e)}")
            
            # ç”Ÿæˆæ¸…ç†æŠ¥å‘Š
            report = cls._generate_cleaning_report(cleaning_stats, failed_files, enable_preview)
            
            # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
            if enable_preview:
                report_path = os.path.join(output_folder, "cleaning_report.json")
                with open(report_path, 'w', encoding='utf-8') as f:
                    json.dump({
                        "summary": report,
                        "details": cleaning_stats,
                        "failed_files": failed_files
                    }, f, ensure_ascii=False, indent=2)
            
            print(f"[è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨] å¤„ç†å®Œæˆ: æˆåŠŸ {processed_count}/{len(video_files)} ä¸ªæ–‡ä»¶")
            
            return io.NodeOutput(output_folder, processed_count, report)
            
        except Exception as e:
            error_msg = f"è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨æ‰§è¡Œå¤±è´¥: {str(e)}"
            print(f"[è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨] é”™è¯¯: {error_msg}")
            # åˆ›å»ºç©ºçš„è§†é¢‘å¯¹è±¡
            import io as python_io
            error_video = VideoFromFile(python_io.BytesIO(b''))
            return io.NodeOutput("", 0, error_msg, "", error_video)
    
    @classmethod
    def _detect_static_segments(cls, video_path, threshold=0.02, min_duration=3.0):
        """æ£€æµ‹é™æ­¢ç‰‡æ®µ - åŸºäºæ„ŸçŸ¥å“ˆå¸Œ"""
        try:
            import cv2
            import imagehash
            from PIL import Image
            
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                return []
            
            # è·å–è§†é¢‘ä¿¡æ¯
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
            duration = frame_count / fps if fps > 0 else 0
            
            if duration == 0:
                cap.release()
                return []
            
            # é‡‡æ ·é—´éš”ï¼ˆæ¯ç§’é‡‡æ ·ï¼‰
            sample_interval = 1.0
            prev_hash = None
            static_start = None
            static_segments = []
            
            sample_time = 0.0
            while sample_time < duration:
                # è·³è½¬åˆ°æŒ‡å®šæ—¶é—´ç‚¹
                cap.set(cv2.CAP_PROP_POS_MSEC, sample_time * 1000)
                ret, frame = cap.read()
                if not ret:
                    break
                
                # è®¡ç®—æ„ŸçŸ¥å“ˆå¸Œ
                cur_hash = cls._phash_frame_hd(frame)
                
                if prev_hash is not None:
                    # è®¡ç®—å½’ä¸€åŒ–æ±‰æ˜è·ç¦»
                    distance = (prev_hash - cur_hash) / float(cur_hash.hash.size)
                    
                    if distance <= threshold:  # é™æ­¢
                        if static_start is None:
                            static_start = sample_time
                    else:  # æœ‰å˜åŒ–
                        if static_start is not None:
                            static_duration = sample_time - static_start
                            if static_duration >= min_duration:
                                static_segments.append((static_start, sample_time))
                        static_start = None
                
                prev_hash = cur_hash
                sample_time += sample_interval
            
            # å¤„ç†è§†é¢‘ç»“å°¾çš„é™æ­¢ç‰‡æ®µ
            if static_start is not None:
                if duration - static_start >= min_duration:
                    static_segments.append((static_start, duration))
            
            cap.release()
            return static_segments
            
        except Exception as e:
            print(f"[è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨] é™æ­¢ç‰‡æ®µæ£€æµ‹å¤±è´¥: {str(e)}")
            return []
    
    @classmethod
    def _phash_frame_hd(cls, frame):
        """é«˜ç²¾åº¦æ„ŸçŸ¥å“ˆå¸Œ"""
        try:
            import cv2
            import imagehash
            from PIL import Image
            
            # è½¬ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # CLAHEå¢å¼ºå¯¹æ¯”åº¦
            gray_single = cv2.cvtColor(gray, cv2.COLOR_RGB2GRAY)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            eq = clahe.apply(gray_single)
            
            # Unsharp maské”åŒ–
            blur = cv2.GaussianBlur(eq, (3, 3), 0)
            sharp = cv2.addWeighted(eq, 1.5, blur, -0.5, 0)
            
            # è½¬ä¸ºPILå›¾åƒå¹¶è®¡ç®—å“ˆå¸Œ
            pil_img = Image.fromarray(sharp)
            return imagehash.phash(pil_img, hash_size=16, highfreq_factor=8)
            
        except Exception as e:
            print(f"[è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨] å“ˆå¸Œè®¡ç®—å¤±è´¥: {str(e)}")
            # é™çº§åˆ°ç®€å•å“ˆå¸Œ
            try:
                pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                return imagehash.phash(pil_img)
            except:
                return None
    
    @classmethod
    def _export_video_without_segments(cls, video_path, segments, output_path):
        """ä½¿ç”¨FFmpegç§»é™¤é™æ­¢ç‰‡æ®µ"""
        try:
            import ffmpeg
            
            # è·å–è§†é¢‘æ—¶é•¿
            duration = cls._get_video_duration(video_path)
            if duration is None:
                return False
            
            # è®¡ç®—ä¿ç•™çš„æ—¶é—´æ®µ
            keep_ranges = cls._invert_segments(segments, duration)
            if not keep_ranges:
                return False
            
            # æ„é€ selectè¡¨è¾¾å¼
            expr = '+'.join([f'between(t,{s},{e})' for s, e in keep_ranges])
            
            # æ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘æµ
            has_audio = cls._has_audio_stream(video_path)
            
            inp = ffmpeg.input(video_path)
            
            # è§†é¢‘æµå¤„ç†
            v = inp.video.filter('select', expr).filter('setpts', 'N/FRAME_RATE/TB')
            
            if has_audio:
                # éŸ³é¢‘æµå¤„ç†
                a = inp.audio.filter('aselect', expr).filter('asetpts', 'N/SR/TB')
                out = ffmpeg.output(
                    v, a, output_path,
                    vcodec='libx264', acodec='aac', 
                    preset='fast',
                    **{'b:v': '2000k', 'b:a': '128k'}
                )
            else:
                out = ffmpeg.output(
                    v, output_path,
                    vcodec='libx264', 
                    preset='fast',
                    **{'b:v': '2000k'}
                )
            
            out = out.overwrite_output()
            out.run(quiet=True)
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            return os.path.exists(output_path) and os.path.getsize(output_path) > 0
            
        except Exception as e:
            print(f"[è§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨] FFmpegå¤„ç†å¤±è´¥: {str(e)}")
            return False
    
    @classmethod
    def _get_video_duration(cls, video_path):
        """è·å–è§†é¢‘æ—¶é•¿"""
        try:
            import ffmpeg
            probe = ffmpeg.probe(video_path)
            return float(probe['format']['duration'])
        except:
            return None
    
    @classmethod
    def _has_audio_stream(cls, video_path):
        """æ£€æŸ¥è§†é¢‘æ˜¯å¦æœ‰éŸ³é¢‘æµ"""
        try:
            import ffmpeg
            probe = ffmpeg.probe(video_path)
            for stream in probe.get('streams', []):
                if stream.get('codec_type') == 'audio':
                    return True
            return False
        except:
            return False
    
    @classmethod
    def _invert_segments(cls, segments, duration):
        """å°†éœ€è¦ç§»é™¤çš„æ—¶é—´æ®µè½¬æ¢ä¸ºéœ€è¦ä¿ç•™çš„æ—¶é—´æ®µ"""
        if not segments:
            return [(0.0, duration)]
        
        segments = sorted(segments, key=lambda x: x[0])
        keep = []
        prev = 0.0
        
        for start, end in segments:
            start = max(0.0, start)
            end = min(duration, end)
            if start > prev:
                keep.append((prev, start))
            prev = max(prev, end)
        
        if prev < duration:
            keep.append((prev, duration))
        
        return [(round(s, 3), round(e, 3)) for s, e in keep if e - s > 0.1]
    
    @classmethod
    def _generate_cleaning_report(cls, stats, failed_files, enable_preview):
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        if not stats and not failed_files:
            return "æœªå¤„ç†ä»»ä½•æ–‡ä»¶"
        
        total_files = len(stats) + len(failed_files)
        successful_files = len(stats)
        
        if successful_files > 0:
            total_original = sum(s['original_duration'] for s in stats)
            total_removed = sum(s['removed_duration'] for s in stats)
            avg_compression = sum(s['compression_ratio'] for s in stats) / successful_files
            
            report = f"""é™æ­¢ç‰‡æ®µæ¸…ç†å®ŒæˆæŠ¥å‘Šï¼š
âœ… æˆåŠŸå¤„ç†: {successful_files}/{total_files} ä¸ªæ–‡ä»¶
ğŸ“Š æ—¶é•¿ç»Ÿè®¡: åŸå§‹ {total_original:.1f}ç§’ â†’ æ¸…ç†å {total_original-total_removed:.1f}ç§’
ğŸ—‘ï¸  ç§»é™¤æ—¶é•¿: {total_removed:.1f}ç§’ ({(total_removed/total_original*100):.1f}%)
ğŸ“ˆ å¹³å‡å‹ç¼©ç‡: {avg_compression:.1f}%"""
            
            if failed_files:
                report += f"\nâŒ å¤±è´¥æ–‡ä»¶: {len(failed_files)} ä¸ª"
        else:
            report = f"å¤„ç†å¤±è´¥: {len(failed_files)} ä¸ªæ–‡ä»¶æœªèƒ½æˆåŠŸå¤„ç†"
        
        return report


class GameHighlightExtractor(io.ComfyNode):
    """æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨ - åŸºäºæ¨¡æ¿åŒ¹é…è‡ªåŠ¨è¯†åˆ«æ¸¸æˆå±€æ¬¡"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="GameHighlightExtractor",
            display_name="ğŸ† æ¸¸æˆé«˜å…‰æå–å™¨",
            category="batch_video",
            description="åŸºäºæ¨¡æ¿åŒ¹é…å’ŒOCRè¯†åˆ«æ¸¸æˆå¼€å§‹/ç»“æŸï¼Œè‡ªåŠ¨æå–å®Œæ•´æ¸¸æˆå±€æ¬¡",
            inputs=[
                io.String.Input("video_folder", tooltip="è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„"),
                io.Image.Input("start_template", optional=True, tooltip="å¼€å§‹æ¨¡æ¿å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰"),
                io.Image.Input("end_template", optional=True, tooltip="ç»“æŸæ¨¡æ¿å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰"),
                io.String.Input("start_keywords", default="å¼€å§‹,start,å‡†å¤‡,ready,å€’è®¡æ—¶", tooltip="å¼€å§‹å…³é”®è¯ï¼ˆé€—å·åˆ†éš”ï¼‰"),
                io.String.Input("end_keywords", default="ç»“æŸ,game over,èƒœåˆ©,victory,å†æ¥ä¸€å±€", tooltip="ç»“æŸå…³é”®è¯ï¼ˆé€—å·åˆ†éš”ï¼‰"),
                io.Float.Input("template_threshold", default=0.8, tooltip="æ¨¡æ¿åŒ¹é…é˜ˆå€¼(0-1)"),
                io.Float.Input("ocr_confidence", default=0.7, tooltip="OCRè¯†åˆ«ç½®ä¿¡åº¦(0-1)"),
                io.Int.Input("start_offset", default=0, tooltip="å¼€å§‹å¸§åå»¶è¿Ÿç§’æ•°"),
                io.Int.Input("end_offset", default=0, tooltip="ç»“æŸå¸§åå»¶è¿Ÿç§’æ•°"),
                io.Int.Input("min_game_duration", default=10, tooltip="æœ€å°æ¸¸æˆæ—¶é•¿(ç§’)"),
                io.Int.Input("max_game_duration", default=300, tooltip="æœ€å¤§æ¸¸æˆæ—¶é•¿(ç§’)"),
                io.Boolean.Input("enable_ocr", default=True, tooltip="å¯ç”¨OCRæ–‡å­—è¯†åˆ«"),
                io.String.Input("output_prefix", default="æ¸¸æˆå±€æ¬¡", tooltip="è¾“å‡ºå‰ç¼€"),
            ],
            outputs=[
                io.String.Output("output_folder", display_name="è¾“å‡ºæ–‡ä»¶å¤¹"),
                io.Int.Output("total_sessions", display_name="æ¸¸æˆå±€æ¬¡æ€»æ•°"),
                io.String.Output("extraction_report", display_name="æå–æŠ¥å‘Š"),
            ],
        )
    
    @classmethod
    def execute(cls, video_folder, start_template=None, end_template=None,
                start_keywords="å¼€å§‹,start,å‡†å¤‡,ready,å€’è®¡æ—¶", end_keywords="ç»“æŸ,game over,èƒœåˆ©,victory,å†æ¥ä¸€å±€",
                template_threshold=0.8, ocr_confidence=0.7, start_offset=0, end_offset=0,
                min_game_duration=10, max_game_duration=300, enable_ocr=True, output_prefix="æ¸¸æˆå±€æ¬¡"):
        
        import os
        import time
        import json
        from pathlib import Path
        
        try:
            # éªŒè¯è¾“å…¥æ–‡ä»¶å¤¹
            if not os.path.exists(video_folder):
                raise ValueError(f"è§†é¢‘æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {video_folder}")
            
            # æ‰«æè§†é¢‘æ–‡ä»¶
            video_files = []
            for ext in ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm', '.m4v']:
                pattern = os.path.join(video_folder, f"*{ext}")
                import glob
                video_files.extend(glob.glob(pattern))
                video_files.extend(glob.glob(pattern.upper()))
            
            if not video_files:
                raise ValueError(f"åœ¨æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {video_folder}")
            
            # å¤„ç†æ¨¡æ¿å›¾ç‰‡
            start_template_cv = cls._convert_image_to_cv(start_template) if start_template is not None else None
            end_template_cv = cls._convert_image_to_cv(end_template) if end_template is not None else None
            
            # å¤„ç†å…³é”®è¯
            start_words = [w.strip().lower() for w in start_keywords.split(',') if w.strip()]
            end_words = [w.strip().lower() for w in end_keywords.split(',') if w.strip()]
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
            timestamp = int(time.time())
            output_folder = os.path.join(folder_paths.get_temp_directory(), f"{output_prefix}_æå–_{timestamp}")
            os.makedirs(output_folder, exist_ok=True)
            
            total_sessions = 0
            extraction_stats = []
            
            print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] å¼€å§‹å¤„ç† {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
            print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] æ¨¡æ¿: å¼€å§‹{'æœ‰' if start_template_cv is not None else 'æ— '}, ç»“æŸ{'æœ‰' if end_template_cv is not None else 'æ— '}")
            print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] åç§»: å¼€å§‹+{start_offset}ç§’, ç»“æŸ+{end_offset}ç§’")
            
            for video_file in video_files:
                try:
                    video_name = Path(video_file).stem
                    print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] å¤„ç†è§†é¢‘: {video_name}")
                    
                    # æ£€æµ‹æ¸¸æˆäº‹ä»¶
                    events = []
                    
                    # æ¨¡æ¿åŒ¹é…æ£€æµ‹
                    if start_template_cv is not None or end_template_cv is not None:
                        template_events = cls._detect_template_events(
                            video_file, start_template_cv, end_template_cv, template_threshold
                        )
                        events.extend(template_events)
                    
                    # OCRæ–‡å­—è¯†åˆ«æ£€æµ‹
                    if enable_ocr and (start_words or end_words):
                        ocr_events = cls._detect_ocr_events(
                            video_file, start_words, end_words, ocr_confidence
                        )
                        events.extend(ocr_events)
                    
                    if not events:
                        print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] {video_name}: æœªæ£€æµ‹åˆ°æ¸¸æˆäº‹ä»¶")
                        continue
                    
                    # åˆå¹¶å’Œæ’åºäº‹ä»¶
                    events = sorted(events, key=lambda x: x['time'])
                    print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] {video_name}: æ£€æµ‹åˆ° {len(events)} ä¸ªäº‹ä»¶")
                    
                    # é…å¯¹æ¸¸æˆå±€æ¬¡
                    sessions = cls._pair_game_sessions(
                        events, min_game_duration, max_game_duration, start_offset, end_offset
                    )
                    
                    if not sessions:
                        print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] {video_name}: æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ¸¸æˆå±€æ¬¡")
                        continue
                    
                    print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] {video_name}: æ‰¾åˆ° {len(sessions)} ä¸ªæ¸¸æˆå±€æ¬¡")
                    
                    # åˆ›å»ºè§†é¢‘è¾“å‡ºç›®å½•
                    video_output_dir = os.path.join(output_folder, video_name)
                    os.makedirs(video_output_dir, exist_ok=True)
                    
                    # æå–æ¸¸æˆç‰‡æ®µ
                    extracted_count = 0
                    for i, session in enumerate(sessions):
                        output_filename = f"game_session_{i+1:03d}.mp4"
                        output_path = os.path.join(video_output_dir, output_filename)
                        
                        success = cls._extract_video_segment(
                            video_file, session['start'], session['end'], output_path
                        )
                        
                        if success:
                            extracted_count += 1
                            print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] æå–: {output_filename} ({session['duration']:.1f}ç§’)")
                        else:
                            print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] æå–å¤±è´¥: {output_filename}")
                    
                    # ç»Ÿè®¡ä¿¡æ¯
                    extraction_stats.append({
                        "file": video_name,
                        "total_sessions": len(sessions),
                        "extracted_sessions": extracted_count,
                        "total_duration": sum(s['duration'] for s in sessions),
                        "events_detected": len(events)
                    })
                    
                    total_sessions += extracted_count
                    
                except Exception as e:
                    print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] å¤„ç†å¤±è´¥: {video_name}, é”™è¯¯: {str(e)}")
            
            # ç”Ÿæˆæå–æŠ¥å‘Š
            report = cls._generate_extraction_report(extraction_stats)
            
            # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
            report_path = os.path.join(output_folder, "extraction_report.json")
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump({
                    "summary": report,
                    "details": extraction_stats,
                    "settings": {
                        "start_offset": start_offset,
                        "end_offset": end_offset,
                        "min_game_duration": min_game_duration,
                        "max_game_duration": max_game_duration,
                        "template_threshold": template_threshold,
                        "ocr_confidence": ocr_confidence
                    }
                }, f, ensure_ascii=False, indent=2)
            
            print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] å¤„ç†å®Œæˆ: å…±æå– {total_sessions} ä¸ªæ¸¸æˆå±€æ¬¡")
            
            return io.NodeOutput(output_folder, total_sessions, report)
            
        except Exception as e:
            error_msg = f"æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨æ‰§è¡Œå¤±è´¥: {str(e)}"
            print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] é”™è¯¯: {error_msg}")
            # åˆ›å»ºç©ºçš„è§†é¢‘å¯¹è±¡
            import io as python_io
            error_video = VideoFromFile(python_io.BytesIO(b''))
            return io.NodeOutput("", 0, error_msg, "", error_video)
    
    @classmethod
    def _convert_image_to_cv(cls, image_tensor):
        """å°†ComfyUIå›¾åƒå¼ é‡è½¬æ¢ä¸ºOpenCVæ ¼å¼"""
        try:
            import cv2
            import numpy as np
            import torch
            
            if image_tensor is None:
                return None
            
            # ComfyUIå›¾åƒæ ¼å¼: [batch, height, width, channels] (0-1 float)
            if isinstance(image_tensor, torch.Tensor):
                # å–ç¬¬ä¸€ä¸ªbatch
                img_array = image_tensor[0].cpu().numpy()
            else:
                img_array = image_tensor[0] if len(image_tensor.shape) == 4 else image_tensor
            
            # è½¬æ¢ä¸º0-255èŒƒå›´
            if img_array.max() <= 1.0:
                img_array = (img_array * 255).astype(np.uint8)
            
            # è½¬æ¢ä¸ºBGRæ ¼å¼ (OpenCVé»˜è®¤)
            if len(img_array.shape) == 3 and img_array.shape[2] == 3:
                # RGB to BGR
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            
            return img_array
            
        except Exception as e:
            print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] å›¾åƒè½¬æ¢å¤±è´¥: {str(e)}")
            return None
    
    @classmethod
    def _detect_template_events(cls, video_path, start_template, end_template, threshold):
        """æ¨¡æ¿åŒ¹é…æ£€æµ‹æ¸¸æˆäº‹ä»¶"""
        try:
            import cv2
            
            cap = cv2.VideoCapture(video_path)
            events = []
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = 0
            
            # æ¯ç§’æ£€æµ‹ä¸€æ¬¡
            sample_interval = max(1, int(fps))
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_count += 1
                if frame_count % sample_interval != 0:
                    continue
                
                current_time = frame_count / fps
                
                # æ£€æµ‹å¼€å§‹æ¨¡æ¿
                if start_template is not None:
                    result = cv2.matchTemplate(frame, start_template, cv2.TM_CCOEFF_NORMED)
                    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)
                    
                    if max_val >= threshold:
                        events.append({
                            "time": current_time,
                            "event": "start",
                            "method": "template",
                            "template": "start_template",
                            "confidence": max_val
                        })
                
                # æ£€æµ‹ç»“æŸæ¨¡æ¿
                if end_template is not None:
                    result = cv2.matchTemplate(frame, end_template, cv2.TM_CCOEFF_NORMED)
                    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)
                    
                    if max_val >= threshold:
                        events.append({
                            "time": current_time,
                            "event": "end",
                            "method": "template",
                            "template": "end_template",
                            "confidence": max_val
                        })
            
            cap.release()
            return events
            
        except Exception as e:
            print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] æ¨¡æ¿æ£€æµ‹å¤±è´¥: {str(e)}")
            return []
    
    @classmethod
    def _detect_ocr_events(cls, video_path, start_words, end_words, confidence_threshold):
        """OCRæ–‡å­—è¯†åˆ«æ£€æµ‹æ¸¸æˆäº‹ä»¶"""
        try:
            import cv2
            import easyocr
            
            reader = easyocr.Reader(['ch_sim', 'en'])
            cap = cv2.VideoCapture(video_path)
            events = []
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = 0
            
            # æ¯2ç§’æ£€æµ‹ä¸€æ¬¡ï¼ˆOCRè¾ƒæ…¢ï¼‰
            sample_interval = max(1, int(fps * 2))
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_count += 1
                if frame_count % sample_interval != 0:
                    continue
                
                current_time = frame_count / fps
                
                try:
                    # OCRè¯†åˆ«
                    results = reader.readtext(frame)
                    
                    for (bbox, text, confidence) in results:
                        if confidence < confidence_threshold:
                            continue
                        
                        text_lower = text.lower().strip()
                        
                        # æ£€æµ‹å¼€å§‹å…³é”®è¯
                        if any(keyword in text_lower for keyword in start_words):
                            events.append({
                                "time": current_time,
                                "event": "start",
                                "method": "ocr",
                                "text": text,
                                "confidence": confidence
                            })
                        
                        # æ£€æµ‹ç»“æŸå…³é”®è¯
                        elif any(keyword in text_lower for keyword in end_words):
                            events.append({
                                "time": current_time,
                                "event": "end",
                                "method": "ocr", 
                                "text": text,
                                "confidence": confidence
                            })
                
                except Exception:
                    continue
            
            cap.release()
            return events
            
        except ImportError:
            print("[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] è­¦å‘Š: easyocræœªå®‰è£…ï¼Œè·³è¿‡OCRæ£€æµ‹")
            return []
        except Exception as e:
            print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] OCRæ£€æµ‹å¤±è´¥: {str(e)}")
            return []
    
    @classmethod
    def _pair_game_sessions(cls, events, min_duration, max_duration, start_offset, end_offset):
        """é…å¯¹æ¸¸æˆå¼€å§‹å’Œç»“æŸäº‹ä»¶"""
        sessions = []
        
        # åˆå¹¶ç›¸è¿‘çš„åŒç±»äº‹ä»¶ï¼ˆå»é‡ï¼‰
        merged_events = cls._merge_nearby_events(events, gap=3.0)
        
        i = 0
        while i < len(merged_events) - 1:
            current_event = merged_events[i]
            
            if current_event['event'] == 'start':
                # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªç»“æŸäº‹ä»¶
                for j in range(i + 1, len(merged_events)):
                    next_event = merged_events[j]
                    
                    if next_event['event'] == 'end':
                        # è®¡ç®—å®é™…çš„å¼€å§‹å’Œç»“æŸæ—¶é—´ï¼ˆåº”ç”¨åç§»ï¼‰
                        actual_start = max(0, current_event['time'] + start_offset)
                        actual_end = next_event['time'] + end_offset
                        duration = actual_end - actual_start
                        
                        # éªŒè¯æ—¶é•¿æ˜¯å¦åˆç†
                        if min_duration <= duration <= max_duration:
                            sessions.append({
                                "start": actual_start,
                                "end": actual_end,
                                "duration": duration,
                                "start_event": current_event,
                                "end_event": next_event
                            })
                        
                        i = j  # è·³åˆ°ç»“æŸäº‹ä»¶ä½ç½®
                        break
                else:
                    i += 1
            else:
                i += 1
        
        return sessions
    
    @classmethod
    def _merge_nearby_events(cls, events, gap=3.0):
        """åˆå¹¶æ—¶é—´ç›¸è¿‘çš„åŒç±»äº‹ä»¶"""
        if not events:
            return events
        
        merged = []
        events = sorted(events, key=lambda x: x['time'])
        
        current_event = events[0]
        
        for event in events[1:]:
            # å¦‚æœæ˜¯åŒç±»äº‹ä»¶ä¸”æ—¶é—´ç›¸è¿‘ï¼Œé€‰æ‹©ç½®ä¿¡åº¦æ›´é«˜çš„
            if (event['event'] == current_event['event'] and 
                event['time'] - current_event['time'] <= gap):
                
                if event.get('confidence', 0) > current_event.get('confidence', 0):
                    current_event = event
            else:
                merged.append(current_event)
                current_event = event
        
        merged.append(current_event)
        return merged
    
    @classmethod
    def _extract_video_segment(cls, video_path, start_time, end_time, output_path):
        """æå–è§†é¢‘ç‰‡æ®µ"""
        try:
            import ffmpeg
            
            duration = end_time - start_time
            
            (
                ffmpeg
                .input(video_path, ss=start_time, t=duration)
                .output(output_path, vcodec='libx264', acodec='aac', preset='fast')
                .overwrite_output()
                .run(quiet=True)
            )
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            return os.path.exists(output_path) and os.path.getsize(output_path) > 0
            
        except Exception as e:
            print(f"[æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨] è§†é¢‘æå–å¤±è´¥: {str(e)}")
            return False
    
    @classmethod
    def _generate_extraction_report(cls, stats):
        """ç”Ÿæˆæå–æŠ¥å‘Š"""
        if not stats:
            return "æœªæå–ä»»ä½•æ¸¸æˆå±€æ¬¡"
        
        total_videos = len(stats)
        successful_videos = len([s for s in stats if s['extracted_sessions'] > 0])
        total_sessions = sum(s['extracted_sessions'] for s in stats)
        total_duration = sum(s['total_duration'] for s in stats)
        
        report = f"""æ¸¸æˆç²¾å½©ç‰‡æ®µæå–å®ŒæˆæŠ¥å‘Šï¼š
ğŸ® å¤„ç†è§†é¢‘: {successful_videos}/{total_videos} ä¸ªæˆåŠŸ
ğŸ¯ æå–å±€æ¬¡: {total_sessions} ä¸ªæ¸¸æˆå±€æ¬¡
â±ï¸ æ€»æ—¶é•¿: {total_duration:.1f} ç§’ ({total_duration/60:.1f} åˆ†é’Ÿ)
ğŸ“Š å¹³å‡æ¯è§†é¢‘: {total_sessions/successful_videos:.1f} ä¸ªå±€æ¬¡"""
        
        if successful_videos < total_videos:
            failed_videos = total_videos - successful_videos
            report += f"\nâŒ å¤±è´¥è§†é¢‘: {failed_videos} ä¸ª"
        
        return report


class VideoThumbnailGenerator(io.ComfyNode):
    """è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨ - æ™ºèƒ½ç”Ÿæˆè§†é¢‘å°é¢ï¼Œæ”¯æŒæ–‡å­—å åŠ å’Œå¤šå°ºå¯¸è¾“å‡º"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="VideoThumbnailGenerator",
            display_name="è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨",
            category="batch_video",
            description="æ™ºèƒ½é€‰æ‹©ç²¾å½©å¸§ç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾ï¼Œæ”¯æŒæ–‡å­—å åŠ å’Œç»Ÿä¸€æ¨¡æ¿",
            inputs=[
                io.String.Input("video_folder", tooltip="è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„"),
                io.String.Input("title_template", default="{filename}", tooltip="æ ‡é¢˜æ¨¡æ¿ï¼Œæ”¯æŒ{filename}, {index}, {duration}ç­‰å˜é‡"),
                io.String.Input("font_path", optional=True, tooltip="å­—ä½“æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“ï¼‰"),
                io.Int.Input("font_size", default=48, tooltip="å­—ä½“å¤§å°"),
                io.String.Input("font_color", default="white", tooltip="å­—ä½“é¢œè‰²(white/black/red/blueç­‰)"),
                io.String.Input("outline_color", default="black", tooltip="å­—ä½“æè¾¹é¢œè‰²"),
                io.Int.Input("outline_width", default=3, tooltip="å­—ä½“æè¾¹å®½åº¦"),
                io.String.Input("text_position", default="bottom-center", tooltip="æ–‡å­—ä½ç½®(top-left/top-center/top-right/center/bottom-left/bottom-center/bottom-right)"),
                io.String.Input("frame_selection", default="middle", tooltip="å¸§é€‰æ‹©ç­–ç•¥(first/middle/last/brightest/highest_contrast/most_colorful)"),
                io.Float.Input("frame_offset", default=0.0, tooltip="å¸§åç§»æ¯”ä¾‹(0.0-1.0)"),
                io.String.Input("output_sizes", default="1920x1080,1280x720,640x360", tooltip="è¾“å‡ºå°ºå¯¸åˆ—è¡¨(é€—å·åˆ†éš”)"),
                io.String.Input("output_format", default="jpg", tooltip="è¾“å‡ºæ ¼å¼(jpg/png)"),
                io.Int.Input("output_quality", default=90, tooltip="è¾“å‡ºè´¨é‡(1-100)"),
                io.Boolean.Input("add_gradient", default=True, tooltip="æ·»åŠ æ–‡å­—èƒŒæ™¯æ¸å˜"),
                io.String.Input("output_prefix", default="ç¼©ç•¥å›¾", tooltip="è¾“å‡ºå‰ç¼€"),
            ],
            outputs=[
                io.String.Output("output_folder", display_name="è¾“å‡ºæ–‡ä»¶å¤¹"),
                io.Int.Output("generated_count", display_name="ç”Ÿæˆæ•°é‡"),
                io.String.Output("generation_report", display_name="ç”ŸæˆæŠ¥å‘Š"),
            ],
        )
    
    @classmethod
    def execute(cls, video_folder, title_template="{filename}", font_path=None, font_size=48,
                font_color="white", outline_color="black", outline_width=3, text_position="bottom-center",
                frame_selection="middle", frame_offset=0.0, output_sizes="1920x1080,1280x720,640x360",
                output_format="jpg", output_quality=90, add_gradient=True, output_prefix="ç¼©ç•¥å›¾"):
        
        import os
        import time
        import json
        from pathlib import Path
        
        try:
            # éªŒè¯è¾“å…¥æ–‡ä»¶å¤¹
            if not os.path.exists(video_folder):
                raise ValueError(f"è§†é¢‘æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {video_folder}")
            
            # æ‰«æè§†é¢‘æ–‡ä»¶
            video_files = []
            for ext in ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm', '.m4v']:
                pattern = os.path.join(video_folder, f"*{ext}")
                import glob
                video_files.extend(glob.glob(pattern))
                video_files.extend(glob.glob(pattern.upper()))
            
            if not video_files:
                raise ValueError(f"åœ¨æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {video_folder}")
            
            # è§£æè¾“å‡ºå°ºå¯¸
            try:
                sizes = []
                for size_str in output_sizes.split(','):
                    size_str = size_str.strip()
                    if 'x' in size_str:
                        w, h = map(int, size_str.split('x'))
                        sizes.append((w, h))
                if not sizes:
                    sizes = [(1920, 1080)]  # é»˜è®¤å°ºå¯¸
            except:
                sizes = [(1920, 1080)]  # è§£æå¤±è´¥ä½¿ç”¨é»˜è®¤
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
            timestamp = int(time.time())
            output_folder = os.path.join(folder_paths.get_temp_directory(), f"{output_prefix}_ç”Ÿæˆ_{timestamp}")
            os.makedirs(output_folder, exist_ok=True)
            
            generated_count = 0
            generation_stats = []
            
            print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] å¼€å§‹å¤„ç† {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
            print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] è¾“å‡ºå°ºå¯¸: {sizes}")
            print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] å¸§é€‰æ‹©ç­–ç•¥: {frame_selection}")
            
            for i, video_file in enumerate(video_files):
                try:
                    video_name = Path(video_file).stem
                    print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] å¤„ç†è§†é¢‘: {video_name} ({i+1}/{len(video_files)})")
                    
                    # è·å–è§†é¢‘ä¿¡æ¯
                    video_info = cls._get_video_info(video_file)
                    if not video_info:
                        print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] æ— æ³•è·å–è§†é¢‘ä¿¡æ¯: {video_name}")
                        continue
                    
                    duration = video_info.get('duration', 0)
                    
                    # æå–å…³é”®å¸§
                    frame_time = cls._calculate_frame_time(duration, frame_selection, frame_offset)
                    frame_image = cls._extract_frame(video_file, frame_time)
                    
                    if frame_image is None:
                        print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] å¸§æå–å¤±è´¥: {video_name}")
                        continue
                    
                    # ç”Ÿæˆæ ‡é¢˜æ–‡å­—
                    title_text = cls._generate_title(title_template, video_name, i+1, duration)
                    
                    # ç”Ÿæˆä¸åŒå°ºå¯¸çš„ç¼©ç•¥å›¾
                    size_count = 0
                    for width, height in sizes:
                        try:
                            # è°ƒæ•´å›¾åƒå°ºå¯¸
                            resized_frame = cls._resize_frame(frame_image, width, height)
                            
                            # æ·»åŠ æ–‡å­—å åŠ 
                            final_image = cls._add_text_overlay(
                                resized_frame, title_text, font_path, font_size,
                                font_color, outline_color, outline_width,
                                text_position, add_gradient
                            )
                            
                            # ä¿å­˜ç¼©ç•¥å›¾
                            output_filename = f"{video_name}_{width}x{height}.{output_format}"
                            output_path = os.path.join(output_folder, output_filename)
                            
                            success = cls._save_image(final_image, output_path, output_format, output_quality)
                            if success:
                                size_count += 1
                                print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] ç”Ÿæˆ: {output_filename}")
                            else:
                                print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] ä¿å­˜å¤±è´¥: {output_filename}")
                        
                        except Exception as e:
                            print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] å°ºå¯¸å¤„ç†å¤±è´¥ {width}x{height}: {str(e)}")
                    
                    if size_count > 0:
                        generation_stats.append({
                            "file": video_name,
                            "sizes_generated": size_count,
                            "total_sizes": len(sizes),
                            "title": title_text,
                            "frame_time": frame_time,
                            "duration": duration
                        })
                        generated_count += size_count
                    
                except Exception as e:
                    print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] å¤„ç†å¤±è´¥: {video_name}, é”™è¯¯: {str(e)}")
            
            # ç”ŸæˆæŠ¥å‘Š
            report = cls._generate_report(generation_stats, len(video_files), len(sizes))
            
            # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
            report_path = os.path.join(output_folder, "generation_report.json")
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump({
                    "summary": report,
                    "details": generation_stats,
                    "settings": {
                        "title_template": title_template,
                        "frame_selection": frame_selection,
                        "output_sizes": output_sizes,
                        "output_format": output_format,
                        "font_size": font_size,
                        "text_position": text_position
                    }
                }, f, ensure_ascii=False, indent=2)
            
            print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] å¤„ç†å®Œæˆ: å…±ç”Ÿæˆ {generated_count} å¼ ç¼©ç•¥å›¾")
            
            return io.NodeOutput(output_folder, generated_count, report)
            
        except Exception as e:
            error_msg = f"è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨æ‰§è¡Œå¤±è´¥: {str(e)}"
            print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] é”™è¯¯: {error_msg}")
            # åˆ›å»ºç©ºçš„è§†é¢‘å¯¹è±¡
            import io as python_io
            error_video = VideoFromFile(python_io.BytesIO(b''))
            return io.NodeOutput("", 0, error_msg, "", error_video)
    
    @classmethod
    def _get_video_info(cls, video_path):
        """è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯"""
        try:
            import ffmpeg
            probe = ffmpeg.probe(video_path)
            video_stream = next(s for s in probe['streams'] if s['codec_type'] == 'video')
            return {
                'duration': float(probe['format']['duration']),
                'width': int(video_stream['width']),
                'height': int(video_stream['height']),
                'fps': eval(video_stream['r_frame_rate'])
            }
        except Exception as e:
            print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] è§†é¢‘ä¿¡æ¯è·å–å¤±è´¥: {str(e)}")
            return None
    
    @classmethod
    def _calculate_frame_time(cls, duration, strategy, offset):
        """è®¡ç®—è¦æå–çš„å¸§æ—¶é—´ç‚¹"""
        if strategy == "first":
            return max(0.1, duration * 0.01)  # é¿å…é»‘å±
        elif strategy == "last":
            return max(0, duration * 0.95)  # é¿å…ç»“æŸé»‘å±
        elif strategy == "middle":
            return duration * 0.5
        else:
            # å¯¹äºå…¶ä»–ç­–ç•¥ï¼Œå…ˆä½¿ç”¨ä¸­é—´ä½ç½®ï¼Œåç»­å¯ä»¥æ”¹ä¸ºæ™ºèƒ½åˆ†æ
            return duration * (0.3 + offset * 0.4)  # 0.3-0.7èŒƒå›´
    
    @classmethod
    def _extract_frame(cls, video_path, time_point):
        """ä»è§†é¢‘ä¸­æå–æŒ‡å®šæ—¶é—´ç‚¹çš„å¸§"""
        try:
            import cv2
            
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                return None
            
            # è·³è½¬åˆ°æŒ‡å®šæ—¶é—´ç‚¹
            cap.set(cv2.CAP_PROP_POS_MSEC, time_point * 1000)
            ret, frame = cap.read()
            cap.release()
            
            if ret and frame is not None:
                return frame
            else:
                return None
                
        except Exception as e:
            print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] å¸§æå–å¤±è´¥: {str(e)}")
            return None
    
    @classmethod
    def _resize_frame(cls, frame, target_width, target_height):
        """è°ƒæ•´å¸§å°ºå¯¸ï¼Œä¿æŒå®½é«˜æ¯”"""
        try:
            import cv2
            
            h, w = frame.shape[:2]
            
            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
            scale = min(target_width / w, target_height / h)
            new_w = int(w * scale)
            new_h = int(h * scale)
            
            # ç¼©æ”¾å›¾åƒ
            resized = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
            
            # åˆ›å»ºç›®æ ‡å°ºå¯¸çš„ç”»å¸ƒï¼ˆé»‘è‰²èƒŒæ™¯ï¼‰
            canvas = cv2.zeros((target_height, target_width, 3), dtype=resized.dtype)
            
            # è®¡ç®—å±…ä¸­ä½ç½®
            x_offset = (target_width - new_w) // 2
            y_offset = (target_height - new_h) // 2
            
            # å°†ç¼©æ”¾åçš„å›¾åƒæ”¾åˆ°ç”»å¸ƒä¸­å¿ƒ
            canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
            
            return canvas
            
        except Exception as e:
            print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] å›¾åƒç¼©æ”¾å¤±è´¥: {str(e)}")
            return frame
    
    @classmethod
    def _generate_title(cls, template, filename, index, duration):
        """ç”Ÿæˆæ ‡é¢˜æ–‡å­—"""
        try:
            # å¯ç”¨å˜é‡
            variables = {
                'filename': Path(filename).stem,
                'index': str(index),
                'duration': f"{int(duration//60):02d}:{int(duration%60):02d}",
                'duration_sec': str(int(duration))
            }
            
            title = template
            for var, value in variables.items():
                title = title.replace(f'{{{var}}}', value)
            
            return title
            
        except Exception as e:
            print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] æ ‡é¢˜ç”Ÿæˆå¤±è´¥: {str(e)}")
            return filename
    
    @classmethod
    def _add_text_overlay(cls, image, text, font_path, font_size, font_color,
                          outline_color, outline_width, position, add_gradient):
        """æ·»åŠ æ–‡å­—å åŠ """
        try:
            import cv2
            import numpy as np
            from PIL import Image, ImageDraw, ImageFont
            
            # è½¬æ¢ä¸ºPILæ ¼å¼
            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(pil_image)
            
            # åŠ è½½å­—ä½“
            try:
                if font_path and os.path.exists(font_path):
                    font = ImageFont.truetype(font_path, font_size)
                else:
                    # å°è¯•ä½¿ç”¨ç³»ç»Ÿå­—ä½“
                    font = ImageFont.load_default()
                    # å¦‚æœå¯èƒ½ï¼Œå°è¯•åŠ è½½æ›´å¥½çš„å­—ä½“
                    try:
                        font = ImageFont.truetype("arial.ttf", font_size)
                    except:
                        pass
            except:
                font = ImageFont.load_default()
            
            # è·å–æ–‡å­—å°ºå¯¸
            bbox = draw.textbbox((0, 0), text, font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
            
            # è®¡ç®—æ–‡å­—ä½ç½®
            img_width, img_height = pil_image.size
            x, y = cls._calculate_text_position(position, img_width, img_height, text_width, text_height)
            
            # æ·»åŠ æ¸å˜èƒŒæ™¯
            if add_gradient:
                cls._add_text_gradient(draw, x, y, text_width, text_height, img_width, img_height)
            
            # é¢œè‰²æ˜ å°„
            color_map = {
                'white': (255, 255, 255),
                'black': (0, 0, 0),
                'red': (255, 0, 0),
                'blue': (0, 0, 255),
                'green': (0, 255, 0),
                'yellow': (255, 255, 0)
            }
            
            text_color = color_map.get(font_color.lower(), (255, 255, 255))
            stroke_color = color_map.get(outline_color.lower(), (0, 0, 0))
            
            # ç»˜åˆ¶æ–‡å­—ï¼ˆå¸¦æè¾¹ï¼‰
            draw.text((x, y), text, font=font, fill=text_color, 
                     stroke_width=outline_width, stroke_fill=stroke_color)
            
            # è½¬æ¢å›OpenCVæ ¼å¼
            return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            
        except Exception as e:
            print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] æ–‡å­—å åŠ å¤±è´¥: {str(e)}")
            return image
    
    @classmethod
    def _calculate_text_position(cls, position, img_w, img_h, text_w, text_h):
        """è®¡ç®—æ–‡å­—ä½ç½®"""
        margin = 20
        
        positions = {
            'top-left': (margin, margin),
            'top-center': (img_w // 2 - text_w // 2, margin),
            'top-right': (img_w - text_w - margin, margin),
            'center': (img_w // 2 - text_w // 2, img_h // 2 - text_h // 2),
            'bottom-left': (margin, img_h - text_h - margin),
            'bottom-center': (img_w // 2 - text_w // 2, img_h - text_h - margin),
            'bottom-right': (img_w - text_w - margin, img_h - text_h - margin)
        }
        
        return positions.get(position, positions['bottom-center'])
    
    @classmethod
    def _add_text_gradient(cls, draw, x, y, text_w, text_h, img_w, img_h):
        """æ·»åŠ æ–‡å­—èƒŒæ™¯æ¸å˜"""
        try:
            from PIL import Image, ImageDraw
            import numpy as np
            
            # åˆ›å»ºæ¸å˜èƒŒæ™¯åŒºåŸŸ
            gradient_height = text_h + 40
            gradient_y = max(0, y - 20)
            
            # åˆ›å»ºæ¸å˜ï¼ˆä»é€æ˜åˆ°åŠé€æ˜é»‘è‰²ï¼‰
            gradient = Image.new('RGBA', (img_w, gradient_height), (0, 0, 0, 0))
            gradient_draw = ImageDraw.Draw(gradient)
            
            for i in range(gradient_height):
                alpha = int(100 * (i / gradient_height))  # æ¸å˜é€æ˜åº¦
                color = (0, 0, 0, alpha)
                gradient_draw.line([(0, i), (img_w, i)], fill=color)
            
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥ç»˜åˆ¶åŠé€æ˜çŸ©å½¢
            overlay = Image.new('RGBA', (img_w, img_h), (0, 0, 0, 0))
            overlay_draw = ImageDraw.Draw(overlay)
            overlay_draw.rectangle([0, gradient_y, img_w, gradient_y + gradient_height], 
                                 fill=(0, 0, 0, 80))
            
        except Exception as e:
            print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] æ¸å˜èƒŒæ™¯å¤±è´¥: {str(e)}")
    
    @classmethod
    def _save_image(cls, image, output_path, format_type, quality):
        """ä¿å­˜å›¾åƒæ–‡ä»¶"""
        try:
            import cv2
            
            if format_type.lower() == 'png':
                success = cv2.imwrite(output_path, image, [cv2.IMWRITE_PNG_COMPRESSION, 9])
            else:  # jpg
                success = cv2.imwrite(output_path, image, [cv2.IMWRITE_JPEG_QUALITY, quality])
            
            return success and os.path.exists(output_path) and os.path.getsize(output_path) > 0
            
        except Exception as e:
            print(f"[è§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨] å›¾åƒä¿å­˜å¤±è´¥: {str(e)}")
            return False
    
    @classmethod
    def _generate_report(cls, stats, total_videos, total_sizes):
        """ç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
        if not stats:
            return "æœªç”Ÿæˆä»»ä½•ç¼©ç•¥å›¾"
        
        successful_videos = len(stats)
        total_generated = sum(s['sizes_generated'] for s in stats)
        expected_total = total_videos * total_sizes
        
        report = f"""ç¼©ç•¥å›¾ç”Ÿæˆå®ŒæˆæŠ¥å‘Šï¼š
ğŸ¨ å¤„ç†è§†é¢‘: {successful_videos}/{total_videos} ä¸ªæˆåŠŸ
ğŸ“¸ ç”Ÿæˆç¼©ç•¥å›¾: {total_generated}/{expected_total} å¼ 
ğŸ“Š æˆåŠŸç‡: {(total_generated/expected_total*100):.1f}%
â­ å¹³å‡æ¯è§†é¢‘: {total_generated/successful_videos:.1f} å¼ ç¼©ç•¥å›¾"""
        
        if successful_videos < total_videos:
            failed_videos = total_videos - successful_videos
            report += f"\nâŒ å¤±è´¥è§†é¢‘: {failed_videos} ä¸ª"
        
        return report


class SmartAudioBasedCutter(io.ComfyNode):
    """æ‰¹é‡è§†é¢‘åˆ‡åˆ†å™¨-æŒ‰éŸ³é¢‘æ—¶é•¿åˆ‡åˆ† - æ ¹æ®éŸ³é¢‘å’Œå¼•æµè§†é¢‘è‡ªåŠ¨è®¡ç®—åˆ‡åˆ†æ—¶é•¿"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="SmartAudioBasedCutter",
            display_name="æ‰¹é‡è§†é¢‘åˆ‡åˆ†å™¨-æŒ‰éŸ³é¢‘æ—¶é•¿åˆ‡åˆ†",
            category="batch_video",
            description="æ ¹æ®éŸ³é¢‘æ–‡ä»¶å’Œå¼•æµè§†é¢‘æ™ºèƒ½è®¡ç®—åˆ‡åˆ†æ—¶é•¿",
            inputs=[
                io.String.Input(
                    "video_folder", 
                    tooltip="è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„"
                ),
                io.String.Input(
                    "audio_folder", 
                    tooltip="éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„"
                ),
                io.String.Input(
                    "trailer_folder", 
                    optional=True,
                    tooltip="å¼•æµè§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„(å¯é€‰)"
                ),
                io.Boolean.Input(
                    "skip_short_segments", 
                    default=True,
                    tooltip="è·³è¿‡è¿‡çŸ­ç‰‡æ®µ"
                ),
                io.String.Input(
                    "output_prefix", 
                    default="æ™ºèƒ½åˆ‡åˆ†", 
                    tooltip="è¾“å‡ºå‰ç¼€"
                ),
            ],
            outputs=[
                io.String.Output("output_folder", display_name="æ–‡ä»¶å¤¹è·¯å¾„"),
                io.Int.Output("total_segments", display_name="æ€»ç‰‡æ®µæ•°"),
                io.Float.Output("calculated_duration", display_name="è®¡ç®—æ—¶é•¿"),
                io.String.Output("summary", display_name="å¤„ç†æ‘˜è¦"),
            ],
        )

    @classmethod
    def execute(cls, video_folder: str, audio_folder: str, trailer_folder: str = None,
                skip_short_segments: bool = True, output_prefix: str = "æ™ºèƒ½åˆ‡åˆ†") -> io.NodeOutput:
        
        import random
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
        output_dir = folder_paths.get_output_directory()
        output_folder = create_output_folder(output_dir, output_prefix)
        
        # æ‰«æå„ç±»æ–‡ä»¶
        if not os.path.exists(video_folder):
            return io.NodeOutput(output_folder, 0, 0.0, "é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶å¤¹ä¸å­˜åœ¨")
        
        if not os.path.exists(audio_folder):
            return io.NodeOutput(output_folder, 0, 0.0, "é”™è¯¯ï¼šéŸ³é¢‘æ–‡ä»¶å¤¹ä¸å­˜åœ¨")
        
        video_files = scan_video_files(video_folder)
        audio_files = scan_media_files(audio_folder, ['audio'])['audio']
        
        if not video_files:
            return io.NodeOutput(output_folder, 0, 0.0, "é”™è¯¯ï¼šæœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            
        if not audio_files:
            return io.NodeOutput(output_folder, 0, 0.0, "é”™è¯¯ï¼šæœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
        
        print(f"æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
        print(f"æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
        
        # è®¡ç®—æ™ºèƒ½åˆ‡åˆ†æ—¶é•¿
        try:
            # éšæœºé€‰æ‹©ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ä½œä¸ºæ—¶é•¿å‚è€ƒ
            reference_audio = random.choice(audio_files)
            audio_duration = get_video_duration(reference_audio)  # éŸ³é¢‘ä¹Ÿå¯ä»¥ç”¨è¿™ä¸ªå‡½æ•°
            print(f"å‚è€ƒéŸ³é¢‘æ—¶é•¿: {audio_duration:.2f}ç§’")
            
            calculated_duration = audio_duration
            strategy_info = f"ä½¿ç”¨éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f}ç§’"
            
            # å¦‚æœæœ‰å¼•æµè§†é¢‘æ–‡ä»¶å¤¹ï¼Œè¿›è¡Œæ™ºèƒ½è®¡ç®—
            if trailer_folder and os.path.exists(trailer_folder):
                trailer_files = scan_video_files(trailer_folder)
                if trailer_files:
                    # éšæœºé€‰æ‹©ä¸€ä¸ªå¼•æµè§†é¢‘ä½œä¸ºå‚è€ƒ
                    reference_trailer = random.choice(trailer_files)
                    print(f"å‚è€ƒå¼•æµè§†é¢‘: {os.path.basename(reference_trailer)}")
                    
                    # æ£€æŸ¥å¼•æµè§†é¢‘æ˜¯å¦æœ‰éŸ³é¢‘
                    trailer_info = get_video_info(reference_trailer)
                    has_audio = any(stream.get('codec_type') == 'audio' for stream in trailer_info.get('streams', []))
                    
                    if has_audio:
                        # å¼•æµè§†é¢‘æœ‰éŸ³é¢‘ï¼šåˆ‡åˆ†æ—¶é•¿ = éŸ³é¢‘æ—¶é•¿
                        calculated_duration = audio_duration
                        strategy_info = f"å¼•æµè§†é¢‘æœ‰éŸ³é¢‘ï¼Œä½¿ç”¨éŸ³é¢‘æ—¶é•¿: {calculated_duration:.2f}ç§’"
                        print("å¼•æµè§†é¢‘æœ‰éŸ³é¢‘ï¼Œä½¿ç”¨å®Œæ•´éŸ³é¢‘æ—¶é•¿")
                    else:
                        # å¼•æµè§†é¢‘æ— éŸ³é¢‘ï¼šåˆ‡åˆ†æ—¶é•¿ = éŸ³é¢‘æ—¶é•¿ - å¼•æµè§†é¢‘æ—¶é•¿
                        trailer_duration = get_video_duration(reference_trailer)
                        calculated_duration = audio_duration - trailer_duration
                        strategy_info = f"å¼•æµè§†é¢‘æ— éŸ³é¢‘ï¼Œè®¡ç®—æ—¶é•¿: {audio_duration:.2f} - {trailer_duration:.2f} = {calculated_duration:.2f}ç§’"
                        print(f"å¼•æµè§†é¢‘æ— éŸ³é¢‘ï¼Œè®¡ç®—æ—¶é•¿: {calculated_duration:.2f}ç§’")
                        
                        if calculated_duration <= 0:
                            return io.NodeOutput(output_folder, 0, calculated_duration, 
                                               f"é”™è¯¯ï¼šå¼•æµè§†é¢‘æ—¶é•¿({trailer_duration:.2f}s) >= éŸ³é¢‘æ—¶é•¿({audio_duration:.2f}s)")
            
        except Exception as e:
            return io.NodeOutput(output_folder, 0, 0.0, f"æ—¶é•¿è®¡ç®—å¤±è´¥: {str(e)}")
        
        print(f"æœ€ç»ˆåˆ‡åˆ†æ—¶é•¿: {calculated_duration:.2f}ç§’")
        
        # å¼€å§‹æ‰¹é‡åˆ‡åˆ†è§†é¢‘
        total_segments = 0
        processed_videos = 0
        
        for video_file in video_files:
            try:
                video_name = Path(video_file).stem
                video_duration = get_video_duration(video_file)
                
                if video_duration < calculated_duration:
                    if skip_short_segments:
                        print(f"è·³è¿‡çŸ­è§†é¢‘: {video_name} ({video_duration:.2f}s < {calculated_duration:.2f}s)")
                        continue
                    else:
                        print(f"å¤„ç†çŸ­è§†é¢‘: {video_name} ({video_duration:.2f}s)")
                
                # åˆ›å»ºè§†é¢‘è¾“å‡ºç›®å½•
                video_output_dir = os.path.join(output_folder, video_name)
                os.makedirs(video_output_dir, exist_ok=True)
                
                # è®¡ç®—å¯ä»¥åˆ‡åˆ†çš„æ®µæ•°
                num_segments = int(video_duration // calculated_duration)
                if num_segments == 0 and not skip_short_segments:
                    num_segments = 1  # è‡³å°‘åˆ‡ä¸€æ®µ
                
                print(f"å¤„ç†è§†é¢‘: {video_name}, å°†åˆ‡åˆ†ä¸º {num_segments} æ®µ")
                
                # åˆ‡åˆ†è§†é¢‘
                segments_created = 0
                import ffmpeg
                
                for i in range(num_segments):
                    start_time = i * calculated_duration
                    segment_duration = min(calculated_duration, video_duration - start_time)
                    
                    if segment_duration < calculated_duration * 0.5 and skip_short_segments:
                        print(f"è·³è¿‡è¿‡çŸ­ç‰‡æ®µ: {segment_duration:.2f}s")
                        continue
                    
                    output_filename = f"segment_{i+1:03d}.mp4"
                    output_path = os.path.join(video_output_dir, output_filename)
                    
                    try:
                        (
                            ffmpeg
                            .input(video_file, ss=start_time, t=segment_duration)
                            .output(output_path, vcodec='libx264', acodec='aac')
                            .overwrite_output()
                            .run(quiet=True)
                        )
                        segments_created += 1
                        print(f"âœ“ å®Œæˆ: {output_filename}")
                    except Exception as e:
                        print(f"âœ— åˆ‡åˆ†å¤±è´¥ {output_filename}: {e}")
                
                if segments_created > 0:
                    total_segments += segments_created
                    processed_videos += 1
                
            except Exception as e:
                print(f"âœ— å¤„ç†è§†é¢‘å¤±è´¥: {os.path.basename(video_file)} - {e}")
        
        summary = f"""æ™ºèƒ½éŸ³é¢‘æ—¶é•¿åˆ‡åˆ†å®Œæˆï¼
{strategy_info}
è¾“å‡ºæ–‡ä»¶å¤¹: {output_folder}
å¤„ç†è§†é¢‘: {processed_videos}/{len(video_files)} ä¸ª
æ€»ç‰‡æ®µæ•°: {total_segments}
æ¯æ®µæ—¶é•¿: {calculated_duration:.2f}ç§’"""
        
        return io.NodeOutput(output_folder, total_segments, calculated_duration, summary)


class VideoNormalizer(io.ComfyNode):
    """è§†é¢‘æ ‡å‡†åŒ–å™¨ - ç»Ÿä¸€è§†é¢‘æ ¼å¼ä¸ºTikTokæ ‡å‡†ï¼ˆ720x1280ï¼‰"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="VideoNormalizer",
            display_name="ğŸ“± TikTokæ ¼å¼è½¬æ¢å™¨",
            category="batch_video",
            description="å°†è§†é¢‘æ ‡å‡†åŒ–ä¸ºTikTokæ ¼å¼ï¼š720x1280åˆ†è¾¨ç‡ï¼Œ30fpsï¼Œç»Ÿä¸€ç¼–ç å‚æ•°",
            inputs=[
                io.String.Input("input_folder", tooltip="è¾“å…¥è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„"),
                io.Int.Input("target_width", default=720, tooltip="ç›®æ ‡å®½åº¦"),
                io.Int.Input("target_height", default=1280, tooltip="ç›®æ ‡é«˜åº¦"),
                io.Int.Input("target_fps", default=30, tooltip="ç›®æ ‡å¸§ç‡"),
                io.String.Input("output_prefix", default="æ ‡å‡†åŒ–", tooltip="è¾“å‡ºæ–‡ä»¶åå‰ç¼€"),
                io.Boolean.Input("keep_aspect_ratio", default=True, tooltip="ä¿æŒå®½é«˜æ¯”ï¼ˆæ·»åŠ é»‘è¾¹ï¼‰"),
            ],
            outputs=[
                io.String.Output("output_folder", display_name="è¾“å‡ºæ–‡ä»¶å¤¹"),
                io.Int.Output("processed_count", display_name="å¤„ç†æ•°é‡"),
                io.String.Output("summary", display_name="å¤„ç†æ‘˜è¦"),
            ],
        )
    
    @classmethod
    def execute(cls, input_folder, target_width=720, target_height=1280, target_fps=30, 
                output_prefix="æ ‡å‡†åŒ–", keep_aspect_ratio=True):
        import os
        import tempfile
        from pathlib import Path
        from .utils import scan_media_files
        import ffmpeg
        import time
        
        try:
            # éªŒè¯è¾“å…¥æ–‡ä»¶å¤¹
            if not os.path.exists(input_folder):
                raise ValueError(f"è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {input_folder}")
            
            # æ‰«æè§†é¢‘æ–‡ä»¶
            media_files = scan_media_files(input_folder, file_types=['video'])
            video_files = media_files.get('video', [])
            if not video_files:
                raise ValueError(f"åœ¨æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {input_folder}")
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
            timestamp = int(time.time())
            output_folder = os.path.join(folder_paths.get_temp_directory(), f"{output_prefix}_è§†é¢‘æ ‡å‡†åŒ–_{timestamp}")
            os.makedirs(output_folder, exist_ok=True)
            
            processed_count = 0
            failed_files = []
            
            print(f"[è§†é¢‘æ ‡å‡†åŒ–å™¨] å¼€å§‹å¤„ç† {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
            print(f"[è§†é¢‘æ ‡å‡†åŒ–å™¨] ç›®æ ‡æ ¼å¼: {target_width}x{target_height}@{target_fps}fps")
            
            for video_file in video_files:
                try:
                    video_name = Path(video_file).stem
                    output_filename = f"{video_name}_æ ‡å‡†åŒ–.mp4"
                    output_path = os.path.join(output_folder, output_filename)
                    
                    # è·å–åŸè§†é¢‘ä¿¡æ¯
                    probe = ffmpeg.probe(video_file)
                    video_stream = next(s for s in probe['streams'] if s['codec_type'] == 'video')
                    original_width = int(video_stream['width'])
                    original_height = int(video_stream['height'])
                    
                    print(f"[è§†é¢‘æ ‡å‡†åŒ–å™¨] å¤„ç†: {video_name} ({original_width}x{original_height})")
                    
                    # åˆ›å»ºè¾“å…¥æµ
                    input_stream = ffmpeg.input(video_file)
                    
                    if keep_aspect_ratio:
                        # ä¿æŒå®½é«˜æ¯”ï¼Œæ·»åŠ é»‘è¾¹
                        video_filter = input_stream.video.filter('scale', f'{target_width}:{target_height}:force_original_aspect_ratio=decrease').filter('pad', target_width, target_height, '(ow-iw)/2', '(oh-ih)/2')
                    else:
                        # æ‹‰ä¼¸åˆ°ç›®æ ‡å°ºå¯¸
                        video_filter = input_stream.video.filter('scale', target_width, target_height)
                    
                    # è®¾ç½®å¸§ç‡
                    video_filter = video_filter.filter('fps', fps=target_fps)
                    
                    # éŸ³é¢‘å¤„ç†
                    audio_filter = input_stream.audio
                    
                    # è¾“å‡ºè§†é¢‘
                    (
                        ffmpeg
                        .output(
                            video_filter,
                            audio_filter,
                            output_path,
                            vcodec='libx264',
                            preset='fast',
                            **{'profile:v': 'main'},
                            acodec='aac',
                            ar=44100,
                            ac=2,
                            **{'b:v': '2000k', 'maxrate': '2500k', 'bufsize': '5000k'}  # è§†é¢‘æ¯”ç‰¹ç‡æ§åˆ¶
                        )
                        .overwrite_output()
                        .run(quiet=True)
                    )
                    
                    # éªŒè¯è¾“å‡ºæ–‡ä»¶
                    if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                        processed_count += 1
                        print(f"[è§†é¢‘æ ‡å‡†åŒ–å™¨] å®Œæˆ: {output_filename}")
                    else:
                        failed_files.append(video_name)
                        print(f"[è§†é¢‘æ ‡å‡†åŒ–å™¨] å¤±è´¥: {video_name} (è¾“å‡ºæ–‡ä»¶æ— æ•ˆ)")
                        
                except Exception as e:
                    failed_files.append(video_name)
                    print(f"[è§†é¢‘æ ‡å‡†åŒ–å™¨] å¤„ç†å¤±è´¥: {video_name}, é”™è¯¯: {str(e)}")
            
            # ç”Ÿæˆæ‘˜è¦
            summary = f"è§†é¢‘æ ‡å‡†åŒ–å®Œæˆ: æˆåŠŸ {processed_count}/{len(video_files)} ä¸ªæ–‡ä»¶"
            if failed_files:
                summary += f", å¤±è´¥: {len(failed_files)} ä¸ªæ–‡ä»¶"
            
            print(f"[è§†é¢‘æ ‡å‡†åŒ–å™¨] {summary}")
            
            return io.NodeOutput(output_folder, processed_count, summary)
            
        except Exception as e:
            error_msg = f"è§†é¢‘æ ‡å‡†åŒ–å™¨æ‰§è¡Œå¤±è´¥: {str(e)}"
            print(f"[è§†é¢‘æ ‡å‡†åŒ–å™¨] é”™è¯¯: {error_msg}")
            # è¿”å›ç©ºç»“æœä½†ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè®©å·¥ä½œæµç»§ç»­
            # åˆ›å»ºç©ºçš„è§†é¢‘å¯¹è±¡
            import io as python_io
            error_video = VideoFromFile(python_io.BytesIO(b''))
            return io.NodeOutput("", 0, error_msg, "", error_video)


class SmartAudioMixer(io.ComfyNode):
    """æ™ºèƒ½éŸ³é¢‘åˆæˆå™¨ - éšæœºé€‰æ‹©éŸ³é¢‘å¹¶ä¸è§†é¢‘éŸ³é¢‘æ··åˆ"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="SmartAudioMixer",
            display_name="æ™ºèƒ½éŸ³é¢‘åˆæˆå™¨",
            category="batch_video",
            description="éšæœºé€‰æ‹©éŸ³é¢‘æ–‡ä»¶ï¼Œæ™ºèƒ½ä¸è§†é¢‘éŸ³é¢‘æ··åˆï¼Œæ”¯æŒéŸ³é‡æ§åˆ¶",
            inputs=[
                io.String.Input("video_folder", tooltip="è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„"),
                io.String.Input("audio_folder", tooltip="éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„"),
                io.Boolean.Input("mute_original", default=False, tooltip="æ˜¯å¦é™éŸ³åŸè§†é¢‘éŸ³é¢‘"),
                io.Float.Input("original_volume", default=50.0, tooltip="åŸè§†é¢‘éŸ³é‡ (0-100)"),
                io.Float.Input("background_volume", default=80.0, tooltip="èƒŒæ™¯éŸ³é¢‘éŸ³é‡ (0-100)"),
                io.String.Input("output_prefix", default="éŸ³é¢‘åˆæˆ", tooltip="è¾“å‡ºæ–‡ä»¶åå‰ç¼€"),
            ],
            outputs=[
                io.String.Output("output_folder", display_name="è¾“å‡ºæ–‡ä»¶å¤¹"),
                io.Int.Output("processed_count", display_name="å¤„ç†æ•°é‡"),
                io.String.Output("summary", display_name="å¤„ç†æ‘˜è¦"),
            ],
        )
    
    @classmethod
    def execute(cls, video_folder, audio_folder, mute_original=False, original_volume=50.0, 
                background_volume=80.0, output_prefix="éŸ³é¢‘åˆæˆ"):
        import os
        import random
        import time
        from pathlib import Path
        from .utils import scan_media_files
        import ffmpeg
        
        try:
            # éªŒè¯è¾“å…¥æ–‡ä»¶å¤¹
            if not os.path.exists(video_folder):
                raise ValueError(f"è§†é¢‘æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {video_folder}")
            if not os.path.exists(audio_folder):
                raise ValueError(f"éŸ³é¢‘æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {audio_folder}")
            
            # æ‰«ææ–‡ä»¶
            video_files = scan_media_files(video_folder, file_types=['video']).get('video', [])
            audio_files = scan_media_files(audio_folder, file_types=['audio']).get('audio', [])
            
            if not video_files:
                raise ValueError(f"åœ¨æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {video_folder}")
            if not audio_files:
                raise ValueError(f"åœ¨æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶: {audio_folder}")
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
            timestamp = int(time.time())
            output_folder = os.path.join(folder_paths.get_temp_directory(), f"{output_prefix}_éŸ³é¢‘åˆæˆ_{timestamp}")
            os.makedirs(output_folder, exist_ok=True)
            
            processed_count = 0
            failed_files = []
            
            print(f"[æ™ºèƒ½éŸ³é¢‘åˆæˆå™¨] å¼€å§‹å¤„ç† {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
            print(f"[æ™ºèƒ½éŸ³é¢‘åˆæˆå™¨] å¯ç”¨éŸ³é¢‘: {len(audio_files)} ä¸ª")
            print(f"[æ™ºèƒ½éŸ³é¢‘åˆæˆå™¨] éŸ³é‡è®¾ç½®: åŸè§†é¢‘={original_volume}%, èƒŒæ™¯éŸ³é¢‘={background_volume}%")
            
            for video_file in video_files:
                try:
                    video_name = Path(video_file).stem
                    output_filename = f"{video_name}_éŸ³é¢‘åˆæˆ.mp4"
                    output_path = os.path.join(output_folder, output_filename)
                    
                    # éšæœºé€‰æ‹©ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶
                    selected_audio = random.choice(audio_files)
                    audio_name = Path(selected_audio).name
                    
                    print(f"[æ™ºèƒ½éŸ³é¢‘åˆæˆå™¨] å¤„ç†: {video_name} + {audio_name}")
                    
                    # è·å–è§†é¢‘æ—¶é•¿
                    video_probe = ffmpeg.probe(video_file)
                    video_duration = float(video_probe['streams'][0]['duration'])
                    
                    # åˆ›å»ºè¾“å…¥æµ
                    video_input = ffmpeg.input(video_file)
                    audio_input = ffmpeg.input(selected_audio)
                    
                    # å¤„ç†éŸ³é¢‘ï¼šå¾ªç¯æ’­æ”¾èƒŒæ™¯éŸ³é¢‘ä»¥åŒ¹é…è§†é¢‘é•¿åº¦
                    background_audio = audio_input.audio.filter('aloop', loop=-1, size=2**31-1).filter('atrim', duration=video_duration)
                    
                    if mute_original:
                        # åªä½¿ç”¨èƒŒæ™¯éŸ³é¢‘
                        mixed_audio = background_audio.filter('volume', background_volume/100.0)
                    else:
                        # æ··åˆåŸè§†é¢‘éŸ³é¢‘å’ŒèƒŒæ™¯éŸ³é¢‘
                        original_audio = video_input.audio.filter('volume', original_volume/100.0)
                        background_audio = background_audio.filter('volume', background_volume/100.0)
                        mixed_audio = ffmpeg.filter([original_audio, background_audio], 'amix', inputs=2, duration='longest')
                    
                    # è¾“å‡ºè§†é¢‘
                    (
                        ffmpeg
                        .output(
                            video_input.video,
                            mixed_audio,
                            output_path,
                            vcodec='libx264',
                            acodec='aac',
                            preset='fast',
                            ar=44100,
                            ac=2
                        )
                        .overwrite_output()
                        .run(quiet=True)
                    )
                    
                    # éªŒè¯è¾“å‡ºæ–‡ä»¶
                    if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                        processed_count += 1
                        print(f"[æ™ºèƒ½éŸ³é¢‘åˆæˆå™¨] å®Œæˆ: {output_filename}")
                    else:
                        failed_files.append(video_name)
                        print(f"[æ™ºèƒ½éŸ³é¢‘åˆæˆå™¨] å¤±è´¥: {video_name} (è¾“å‡ºæ–‡ä»¶æ— æ•ˆ)")
                        
                except Exception as e:
                    failed_files.append(video_name)
                    print(f"[æ™ºèƒ½éŸ³é¢‘åˆæˆå™¨] å¤„ç†å¤±è´¥: {video_name}, é”™è¯¯: {str(e)}")
            
            # ç”Ÿæˆæ‘˜è¦
            summary = f"éŸ³é¢‘åˆæˆå®Œæˆ: æˆåŠŸ {processed_count}/{len(video_files)} ä¸ªæ–‡ä»¶"
            if failed_files:
                summary += f", å¤±è´¥: {len(failed_files)} ä¸ªæ–‡ä»¶"
            
            print(f"[æ™ºèƒ½éŸ³é¢‘åˆæˆå™¨] {summary}")
            
            return io.NodeOutput(output_folder, processed_count, summary)
            
        except Exception as e:
            error_msg = f"æ™ºèƒ½éŸ³é¢‘åˆæˆå™¨æ‰§è¡Œå¤±è´¥: {str(e)}"
            print(f"[æ™ºèƒ½éŸ³é¢‘åˆæˆå™¨] é”™è¯¯: {error_msg}")
            # åˆ›å»ºç©ºçš„è§†é¢‘å¯¹è±¡
            import io as python_io
            error_video = VideoFromFile(python_io.BytesIO(b''))
            return io.NodeOutput("", 0, error_msg, "", error_video)


class BatchSubtitleGenerator(io.ComfyNode):
    """æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨ - æ”¯æŒé¢„è®¾å­—å¹•å’ŒAIç”Ÿæˆå­—å¹•"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="BatchSubtitleGenerator",
            display_name="æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨",
            category="batch_video",
            description="ä¸ºè§†é¢‘æ‰¹é‡æ·»åŠ å­—å¹•ï¼Œæ”¯æŒé¢„è®¾å­—å¹•æ–‡ä»¶å’ŒAIç”Ÿæˆå­—å¹•",
            inputs=[
                io.String.Input("video_folder", tooltip="è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„"),
                io.String.Input("subtitle_folder", optional=True, tooltip="é¢„è®¾å­—å¹•æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå¯é€‰ï¼‰"),
                io.Boolean.Input("enable_ai_subtitles", default=False, tooltip="å¯ç”¨AIå­—å¹•ç”Ÿæˆ"),
                io.String.Input("subtitle_style", default="default", tooltip="å­—å¹•æ ·å¼"),
                io.Int.Input("font_size", default=24, tooltip="å­—ä½“å¤§å°"),
                io.String.Input("font_color", default="white", tooltip="å­—ä½“é¢œè‰²"),
                io.String.Input("outline_color", default="black", tooltip="æè¾¹é¢œè‰²"),
                io.Int.Input("outline_width", default=2, tooltip="æè¾¹å®½åº¦"),
                io.String.Input("output_prefix", default="å­—å¹•ç‰ˆ", tooltip="è¾“å‡ºæ–‡ä»¶åå‰ç¼€"),
            ],
            outputs=[
                io.String.Output("output_folder", display_name="è¾“å‡ºæ–‡ä»¶å¤¹"),
                io.Int.Output("processed_count", display_name="å¤„ç†æ•°é‡"),
                io.String.Output("summary", display_name="å¤„ç†æ‘˜è¦"),
            ],
        )
    
    @classmethod
    def execute(cls, video_folder, subtitle_folder=None, enable_ai_subtitles=False, 
                subtitle_style="default", font_size=24, font_color="white", 
                outline_color="black", outline_width=2, output_prefix="å­—å¹•ç‰ˆ"):
        import os
        import random
        import time
        from pathlib import Path
        from .utils import scan_media_files
        import ffmpeg
        
        try:
            # éªŒè¯è¾“å…¥æ–‡ä»¶å¤¹
            if not os.path.exists(video_folder):
                raise ValueError(f"è§†é¢‘æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {video_folder}")
            
            # æ‰«æè§†é¢‘æ–‡ä»¶
            video_files = scan_media_files(video_folder, file_types=['video']).get('video', [])
            if not video_files:
                raise ValueError(f"åœ¨æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {video_folder}")
            
            # æ‰«æå­—å¹•æ–‡ä»¶
            subtitle_files = []
            if subtitle_folder and os.path.exists(subtitle_folder):
                # æ”¯æŒçš„å­—å¹•æ ¼å¼
                subtitle_extensions = ['.srt', '.ass', '.vtt', '.sub']
                for ext in subtitle_extensions:
                    pattern = os.path.join(subtitle_folder, f"*{ext}")
                    import glob
                    subtitle_files.extend(glob.glob(pattern))
                    subtitle_files.extend(glob.glob(pattern.upper()))
                print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] æ‰¾åˆ° {len(subtitle_files)} ä¸ªé¢„è®¾å­—å¹•æ–‡ä»¶")
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
            timestamp = int(time.time())
            output_folder = os.path.join(folder_paths.get_temp_directory(), f"{output_prefix}_å­—å¹•ç”Ÿæˆ_{timestamp}")
            os.makedirs(output_folder, exist_ok=True)
            
            processed_count = 0
            failed_files = []
            
            print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] å¼€å§‹å¤„ç† {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
            print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] AIå­—å¹•: {'å¯ç”¨' if enable_ai_subtitles else 'ç¦ç”¨'}")
            print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] å­—å¹•æ ·å¼: {font_size}px {font_color} æè¾¹{outline_color}")
            
            for video_file in video_files:
                try:
                    video_name = Path(video_file).stem
                    output_filename = f"{video_name}_{output_prefix}.mp4"
                    output_path = os.path.join(output_folder, output_filename)
                    
                    print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] å¤„ç†: {video_name}")
                    
                    # åˆ›å»ºè¾“å…¥æµ
                    video_input = ffmpeg.input(video_file)
                    
                    # é€‰æ‹©å­—å¹•æ–¹å¼
                    subtitle_applied = False
                    
                    # ä¼˜å…ˆä½¿ç”¨é¢„è®¾å­—å¹•æ–‡ä»¶
                    if subtitle_files:
                        selected_subtitle = random.choice(subtitle_files)
                        subtitle_name = Path(selected_subtitle).name
                        print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] ä½¿ç”¨é¢„è®¾å­—å¹•: {subtitle_name}")
                        
                        try:
                            # ä½¿ç”¨å­—å¹•æ–‡ä»¶
                            (
                                ffmpeg
                                .output(
                                    video_input,
                                    output_path,
                                    vf=f"subtitles={selected_subtitle}:force_style='FontSize={font_size},PrimaryColour=&H{cls._color_to_hex(font_color)},OutlineColour=&H{cls._color_to_hex(outline_color)},Outline={outline_width}'",
                                    vcodec='libx264',
                                    acodec='aac',
                                    preset='fast'
                                )
                                .overwrite_output()
                                .run(quiet=True)
                            )
                            subtitle_applied = True
                        except Exception as subtitle_error:
                            print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] é¢„è®¾å­—å¹•å¤±è´¥: {str(subtitle_error)}")
                    
                    # å¦‚æœé¢„è®¾å­—å¹•å¤±è´¥æˆ–æœªå¯ç”¨ï¼Œå°è¯•AIå­—å¹•
                    if not subtitle_applied and enable_ai_subtitles:
                        print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] å°è¯•AIå­—å¹•ç”Ÿæˆ")
                        try:
                            ai_subtitle_path = cls._generate_ai_subtitles(video_file, output_folder)
                            if ai_subtitle_path:
                                (
                                    ffmpeg
                                    .output(
                                        video_input,
                                        output_path,
                                        vf=f"subtitles={ai_subtitle_path}:force_style='FontSize={font_size},PrimaryColour=&H{cls._color_to_hex(font_color)},OutlineColour=&H{cls._color_to_hex(outline_color)},Outline={outline_width}'",
                                        vcodec='libx264',
                                        acodec='aac',
                                        preset='fast'
                                    )
                                    .overwrite_output()
                                    .run(quiet=True)
                                )
                                subtitle_applied = True
                                print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] AIå­—å¹•ç”ŸæˆæˆåŠŸ")
                            else:
                                print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] AIå­—å¹•ç”Ÿæˆå¤±è´¥")
                        except Exception as ai_error:
                            print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] AIå­—å¹•å¤±è´¥: {str(ai_error)}")
                    
                    # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œç›´æ¥å¤åˆ¶è§†é¢‘
                    if not subtitle_applied:
                        print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] æ— å­—å¹•ï¼Œç›´æ¥å¤åˆ¶è§†é¢‘")
                        (
                            ffmpeg
                            .output(video_input, output_path, vcodec='libx264', acodec='aac', preset='fast')
                            .overwrite_output()
                            .run(quiet=True)
                        )
                    
                    # éªŒè¯è¾“å‡ºæ–‡ä»¶
                    if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                        processed_count += 1
                        print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] å®Œæˆ: {output_filename}")
                    else:
                        failed_files.append(video_name)
                        print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] å¤±è´¥: {video_name} (è¾“å‡ºæ–‡ä»¶æ— æ•ˆ)")
                        
                except Exception as e:
                    failed_files.append(video_name)
                    print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] å¤„ç†å¤±è´¥: {video_name}, é”™è¯¯: {str(e)}")
            
            # ç”Ÿæˆæ‘˜è¦
            summary = f"å­—å¹•ç”Ÿæˆå®Œæˆ: æˆåŠŸ {processed_count}/{len(video_files)} ä¸ªæ–‡ä»¶"
            if failed_files:
                summary += f", å¤±è´¥: {len(failed_files)} ä¸ªæ–‡ä»¶"
            
            print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] {summary}")
            
            return io.NodeOutput(output_folder, processed_count, summary)
            
        except Exception as e:
            error_msg = f"æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨æ‰§è¡Œå¤±è´¥: {str(e)}"
            print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] é”™è¯¯: {error_msg}")
            # åˆ›å»ºç©ºçš„è§†é¢‘å¯¹è±¡
            import io as python_io
            error_video = VideoFromFile(python_io.BytesIO(b''))
            return io.NodeOutput("", 0, error_msg, "", error_video)
    
    @classmethod
    def _color_to_hex(cls, color_name):
        """å°†é¢œè‰²åè½¬æ¢ä¸ºFFmpegå­—å¹•ä½¿ç”¨çš„åå…­è¿›åˆ¶æ ¼å¼"""
        color_map = {
            'white': 'FFFFFF',
            'black': '000000',
            'red': '0000FF',
            'green': '00FF00',
            'blue': 'FF0000',
            'yellow': '00FFFF',
            'cyan': 'FFFF00',
            'magenta': 'FF00FF',
        }
        return color_map.get(color_name.lower(), 'FFFFFF')
    
    @classmethod  
    def _generate_ai_subtitles(cls, video_file, temp_dir):
        """ä½¿ç”¨AIç”Ÿæˆå­—å¹•æ–‡ä»¶ï¼ˆéœ€è¦å®‰è£…whisperæˆ–å…¶ä»–è¯­éŸ³è¯†åˆ«åº“ï¼‰"""
        try:
            # è¿™é‡Œæ˜¯AIå­—å¹•ç”Ÿæˆçš„å ä½å®ç°
            # å®é™…ä½¿ç”¨æ—¶éœ€è¦å®‰è£… openai-whisper æˆ–å…¶ä»–è¯­éŸ³è¯†åˆ«åº“
            print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] AIå­—å¹•ç”ŸæˆåŠŸèƒ½éœ€è¦å®‰è£…whisperåº“")
            print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] å¯ä»¥è¿è¡Œ: pip install openai-whisper")
            
            # å°è¯•å¯¼å…¥whisperï¼ˆå¦‚æœå·²å®‰è£…ï¼‰
            try:
                import whisper
                
                # æå–éŸ³é¢‘
                audio_path = os.path.join(temp_dir, f"temp_audio_{int(time.time())}.wav")
                ffmpeg.input(video_file).output(audio_path, acodec='pcm_s16le', ar=16000).overwrite_output().run(quiet=True)
                
                # ä½¿ç”¨whisperç”Ÿæˆå­—å¹•
                model = whisper.load_model("base")
                result = model.transcribe(audio_path)
                
                # ç”ŸæˆSRTå­—å¹•æ–‡ä»¶
                subtitle_path = os.path.join(temp_dir, f"ai_subtitle_{int(time.time())}.srt")
                with open(subtitle_path, 'w', encoding='utf-8') as f:
                    for i, segment in enumerate(result['segments']):
                        start_time = cls._format_timestamp(segment['start'])
                        end_time = cls._format_timestamp(segment['end'])
                        text = segment['text'].strip()
                        
                        f.write(f"{i+1}\n")
                        f.write(f"{start_time} --> {end_time}\n")
                        f.write(f"{text}\n\n")
                
                # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                if os.path.exists(audio_path):
                    os.remove(audio_path)
                
                return subtitle_path
                
            except ImportError:
                print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] whisperåº“æœªå®‰è£…ï¼Œè·³è¿‡AIå­—å¹•ç”Ÿæˆ")
                return None
                
        except Exception as e:
            print(f"[æ‰¹é‡å­—å¹•ç”Ÿæˆå™¨] AIå­—å¹•ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None
    
    @classmethod
    def _format_timestamp(cls, seconds):
        """å°†ç§’æ•°è½¬æ¢ä¸ºSRTæ—¶é—´æˆ³æ ¼å¼"""
        import time
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"


class BatchLLMGenerator(io.ComfyNode):
    """æ‰¹é‡æ–‡æ¡ˆç”Ÿæˆå™¨ - åŸºäºLLMæ‰¹é‡ç”Ÿæˆæ–‡æ¡ˆå†…å®¹"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="BatchLLMGenerator", 
            display_name="æ‰¹é‡æ–‡æ¡ˆç”Ÿæˆå™¨",
            category="batch_video",
            description="åŸºäºLLMæ‰¹é‡ç”Ÿæˆæ–‡æ¡ˆ",
            inputs=[
                # LLMé…ç½®
                io.String.Input("model", default="gpt-3.5-turbo", tooltip="æ¨¡å‹åç§°"),
                io.String.Input("api_key", optional=True, tooltip="APIå¯†é’¥"),
                io.String.Input("base_url", optional=True, tooltip="APIåœ°å€"),
                
                # æ‰¹é‡ç”Ÿæˆé…ç½®  
                io.String.Input("prompt_template", multiline=True,
                               default="ä¸º{topic}å†™ä¸€æ®µè§£è¯´è¯ï¼Œè¦æ±‚ç”ŸåŠ¨æœ‰è¶£ï¼Œæœ—è¯»æ—¶é—´15-25ç§’",
                               tooltip="æ–‡æ¡ˆæ¨¡æ¿ï¼Œç”¨{topic}å ä½"),
                io.String.Input("topics", multiline=True,
                               tooltip="ä¸»é¢˜åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ª"),
                io.Float.Input("temperature", default=0.7, tooltip="åˆ›ä½œéšæœºæ€§ (0-1)"),
                io.Int.Input("max_length", default=500, tooltip="æœ€å¤§æ–‡æ¡ˆé•¿åº¦"),
                
                io.String.Input("output_prefix", default="æ‰¹é‡æ–‡æ¡ˆ", tooltip="è¾“å‡ºå‰ç¼€"),
            ],
            outputs=[
                io.String.Output("content_folder", display_name="æ–‡æ¡ˆæ–‡ä»¶å¤¹"),
                io.Int.Output("generated_count", display_name="ç”Ÿæˆæ•°é‡"),
                io.String.Output("summary", display_name="ç”Ÿæˆæ‘˜è¦"),
            ],
        )
    
    @classmethod
    def execute(cls, model="gpt-3.5-turbo", api_key=None, base_url=None, 
                prompt_template="ä¸º{topic}å†™ä¸€æ®µè§£è¯´è¯", topics="", temperature=0.7, max_length=500,
                output_prefix="æ‰¹é‡æ–‡æ¡ˆ"):
        import os
        import time
        import json
        import openai
        from pathlib import Path
        
        try:
            # è§£æä¸»é¢˜åˆ—è¡¨
            topic_list = [t.strip() for t in topics.split('\n') if t.strip()]
            if not topic_list:
                raise ValueError("ä¸»é¢˜åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
            
            # é…ç½®OpenAIå®¢æˆ·ç«¯
            if api_key:
                client_api_key = api_key
            else:
                # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
                import os
                client_api_key = os.environ.get("OPENAI_API_KEY")
                if not client_api_key:
                    raise ValueError("æœªæä¾›APIå¯†é’¥")
            
            if base_url:
                client_base_url = base_url if base_url.endswith('/') else base_url + '/'
            else:
                client_base_url = "https://api.openai.com/v1/"
            
            # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
            from openai import OpenAI
            client = OpenAI(
                api_key=client_api_key,
                base_url=client_base_url
            )
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
            timestamp = int(time.time())
            output_folder = os.path.join(folder_paths.get_temp_directory(), f"{output_prefix}_{timestamp}")
            os.makedirs(output_folder, exist_ok=True)
            
            generated_count = 0
            failed_topics = []
            content_list = []
            
            print(f"[æ‰¹é‡æ–‡æ¡ˆç”Ÿæˆå™¨] å¼€å§‹ç”Ÿæˆ {len(topic_list)} ä¸ªæ–‡æ¡ˆ")
            
            # æ‰¹é‡ç”Ÿæˆæ–‡æ¡ˆ
            for i, topic in enumerate(topic_list):
                try:
                    # æ„å»ºå®Œæ•´çš„prompt
                    full_prompt = prompt_template.format(topic=topic)
                    
                    print(f"[æ‰¹é‡æ–‡æ¡ˆç”Ÿæˆå™¨] ç”Ÿæˆæ–‡æ¡ˆ {i+1}/{len(topic_list)}: {topic}")
                    
                    # è°ƒç”¨LLM API
                    response = client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡ˆåˆ›ä½œè€…ï¼Œæ“…é•¿åˆ›ä½œç”ŸåŠ¨æœ‰è¶£çš„è§†é¢‘è§£è¯´è¯ã€‚"},
                            {"role": "user", "content": full_prompt}
                        ],
                        temperature=temperature,
                        max_tokens=max_length,
                        timeout=30
                    )
                    
                    content = response.choices[0].message.content.strip()
                    
                    # ä¿å­˜æ–‡æ¡ˆåˆ°æ–‡ä»¶
                    content_filename = f"content_{i+1:03d}.txt"
                    content_path = os.path.join(output_folder, content_filename)
                    
                    with open(content_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                    
                    # ä¿å­˜åˆ°å†…å®¹åˆ—è¡¨
                    content_data = {
                        'index': i + 1,
                        'topic': topic,
                        'content': content,
                        'filename': content_filename,
                        'length': len(content)
                    }
                    content_list.append(content_data)
                    
                    generated_count += 1
                    print(f"[æ‰¹é‡æ–‡æ¡ˆç”Ÿæˆå™¨] âœ“ å®Œæˆ: {topic} ({len(content)}å­—)")
                    
                    # é¿å…APIé™åˆ¶ï¼Œæ·»åŠ å°å»¶è¿Ÿ
                    time.sleep(0.5)
                    
                except Exception as e:
                    failed_topics.append(f"{topic}: {str(e)}")
                    print(f"[æ‰¹é‡æ–‡æ¡ˆç”Ÿæˆå™¨] âœ— å¤±è´¥: {topic} - {str(e)}")
            
            # ä¿å­˜å†…å®¹ç´¢å¼•æ–‡ä»¶
            index_file = os.path.join(output_folder, "content_index.json")
            with open(index_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'generated_time': timestamp,
                    'total_count': len(topic_list),
                    'success_count': generated_count,
                    'failed_count': len(failed_topics),
                    'model_info': {
                        'model': model,
                        'temperature': temperature,
                        'max_length': max_length
                    },
                    'contents': content_list,
                    'failed_topics': failed_topics
                }, f, indent=2, ensure_ascii=False)
            
            # ç”Ÿæˆæ‘˜è¦
            summary = f"æ–‡æ¡ˆç”Ÿæˆå®Œæˆ: æˆåŠŸ {generated_count}/{len(topic_list)} ä¸ª"
            if failed_topics:
                summary += f", å¤±è´¥ {len(failed_topics)} ä¸ª"
            
            total_chars = sum(len(content['content']) for content in content_list)
            avg_chars = total_chars // generated_count if generated_count > 0 else 0
            summary += f", å¹³å‡é•¿åº¦ {avg_chars} å­—"
            
            print(f"[æ‰¹é‡æ–‡æ¡ˆç”Ÿæˆå™¨] {summary}")
            
            return io.NodeOutput(output_folder, generated_count, summary)
            
        except Exception as e:
            error_msg = f"æ‰¹é‡æ–‡æ¡ˆç”Ÿæˆå™¨æ‰§è¡Œå¤±è´¥: {str(e)}"
            print(f"[æ‰¹é‡æ–‡æ¡ˆç”Ÿæˆå™¨] é”™è¯¯: {error_msg}")
            # åˆ›å»ºç©ºçš„è§†é¢‘å¯¹è±¡
            import io as python_io
            error_video = VideoFromFile(python_io.BytesIO(b''))
            return io.NodeOutput("", 0, error_msg, "", error_video)


class BatchTTSGenerator(io.ComfyNode):
    """æ‰¹é‡TTSç”Ÿæˆå™¨ - æ‰¹é‡TTSè¯­éŸ³åˆæˆ"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="BatchTTSGenerator",
            display_name="æ‰¹é‡TTSç”Ÿæˆå™¨", 
            category="batch_video",
            description="æ‰¹é‡TTSè¯­éŸ³åˆæˆ",
            inputs=[
                # å†…å®¹è¾“å…¥
                io.String.Input("content_folder", tooltip="æ–‡æ¡ˆæ–‡ä»¶å¤¹è·¯å¾„"),
                
                # TTSå¼•æ“é€‰æ‹©
                io.Combo.Input("tts_engine", 
                               options=["IndexTTS", "OpenAI-TTS"], 
                               default="OpenAI-TTS", tooltip="TTSå¼•æ“"),
                
                # IndexTTSé…ç½®
                io.String.Input("speaker_audio", optional=True, tooltip="è¯´è¯äººéŸ³é¢‘æ–‡ä»¶è·¯å¾„(IndexTTS)"),
                io.Float.Input("temperature", default=0.8, tooltip="éšæœºæ€§(IndexTTS)"),
                io.Int.Input("max_mel_tokens", default=1500, tooltip="æœ€å¤§é•¿åº¦(IndexTTS)"),
                io.Boolean.Input("enable_emotion", default=False, tooltip="å¯ç”¨æƒ…ç»ªæ§åˆ¶(IndexTTS)"),
                io.String.Input("emotion_text", default="", tooltip="æƒ…ç»ªæç¤ºè¯(IndexTTS)"),
                
                # OpenAI TTSé…ç½®
                io.String.Input("openai_voice", default="alloy", tooltip="OpenAIè¯­éŸ³"),
                io.String.Input("openai_model", default="tts-1", tooltip="OpenAIæ¨¡å‹"),
                io.String.Input("openai_api_key", optional=True, tooltip="OpenAI APIå¯†é’¥"),
                io.String.Input("openai_base_url", optional=True, tooltip="OpenAI APIåœ°å€"),
                
                io.String.Input("output_prefix", default="æ‰¹é‡TTS", tooltip="è¾“å‡ºå‰ç¼€"),
            ],
            outputs=[
                io.String.Output("audio_folder", display_name="éŸ³é¢‘æ–‡ä»¶å¤¹"),
                io.Int.Output("generated_count", display_name="ç”Ÿæˆæ•°é‡"),
                io.String.Output("summary", display_name="TTSæ‘˜è¦"),
            ],
        )
    
    @classmethod
    def execute(cls, content_folder, tts_engine="OpenAI-TTS", 
                speaker_audio=None, temperature=0.8, max_mel_tokens=1500, 
                enable_emotion=False, emotion_text="",
                openai_voice="alloy", openai_model="tts-1", 
                openai_api_key=None, openai_base_url=None,
                output_prefix="æ‰¹é‡TTS"):
        import os
        import time
        import json
        from pathlib import Path
        
        try:
            # éªŒè¯å†…å®¹æ–‡ä»¶å¤¹
            if not os.path.exists(content_folder):
                raise ValueError(f"æ–‡æ¡ˆæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {content_folder}")
            
            # è¯»å–æ–‡æ¡ˆæ–‡ä»¶
            content_files = []
            for file in os.listdir(content_folder):
                if file.endswith('.txt') and file.startswith('content_'):
                    content_files.append(os.path.join(content_folder, file))
            
            if not content_files:
                raise ValueError(f"åœ¨æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°æ–‡æ¡ˆæ–‡ä»¶: {content_folder}")
            
            # æŒ‰æ–‡ä»¶åæ’åºç¡®ä¿é¡ºåº
            content_files.sort()
            
            # è¯»å–å†…å®¹ç´¢å¼•æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            content_data_list = []
            index_file = os.path.join(content_folder, "content_index.json")
            if os.path.exists(index_file):
                with open(index_file, 'r', encoding='utf-8') as f:
                    index_data = json.load(f)
                    content_data_list = index_data.get('contents', [])
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
            timestamp = int(time.time())
            output_folder = os.path.join(folder_paths.get_temp_directory(), f"{output_prefix}_{timestamp}")
            os.makedirs(output_folder, exist_ok=True)
            
            generated_count = 0
            failed_files = []
            audio_info_list = []
            
            print(f"[æ‰¹é‡TTSç”Ÿæˆå™¨] å¼€å§‹å¤„ç† {len(content_files)} ä¸ªæ–‡æ¡ˆæ–‡ä»¶")
            print(f"[æ‰¹é‡TTSç”Ÿæˆå™¨] ä½¿ç”¨TTSå¼•æ“: {tts_engine}")
            
            # æ‰¹é‡ç”Ÿæˆè¯­éŸ³
            for i, content_file in enumerate(content_files):
                try:
                    # è¯»å–æ–‡æ¡ˆå†…å®¹
                    with open(content_file, 'r', encoding='utf-8') as f:
                        content_text = f.read().strip()
                    
                    if not content_text:
                        print(f"[æ‰¹é‡TTSç”Ÿæˆå™¨] âš ï¸ è·³è¿‡ç©ºæ–‡æ¡ˆ: {os.path.basename(content_file)}")
                        continue
                    
                    # è·å–å¯¹åº”çš„å†…å®¹æ•°æ®
                    content_data = None
                    if i < len(content_data_list):
                        content_data = content_data_list[i]
                    
                    file_basename = Path(content_file).stem
                    audio_filename = f"tts_{i+1:03d}.wav"
                    audio_path = os.path.join(output_folder, audio_filename)
                    
                    print(f"[æ‰¹é‡TTSç”Ÿæˆå™¨] ç”Ÿæˆè¯­éŸ³ {i+1}/{len(content_files)}: {file_basename}")
                    
                    # æ ¹æ®é€‰æ‹©çš„å¼•æ“ç”Ÿæˆè¯­éŸ³
                    if tts_engine == "IndexTTS":
                        success = cls._generate_indexts_audio(
                            content_text, audio_path, speaker_audio, 
                            temperature, max_mel_tokens, enable_emotion, emotion_text
                        )
                    else:  # OpenAI-TTS
                        success = cls._generate_openai_tts_audio(
                            content_text, audio_path, openai_voice, openai_model,
                            openai_api_key, openai_base_url
                        )
                    
                    if success:
                        # è·å–éŸ³é¢‘æ—¶é•¿
                        audio_duration = cls._get_audio_duration(audio_path)
                        
                        audio_info = {
                            'index': i + 1,
                            'content_file': os.path.basename(content_file),
                            'audio_file': audio_filename,
                            'content_length': len(content_text),
                            'audio_duration': audio_duration,
                            'content_data': content_data
                        }
                        audio_info_list.append(audio_info)
                        
                        generated_count += 1
                        print(f"[æ‰¹é‡TTSç”Ÿæˆå™¨] âœ“ å®Œæˆ: {audio_filename} ({audio_duration:.1f}s)")
                    else:
                        failed_files.append(os.path.basename(content_file))
                        print(f"[æ‰¹é‡TTSç”Ÿæˆå™¨] âœ— å¤±è´¥: {file_basename}")
                        
                except Exception as e:
                    failed_files.append(os.path.basename(content_file))
                    print(f"[æ‰¹é‡TTSç”Ÿæˆå™¨] âœ— å¤„ç†å¤±è´¥: {os.path.basename(content_file)} - {str(e)}")
            
            # ä¿å­˜éŸ³é¢‘ç´¢å¼•æ–‡ä»¶
            audio_index_file = os.path.join(output_folder, "audio_index.json")
            with open(audio_index_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'generated_time': timestamp,
                    'tts_engine': tts_engine,
                    'total_count': len(content_files),
                    'success_count': generated_count,
                    'failed_count': len(failed_files),
                    'engine_config': {
                        'tts_engine': tts_engine,
                        'openai_voice': openai_voice if tts_engine == "OpenAI-TTS" else None,
                        'speaker_audio': speaker_audio if tts_engine == "IndexTTS" else None
                    },
                    'audio_info': audio_info_list,
                    'failed_files': failed_files
                }, f, indent=2, ensure_ascii=False)
            
            # ç”Ÿæˆæ‘˜è¦
            summary = f"TTSç”Ÿæˆå®Œæˆ: æˆåŠŸ {generated_count}/{len(content_files)} ä¸ª"
            if failed_files:
                summary += f", å¤±è´¥ {len(failed_files)} ä¸ª"
            
            if audio_info_list:
                avg_duration = sum(info['audio_duration'] for info in audio_info_list) / len(audio_info_list)
                summary += f", å¹³å‡æ—¶é•¿ {avg_duration:.1f}s"
            
            print(f"[æ‰¹é‡TTSç”Ÿæˆå™¨] {summary}")
            
            return io.NodeOutput(output_folder, generated_count, summary)
            
        except Exception as e:
            error_msg = f"æ‰¹é‡TTSç”Ÿæˆå™¨æ‰§è¡Œå¤±è´¥: {str(e)}"
            print(f"[æ‰¹é‡TTSç”Ÿæˆå™¨] é”™è¯¯: {error_msg}")
            # åˆ›å»ºç©ºçš„è§†é¢‘å¯¹è±¡
            import io as python_io
            error_video = VideoFromFile(python_io.BytesIO(b''))
            return io.NodeOutput("", 0, error_msg, "", error_video)
    
    @classmethod
    def _generate_indexts_audio(cls, text, output_path, speaker_audio, temperature, max_mel_tokens, enable_emotion, emotion_text):
        """ä½¿ç”¨IndexTTSç”ŸæˆéŸ³é¢‘"""
        try:
            # è¿™é‡Œéœ€è¦è°ƒç”¨IndexTTSçš„æ¥å£
            # ç”±äºIndexTTSå¯èƒ½æ²¡æœ‰å®‰è£…ï¼Œå…ˆè¿”å›Falseè¡¨ç¤ºä¸æ”¯æŒ
            print(f"[æ‰¹é‡TTSç”Ÿæˆå™¨] IndexTTSæš‚æœªé›†æˆï¼Œè¯·ä½¿ç”¨OpenAI-TTS")
            return False
        except Exception as e:
            print(f"[æ‰¹é‡TTSç”Ÿæˆå™¨] IndexTTSç”Ÿæˆå¤±è´¥: {str(e)}")
            return False
    
    @classmethod
    def _generate_openai_tts_audio(cls, text, output_path, voice, model, api_key, base_url):
        """ä½¿ç”¨OpenAI TTSç”ŸæˆéŸ³é¢‘"""
        try:
            import torchaudio
            from openai import OpenAI
            
            # é…ç½®API
            if api_key:
                client_api_key = api_key
            else:
                import os
                client_api_key = os.environ.get("OPENAI_API_KEY")
                if not client_api_key:
                    raise ValueError("æœªæä¾›OpenAI APIå¯†é’¥")
            
            if base_url:
                client_base_url = base_url if base_url.endswith('/') else base_url + '/'
            else:
                client_base_url = "https://api.openai.com/v1/"
            
            # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
            client = OpenAI(
                api_key=client_api_key,
                base_url=client_base_url
            )
            
            # è°ƒç”¨TTS API
            response = client.audio.speech.create(
                model=model,
                voice=voice,
                input=text
            )
            
            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            with open(output_path, "wb") as f:
                f.write(response.content)
            
            return os.path.exists(output_path) and os.path.getsize(output_path) > 0
            
        except Exception as e:
            print(f"[æ‰¹é‡TTSç”Ÿæˆå™¨] OpenAI TTSç”Ÿæˆå¤±è´¥: {str(e)}")
            return False
    
    @classmethod
    def _get_audio_duration(cls, audio_path):
        """è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿"""
        try:
            import torchaudio
            waveform, sample_rate = torchaudio.load(audio_path)
            duration = waveform.shape[1] / sample_rate
            return float(duration)
        except Exception as e:
            print(f"[æ‰¹é‡TTSç”Ÿæˆå™¨] è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {str(e)}")
            return 0.0


class SmartVideoCutterWithAudio(io.ComfyNode):
    """æ™ºèƒ½è§†é¢‘è£åˆ‡å™¨å¸¦éŸ³é¢‘èåˆ - ä¸€å¯¹ä¸€å¤„ç†ç¡®ä¿ä¸æ··ä¹±"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="SmartVideoCutterWithAudio",
            display_name="ğŸ§ éŸ³é¢‘æ—¶é•¿åŒ¹é…å™¨",
            category="batch_video", 
            description="æŒ‰éŸ³é¢‘æ—¶é•¿è£åˆ‡è§†é¢‘å¹¶ç›´æ¥èåˆéŸ³é¢‘ï¼Œç¡®ä¿ä¸€ä¸€å¯¹åº”",
            inputs=[
                # è¾“å…¥æº
                io.String.Input("video_folder", tooltip="è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„"),
                io.String.Input("audio_folder", tooltip="TTSéŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„"),
                
                # è£åˆ‡ç­–ç•¥
                io.Combo.Input("video_selection", 
                               options=["é¡ºåºå¾ªç¯", "éšæœºé€‰æ‹©", "æŒ‰åç§°åŒ¹é…"], 
                               default="é¡ºåºå¾ªç¯", tooltip="è§†é¢‘é€‰æ‹©ç­–ç•¥"),
                io.Boolean.Input("skip_short_videos", default=True, tooltip="è·³è¿‡è¿‡çŸ­è§†é¢‘"),
                io.Float.Input("min_video_duration", default=10.0, tooltip="æœ€å°è§†é¢‘æ—¶é•¿è¦æ±‚"),
                
                # éŸ³é¢‘èåˆé…ç½®
                io.Boolean.Input("enable_audio_mix", default=True, tooltip="å¯ç”¨éŸ³é¢‘èåˆ"),
                io.Float.Input("tts_volume", default=90.0, tooltip="TTSéŸ³é‡ (0-100)"),
                io.Float.Input("original_volume", default=20.0, tooltip="åŸè§†é¢‘éŸ³é‡ (0-100)"),
                io.Float.Input("bg_music_volume", default=30.0, tooltip="èƒŒæ™¯éŸ³ä¹éŸ³é‡ (0-100)"),
                io.String.Input("bg_music_folder", optional=True, tooltip="èƒŒæ™¯éŸ³ä¹æ–‡ä»¶å¤¹(å¯é€‰)"),
                
                io.String.Input("output_prefix", default="æ™ºèƒ½è£åˆ‡", tooltip="è¾“å‡ºå‰ç¼€"),
            ],
            outputs=[
                io.String.Output("output_folder", display_name="è¾“å‡ºæ–‡ä»¶å¤¹"),
                io.Int.Output("processed_count", display_name="å¤„ç†æ•°é‡"),
                io.String.Output("pairing_info", display_name="é…å¯¹ä¿¡æ¯"),
                io.String.Output("summary", display_name="å¤„ç†æ‘˜è¦"),
            ],
        )
    
    @classmethod
    def execute(cls, video_folder, audio_folder, video_selection="é¡ºåºå¾ªç¯", 
                skip_short_videos=True, min_video_duration=10.0,
                enable_audio_mix=True, tts_volume=90.0, original_volume=20.0, 
                bg_music_volume=30.0, bg_music_folder=None, output_prefix="æ™ºèƒ½è£åˆ‡"):
        import os
        import time
        import json
        import random
        from pathlib import Path
        from .utils import scan_media_files
        import ffmpeg
        
        try:
            # 1. éªŒè¯è¾“å…¥æ–‡ä»¶å¤¹
            if not os.path.exists(video_folder):
                raise ValueError(f"è§†é¢‘æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {video_folder}")
            if not os.path.exists(audio_folder):
                raise ValueError(f"éŸ³é¢‘æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {audio_folder}")
            
            # 2. æ‰«æéŸ³é¢‘å’Œè§†é¢‘æ–‡ä»¶
            audio_files = scan_media_files(audio_folder, ['audio'])['audio']
            video_files = scan_media_files(video_folder, ['video'])['video']
            bg_music_files = []
            if bg_music_folder and os.path.exists(bg_music_folder):
                bg_music_files = scan_media_files(bg_music_folder, ['audio'])['audio']
            
            if not audio_files:
                raise ValueError(f"æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶: {audio_folder}")
            if not video_files:
                raise ValueError(f"æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {video_folder}")
            
            # æŒ‰æ–‡ä»¶åæ’åºï¼Œç¡®ä¿TTSéŸ³é¢‘çš„é¡ºåº
            audio_files.sort(key=lambda x: os.path.basename(x))
            
            print(f"[æ™ºèƒ½è§†é¢‘è£åˆ‡+éŸ³é¢‘èåˆå™¨] æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
            print(f"[æ™ºèƒ½è§†é¢‘è£åˆ‡+éŸ³é¢‘èåˆå™¨] æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
            if bg_music_files:
                print(f"[æ™ºèƒ½è§†é¢‘è£åˆ‡+éŸ³é¢‘èåˆå™¨] æ‰¾åˆ° {len(bg_music_files)} ä¸ªèƒŒæ™¯éŸ³ä¹")
            
            # 3. å»ºç«‹è§†é¢‘-éŸ³é¢‘é…å¯¹å…³ç³»
            video_audio_pairs = cls._create_video_audio_pairs(
                video_files, audio_files, video_selection
            )
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
            timestamp = int(time.time())
            output_folder = os.path.join(folder_paths.get_temp_directory(), f"{output_prefix}_{timestamp}")
            os.makedirs(output_folder, exist_ok=True)
            
            processed_count = 0
            failed_count = 0
            pairing_info_list = []
            
            print(f"[æ™ºèƒ½è§†é¢‘è£åˆ‡+éŸ³é¢‘èåˆå™¨] å¼€å§‹å¤„ç† {len(video_audio_pairs)} ä¸ªé…å¯¹")
            
            # 4. é€ä¸ªå¤„ç†æ¯ä¸ªé…å¯¹
            for i, (video_file, audio_file) in enumerate(video_audio_pairs):
                try:
                    # è·å–éŸ³é¢‘æ—¶é•¿ä½œä¸ºè£åˆ‡æ—¶é•¿
                    audio_duration = cls._get_audio_duration(audio_file)
                    video_duration = cls._get_video_duration(video_file)
                    
                    audio_name = Path(audio_file).stem
                    video_name = Path(video_file).stem
                    
                    print(f"[æ™ºèƒ½è§†é¢‘è£åˆ‡+éŸ³é¢‘èåˆå™¨] å¤„ç†é…å¯¹ {i+1}/{len(video_audio_pairs)}")
                    print(f"  éŸ³é¢‘: {os.path.basename(audio_file)} ({audio_duration:.1f}s)")
                    print(f"  è§†é¢‘: {os.path.basename(video_file)} ({video_duration:.1f}s)")
                    
                    # æ£€æŸ¥è§†é¢‘æ˜¯å¦å¤Ÿé•¿
                    if skip_short_videos and video_duration < max(audio_duration, min_video_duration):
                        print(f"  âš ï¸ è·³è¿‡è¿‡çŸ­è§†é¢‘: {video_name}")
                        continue
                    
                    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                    output_filename = f"{output_prefix}_{audio_name}.mp4"
                    output_path = os.path.join(output_folder, output_filename)
                    
                    # è®°å½•é…å¯¹ä¿¡æ¯
                    pairing_info = {
                        'index': i + 1,
                        'audio_file': os.path.basename(audio_file),
                        'video_file': os.path.basename(video_file),
                        'audio_duration': audio_duration,
                        'video_duration': video_duration,
                        'output_file': output_filename
                    }
                    
                    # 5. æ‰§è¡Œè£åˆ‡+éŸ³é¢‘èåˆ
                    success = cls._process_single_video_audio_pair(
                        video_file, audio_file, output_path, audio_duration,
                        enable_audio_mix, tts_volume, original_volume, bg_music_volume,
                        bg_music_files
                    )
                    
                    if success:
                        processed_count += 1
                        pairing_info['status'] = 'success'
                        print(f"  âœ“ å®Œæˆ: {output_filename}")
                    else:
                        failed_count += 1
                        pairing_info['status'] = 'failed'
                        print(f"  âœ— å¤±è´¥: {output_filename}")
                    
                    pairing_info_list.append(pairing_info)
                        
                except Exception as e:
                    failed_count += 1
                    print(f"  âœ— å¤„ç†å¤±è´¥: {os.path.basename(audio_file)} - {str(e)}")
                    pairing_info_list.append({
                        'index': i + 1,
                        'audio_file': os.path.basename(audio_file),
                        'video_file': os.path.basename(video_file),
                        'status': 'error',
                        'error': str(e)
                    })
            
            # ä¿å­˜é…å¯¹ä¿¡æ¯æ–‡ä»¶
            pairing_file = os.path.join(output_folder, "pairing_info.json")
            with open(pairing_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'generated_time': timestamp,
                    'total_pairs': len(video_audio_pairs),
                    'success_count': processed_count,
                    'failed_count': failed_count,
                    'config': {
                        'video_selection': video_selection,
                        'enable_audio_mix': enable_audio_mix,
                        'tts_volume': tts_volume,
                        'original_volume': original_volume,
                        'bg_music_volume': bg_music_volume
                    },
                    'pairings': pairing_info_list
                }, f, indent=2, ensure_ascii=False)
            
            # ç”Ÿæˆé…å¯¹ä¿¡æ¯æ‘˜è¦
            pairing_summary = cls._format_pairing_summary(pairing_info_list[:5])  # æ˜¾ç¤ºå‰5ä¸ª
            summary = f"å¤„ç†å®Œæˆ: æˆåŠŸ {processed_count}/{len(video_audio_pairs)} ä¸ªè§†é¢‘"
            if failed_count > 0:
                summary += f", å¤±è´¥ {failed_count} ä¸ª"
            
            print(f"[æ™ºèƒ½è§†é¢‘è£åˆ‡+éŸ³é¢‘èåˆå™¨] {summary}")
            
            return io.NodeOutput(output_folder, processed_count, pairing_summary, summary)
            
        except Exception as e:
            error_msg = f"æ™ºèƒ½è§†é¢‘è£åˆ‡+éŸ³é¢‘èåˆå™¨æ‰§è¡Œå¤±è´¥: {str(e)}"
            print(f"[æ™ºèƒ½è§†é¢‘è£åˆ‡+éŸ³é¢‘èåˆå™¨] é”™è¯¯: {error_msg}")
            return io.NodeOutput("", 0, "", error_msg)
    
    @classmethod
    def _create_video_audio_pairs(cls, video_files, audio_files, selection_strategy):
        """åˆ›å»ºè§†é¢‘-éŸ³é¢‘é…å¯¹"""
        pairs = []
        
        if selection_strategy == "é¡ºåºå¾ªç¯":
            # è§†é¢‘å¾ªç¯ä½¿ç”¨ï¼Œæ¯ä¸ªéŸ³é¢‘å¯¹åº”ä¸€ä¸ªè§†é¢‘
            for i, audio_file in enumerate(audio_files):
                video_file = video_files[i % len(video_files)]
                pairs.append((video_file, audio_file))
        
        elif selection_strategy == "éšæœºé€‰æ‹©":
            # æ¯ä¸ªéŸ³é¢‘éšæœºé€‰æ‹©ä¸€ä¸ªè§†é¢‘
            for audio_file in audio_files:
                video_file = random.choice(video_files)
                pairs.append((video_file, audio_file))
        
        elif selection_strategy == "æŒ‰åç§°åŒ¹é…":
            # å°è¯•æŒ‰æ–‡ä»¶ååŒ¹é…ï¼ŒåŒ¹é…ä¸ä¸Šçš„ç”¨å¾ªç¯
            for i, audio_file in enumerate(audio_files):
                audio_name = Path(audio_file).stem
                matched_video = None
                
                # å¯»æ‰¾åç§°ç›¸ä¼¼çš„è§†é¢‘
                for video_file in video_files:
                    video_name = Path(video_file).stem
                    if audio_name in video_name or video_name in audio_name:
                        matched_video = video_file
                        break
                
                # æ²¡åŒ¹é…ä¸Šå°±ç”¨å¾ªç¯ç­–ç•¥
                if not matched_video:
                    matched_video = video_files[i % len(video_files)]
                
                pairs.append((matched_video, audio_file))
        
        return pairs
    
    @classmethod
    def _process_single_video_audio_pair(cls, video_file, audio_file, output_path, duration,
                                       enable_audio_mix, tts_vol, orig_vol, bg_vol, bg_music_files):
        """å¤„ç†å•ä¸ªè§†é¢‘-éŸ³é¢‘é…å¯¹"""
        try:
            import ffmpeg
            
            # åˆ›å»ºè§†é¢‘è¾“å…¥æµï¼ŒæŒ‰éŸ³é¢‘æ—¶é•¿è£åˆ‡
            video_input = ffmpeg.input(video_file, t=duration)
            
            if not enable_audio_mix:
                # ç®€å•æ›¿æ¢ï¼šåªç”¨TTSéŸ³é¢‘
                audio_input = ffmpeg.input(audio_file)
                (
                    ffmpeg
                    .output(video_input.video, audio_input.audio, output_path,
                           vcodec='libx264', acodec='aac', preset='fast')
                    .overwrite_output()
                    .run(quiet=True)
                )
            else:
                # å¤æ‚æ··éŸ³ï¼šTTS + åŸè§†é¢‘éŸ³é¢‘ + èƒŒæ™¯éŸ³ä¹
                tts_input = ffmpeg.input(audio_file)
                
                # è°ƒæ•´TTSéŸ³é‡
                tts_audio = tts_input.audio.filter('volume', tts_vol/100.0)
                
                # è°ƒæ•´åŸè§†é¢‘éŸ³é‡
                orig_audio = video_input.audio.filter('volume', orig_vol/100.0)
                
                # æ··åˆTTSå’ŒåŸéŸ³é¢‘
                mixed_audio = ffmpeg.filter([tts_audio, orig_audio], 'amix', inputs=2, duration='longest')
                
                # å¦‚æœæœ‰èƒŒæ™¯éŸ³ä¹ï¼Œå†æ··å…¥
                if bg_music_files and bg_vol > 0:
                    bg_music = random.choice(bg_music_files)
                    bg_input = ffmpeg.input(bg_music, stream_loop=-1, t=duration)
                    bg_audio = bg_input.audio.filter('volume', bg_vol/100.0)
                    mixed_audio = ffmpeg.filter([mixed_audio, bg_audio], 'amix', inputs=2, duration='first')
                
                (
                    ffmpeg
                    .output(video_input.video, mixed_audio, output_path,
                           vcodec='libx264', acodec='aac', preset='fast')
                    .overwrite_output()
                    .run(quiet=True)
                )
            
            return os.path.exists(output_path) and os.path.getsize(output_path) > 0
            
        except Exception as e:
            print(f"[æ™ºèƒ½è§†é¢‘è£åˆ‡+éŸ³é¢‘èåˆå™¨] FFmpegå¤„ç†å¤±è´¥: {str(e)}")
            return False
    
    @classmethod
    def _get_audio_duration(cls, audio_path):
        """è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿"""
        try:
            import ffmpeg
            probe = ffmpeg.probe(audio_path)
            duration = float(probe['streams'][0]['duration'])
            return duration
        except Exception as e:
            print(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {str(e)}")
            return 0.0
    
    @classmethod
    def _get_video_duration(cls, video_path):
        """è·å–è§†é¢‘æ–‡ä»¶æ—¶é•¿"""
        try:
            import ffmpeg
            probe = ffmpeg.probe(video_path)
            duration = float(probe['streams'][0]['duration'])
            return duration
        except Exception as e:
            print(f"è·å–è§†é¢‘æ—¶é•¿å¤±è´¥: {str(e)}")
            return 0.0
    
    @classmethod
    def _format_pairing_summary(cls, pairing_list):
        """æ ¼å¼åŒ–é…å¯¹ä¿¡æ¯æ‘˜è¦"""
        if not pairing_list:
            return "æ— é…å¯¹ä¿¡æ¯"
        
        summary_lines = ["é…å¯¹ä¿¡æ¯ (å‰5ä¸ª):"]
        for pair in pairing_list:
            status_icon = "âœ“" if pair.get('status') == 'success' else "âœ—"
            audio_name = pair.get('audio_file', 'unknown')
            video_name = pair.get('video_file', 'unknown')
            duration = pair.get('audio_duration', 0)
            summary_lines.append(f"{status_icon} {audio_name} + {video_name} ({duration:.1f}s)")
        
        return "\n".join(summary_lines)


class BatchVideoCropper(io.ComfyNode):
    """æ‰¹é‡è§†é¢‘è£å‰ªå™¨ - æ”¯æŒå®æ—¶é¢„è§ˆå’Œæ™ºèƒ½è£å‰ª"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="BatchVideoCropper",
            display_name="æ‰¹é‡è§†é¢‘è£å‰ªå™¨",
            category="batch_video",
            description="æ‰¹é‡è£å‰ªè§†é¢‘ï¼Œæ”¯æŒç«–å±è½¬æ¨ªå±ï¼Œæä¾›å®æ—¶é¢„è§ˆåŠŸèƒ½",
            inputs=[
                io.String.Input("video_folder", tooltip="è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„"),
                
                # è£å‰ªæ¨¡å¼é€‰æ‹©
                io.Combo.Input("crop_mode", 
                               options=["æ™ºèƒ½å±…ä¸­", "é¡¶éƒ¨å¯¹é½", "åº•éƒ¨å¯¹é½", "å·¦ä¾§å¯¹é½", "å³ä¾§å¯¹é½", "è‡ªå®šä¹‰"], 
                               default="æ™ºèƒ½å±…ä¸­", 
                               tooltip="è£å‰ªæ¨¡å¼"),
                
                # ç›®æ ‡å°ºå¯¸
                io.Int.Input("target_width", default=1920, tooltip="ç›®æ ‡å®½åº¦"),
                io.Int.Input("target_height", default=1080, tooltip="ç›®æ ‡é«˜åº¦"),
                
                # è‡ªå®šä¹‰è£å‰ªå‚æ•°
                io.Float.Input("crop_x", default=0.0, tooltip="è£å‰ªXèµ·ç‚¹ï¼ˆæ¯”ä¾‹0-1ï¼‰"),
                io.Float.Input("crop_y", default=0.0, tooltip="è£å‰ªYèµ·ç‚¹ï¼ˆæ¯”ä¾‹0-1ï¼‰"),
                io.Float.Input("crop_width", default=1.0, tooltip="è£å‰ªå®½åº¦ï¼ˆæ¯”ä¾‹0-1ï¼‰"),
                io.Float.Input("crop_height", default=1.0, tooltip="è£å‰ªé«˜åº¦ï¼ˆæ¯”ä¾‹0-1ï¼‰"),
                
                # é¢„è§ˆå’Œå¤„ç†é€‰é¡¹
                io.Boolean.Input("generate_preview", default=True, tooltip="ç”Ÿæˆé¢„è§ˆå›¾ç‰‡"),
                io.String.Input("output_prefix", default="è£å‰ª", tooltip="è¾“å‡ºæ–‡ä»¶åå‰ç¼€"),
            ],
            outputs=[
                io.String.Output("output_folder", display_name="è¾“å‡ºæ–‡ä»¶å¤¹"),
                io.String.Output("preview_image", display_name="é¢„è§ˆå›¾ç‰‡è·¯å¾„"),
                io.Int.Output("processed_count", display_name="å¤„ç†æ•°é‡"),
                io.String.Output("crop_info", display_name="è£å‰ªä¿¡æ¯"),
                io.String.Output("summary", display_name="å¤„ç†æ‘˜è¦"),
            ],
        )
    
    @classmethod
    def execute(cls, video_folder, crop_mode="æ™ºèƒ½å±…ä¸­", target_width=1920, target_height=1080,
                crop_x=0.0, crop_y=0.0, crop_width=1.0, crop_height=1.0,
                generate_preview=True, output_prefix="è£å‰ª"):
        import os
        import time
        from pathlib import Path
        from .utils import scan_media_files
        import ffmpeg
        
        try:
            # éªŒè¯è¾“å…¥æ–‡ä»¶å¤¹
            if not os.path.exists(video_folder):
                raise ValueError(f"è§†é¢‘æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {video_folder}")
            
            # æ‰«æè§†é¢‘æ–‡ä»¶
            video_files = scan_media_files(video_folder, file_types=['video']).get('video', [])
            if not video_files:
                raise ValueError(f"åœ¨æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {video_folder}")
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
            timestamp = int(time.time())
            output_folder = os.path.join(folder_paths.get_temp_directory(), f"{output_prefix}_è§†é¢‘è£å‰ª_{timestamp}")
            os.makedirs(output_folder, exist_ok=True)
            
            # è·å–ç¬¬ä¸€ä¸ªè§†é¢‘çš„ä¿¡æ¯ç”¨äºè®¡ç®—è£å‰ªå‚æ•°
            first_video = video_files[0]
            probe = ffmpeg.probe(first_video)
            video_stream = next(s for s in probe['streams'] if s['codec_type'] == 'video')
            original_width = int(video_stream['width'])
            original_height = int(video_stream['height'])
            
            print(f"[æ‰¹é‡è§†é¢‘è£å‰ªå™¨] åŸå§‹å°ºå¯¸: {original_width}x{original_height}")
            print(f"[æ‰¹é‡è§†é¢‘è£å‰ªå™¨] ç›®æ ‡å°ºå¯¸: {target_width}x{target_height}")
            print(f"[æ‰¹é‡è§†é¢‘è£å‰ªå™¨] è£å‰ªæ¨¡å¼: {crop_mode}")
            
            # è®¡ç®—è£å‰ªå‚æ•°
            if crop_mode == "è‡ªå®šä¹‰":
                final_crop_x = crop_x
                final_crop_y = crop_y
                final_crop_w = crop_width
                final_crop_h = crop_height
            else:
                final_crop_x, final_crop_y, final_crop_w, final_crop_h = cls._calculate_smart_crop(
                    original_width, original_height, target_width, target_height, crop_mode
                )
            
            # è½¬æ¢ä¸ºåƒç´ åæ ‡
            crop_x_px = int(final_crop_x * original_width)
            crop_y_px = int(final_crop_y * original_height)
            crop_w_px = int(final_crop_w * original_width)
            crop_h_px = int(final_crop_h * original_height)
            
            crop_info = f"""è£å‰ªå‚æ•°:
èµ·ç‚¹: ({crop_x_px}, {crop_y_px})
å°ºå¯¸: {crop_w_px}x{crop_h_px}
æ¯”ä¾‹: {final_crop_x:.2f}, {final_crop_y:.2f}, {final_crop_w:.2f}, {final_crop_h:.2f}"""
            
            print(f"[æ‰¹é‡è§†é¢‘è£å‰ªå™¨] {crop_info}")
            
            # ç”Ÿæˆé¢„è§ˆå›¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            preview_image_path = ""
            if generate_preview:
                preview_image_path = cls._generate_preview(
                    first_video, output_folder, crop_x_px, crop_y_px, 
                    crop_w_px, crop_h_px, target_width, target_height
                )
            
            # æ‰¹é‡å¤„ç†è§†é¢‘
            processed_count = 0
            failed_files = []
            
            print(f"[æ‰¹é‡è§†é¢‘è£å‰ªå™¨] å¼€å§‹å¤„ç† {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
            
            for video_file in video_files:
                try:
                    video_name = Path(video_file).stem
                    output_filename = f"{video_name}_{output_prefix}.mp4"
                    output_path = os.path.join(output_folder, output_filename)
                    
                    print(f"[æ‰¹é‡è§†é¢‘è£å‰ªå™¨] å¤„ç†: {video_name}")
                    
                    # ä½¿ç”¨FFmpegè¿›è¡Œè£å‰ªå’Œç¼©æ”¾
                    (
                        ffmpeg
                        .input(video_file)
                        .filter('crop', crop_w_px, crop_h_px, crop_x_px, crop_y_px)
                        .filter('scale', target_width, target_height)
                        .output(
                            output_path,
                            vcodec='libx264',
                            acodec='aac',
                            preset='fast',
                            **{'profile:v': 'main'}
                        )
                        .overwrite_output()
                        .run(quiet=True)
                    )
                    
                    # éªŒè¯è¾“å‡ºæ–‡ä»¶
                    if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                        processed_count += 1
                        print(f"[æ‰¹é‡è§†é¢‘è£å‰ªå™¨] å®Œæˆ: {output_filename}")
                    else:
                        failed_files.append(video_name)
                        print(f"[æ‰¹é‡è§†é¢‘è£å‰ªå™¨] å¤±è´¥: {video_name} (è¾“å‡ºæ–‡ä»¶æ— æ•ˆ)")
                        
                except Exception as e:
                    failed_files.append(video_name)
                    print(f"[æ‰¹é‡è§†é¢‘è£å‰ªå™¨] å¤„ç†å¤±è´¥: {video_name}, é”™è¯¯: {str(e)}")
            
            # ç”Ÿæˆæ‘˜è¦
            summary = f"è§†é¢‘è£å‰ªå®Œæˆ: æˆåŠŸ {processed_count}/{len(video_files)} ä¸ªæ–‡ä»¶"
            if failed_files:
                summary += f", å¤±è´¥: {len(failed_files)} ä¸ªæ–‡ä»¶"
            
            print(f"[æ‰¹é‡è§†é¢‘è£å‰ªå™¨] {summary}")
            
            return io.NodeOutput(output_folder, preview_image_path, processed_count, crop_info, summary)
            
        except Exception as e:
            error_msg = f"æ‰¹é‡è§†é¢‘è£å‰ªå™¨æ‰§è¡Œå¤±è´¥: {str(e)}"
            print(f"[æ‰¹é‡è§†é¢‘è£å‰ªå™¨] é”™è¯¯: {error_msg}")
            return io.NodeOutput("", "", 0, "", error_msg)
    
    @classmethod
    def _calculate_smart_crop(cls, orig_w, orig_h, target_w, target_h, mode):
        """è®¡ç®—æ™ºèƒ½è£å‰ªå‚æ•°"""
        # è®¡ç®—ç›®æ ‡å®½é«˜æ¯”
        target_ratio = target_w / target_h
        orig_ratio = orig_w / orig_h
        
        if orig_ratio > target_ratio:
            # åŸè§†é¢‘æ›´å®½ï¼Œéœ€è¦è£å‰ªå®½åº¦
            crop_h = orig_h
            crop_w = int(orig_h * target_ratio)
            
            if mode == "æ™ºèƒ½å±…ä¸­":
                crop_x = (orig_w - crop_w) // 2
                crop_y = 0
            elif mode == "å·¦ä¾§å¯¹é½":
                crop_x = 0
                crop_y = 0
            elif mode == "å³ä¾§å¯¹é½":
                crop_x = orig_w - crop_w
                crop_y = 0
            else:  # é¡¶éƒ¨å’Œåº•éƒ¨å¯¹é½å¯¹äºæ°´å¹³è£å‰ªä½¿ç”¨å±…ä¸­
                crop_x = (orig_w - crop_w) // 2
                crop_y = 0
        else:
            # åŸè§†é¢‘æ›´é«˜ï¼Œéœ€è¦è£å‰ªé«˜åº¦
            crop_w = orig_w
            crop_h = int(orig_w / target_ratio)
            
            if mode == "æ™ºèƒ½å±…ä¸­":
                crop_x = 0
                crop_y = (orig_h - crop_h) // 2
            elif mode == "é¡¶éƒ¨å¯¹é½":
                crop_x = 0
                crop_y = 0
            elif mode == "åº•éƒ¨å¯¹é½":
                crop_x = 0
                crop_y = orig_h - crop_h
            else:  # å·¦ä¾§å’Œå³ä¾§å¯¹é½å¯¹äºå‚ç›´è£å‰ªä½¿ç”¨å±…ä¸­
                crop_x = 0
                crop_y = (orig_h - crop_h) // 2
        
        # è½¬æ¢ä¸ºæ¯”ä¾‹
        crop_x_ratio = crop_x / orig_w
        crop_y_ratio = crop_y / orig_h
        crop_w_ratio = crop_w / orig_w
        crop_h_ratio = crop_h / orig_h
        
        return crop_x_ratio, crop_y_ratio, crop_w_ratio, crop_h_ratio
    
    @classmethod
    def _generate_preview(cls, video_file, output_folder, crop_x, crop_y, crop_w, crop_h, target_w, target_h):
        """ç”Ÿæˆé¢„è§ˆå›¾ç‰‡"""
        try:
            preview_path = os.path.join(output_folder, "preview_crop.jpg")
            
            # æå–ä¸­é—´å¸§å¹¶åº”ç”¨è£å‰ª
            (
                ffmpeg
                .input(video_file, ss=1)  # æå–ç¬¬1ç§’çš„å¸§
                .filter('crop', crop_w, crop_h, crop_x, crop_y)
                .filter('scale', target_w, target_h)
                .output(preview_path, vframes=1)
                .overwrite_output()
                .run(quiet=True)
            )
            
            if os.path.exists(preview_path):
                print(f"[æ‰¹é‡è§†é¢‘è£å‰ªå™¨] é¢„è§ˆå›¾å·²ç”Ÿæˆ: {preview_path}")
                return preview_path
            else:
                return ""
                
        except Exception as e:
            print(f"[æ‰¹é‡è§†é¢‘è£å‰ªå™¨] é¢„è§ˆå›¾ç”Ÿæˆå¤±è´¥: {str(e)}")
            return ""


class BatchVideoComposer(io.ComfyNode):
    """æ‰¹é‡è§†é¢‘ç©ºé—´åˆæˆå™¨ - æ”¯æŒå¤šç§å¸ƒå±€çš„è§†é¢‘åˆæˆ"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="BatchVideoComposer",
            display_name="ğŸ–¼ï¸ è§†é¢‘ç”»é¢æ‹¼æ¥å™¨",
            category="batch_video",
            description="å°†å¤šä¸ªæ–‡ä»¶å¤¹çš„è§†é¢‘åœ¨ç©ºé—´ä¸Šè¿›è¡Œåˆæˆï¼Œæ”¯æŒå¤šç§å¸ƒå±€æ–¹å¼",
            inputs=[
                # æ–‡ä»¶å¤¹è¾“å…¥
                io.String.Input("folder_1", tooltip="ç¬¬ä¸€ä¸ªè§†é¢‘æ–‡ä»¶å¤¹"),
                io.String.Input("folder_2", tooltip="ç¬¬äºŒä¸ªè§†é¢‘æ–‡ä»¶å¤¹"),
                io.String.Input("folder_3", optional=True, tooltip="ç¬¬ä¸‰ä¸ªè§†é¢‘æ–‡ä»¶å¤¹ï¼ˆå¯é€‰ï¼‰"),
                io.String.Input("folder_4", optional=True, tooltip="ç¬¬å››ä¸ªè§†é¢‘æ–‡ä»¶å¤¹ï¼ˆå¯é€‰ï¼‰"),
                
                # åˆæˆå¸ƒå±€
                io.Combo.Input("layout_mode", 
                               options=["å·¦å³åˆ†å±", "ä¸Šä¸‹åˆ†å±", "ç”»ä¸­ç”»", "å››å®«æ ¼", "ä¹å®«æ ¼"], 
                               default="å·¦å³åˆ†å±", 
                               tooltip="åˆæˆå¸ƒå±€æ¨¡å¼"),
                
                # è¾“å‡ºå°ºå¯¸
                io.Int.Input("output_width", default=1920, tooltip="è¾“å‡ºå®½åº¦"),
                io.Int.Input("output_height", default=1080, tooltip="è¾“å‡ºé«˜åº¦"),
                
                # è¾¹æ¡†å’Œé—´è·
                io.Int.Input("border_width", default=0, tooltip="è¾¹æ¡†å®½åº¦ï¼ˆåƒç´ ï¼‰"),
                io.String.Input("border_color", default="black", tooltip="è¾¹æ¡†é¢œè‰²"),
                io.Int.Input("gap_size", default=0, tooltip="è§†é¢‘é—´éš™ï¼ˆåƒç´ ï¼‰"),
                
                # éŸ³é¢‘å¤„ç†
                io.Combo.Input("audio_mode", 
                               options=["ä¸»è§†é¢‘éŸ³é¢‘", "æ··åˆéŸ³é¢‘", "é™éŸ³"], 
                               default="ä¸»è§†é¢‘éŸ³é¢‘", 
                               tooltip="éŸ³é¢‘å¤„ç†æ–¹å¼"),
                
                # è§†é¢‘é€‰æ‹©ç­–ç•¥
                io.Combo.Input("selection_mode", 
                               options=["æŒ‰é¡ºåº", "éšæœºç»„åˆ", "æ—¶é•¿åŒ¹é…"], 
                               default="æŒ‰é¡ºåº", 
                               tooltip="è§†é¢‘é€‰æ‹©ç­–ç•¥"),
                
                io.String.Input("output_prefix", default="åˆæˆ", tooltip="è¾“å‡ºæ–‡ä»¶åå‰ç¼€"),
            ],
            outputs=[
                io.String.Output("output_folder", display_name="è¾“å‡ºæ–‡ä»¶å¤¹"),
                io.Int.Output("composed_count", display_name="åˆæˆæ•°é‡"),
                io.String.Output("layout_info", display_name="å¸ƒå±€ä¿¡æ¯"),
                io.String.Output("summary", display_name="å¤„ç†æ‘˜è¦"),
            ],
        )
    
    @classmethod
    def execute(cls, folder_1, folder_2, folder_3=None, folder_4=None,
                layout_mode="å·¦å³åˆ†å±", output_width=1920, output_height=1080,
                border_width=0, border_color="black", gap_size=0,
                audio_mode="ä¸»è§†é¢‘éŸ³é¢‘", selection_mode="æŒ‰é¡ºåº", output_prefix="åˆæˆ"):
        import os
        import random
        import time
        from pathlib import Path
        from .utils import scan_media_files
        import ffmpeg
        
        try:
            # æ”¶é›†æ‰€æœ‰è¾“å…¥æ–‡ä»¶å¤¹
            input_folders = [folder_1, folder_2]
            if folder_3 and os.path.exists(folder_3):
                input_folders.append(folder_3)
            if folder_4 and os.path.exists(folder_4):
                input_folders.append(folder_4)
            
            # éªŒè¯æ–‡ä»¶å¤¹å¹¶æ‰«æè§†é¢‘æ–‡ä»¶
            folder_videos = []
            for i, folder in enumerate(input_folders):
                if not os.path.exists(folder):
                    raise ValueError(f"æ–‡ä»¶å¤¹ {i+1} ä¸å­˜åœ¨: {folder}")
                
                videos = scan_media_files(folder, file_types=['video']).get('video', [])
                if not videos:
                    raise ValueError(f"æ–‡ä»¶å¤¹ {i+1} ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {folder}")
                
                folder_videos.append(videos)
                print(f"[æ‰¹é‡è§†é¢‘åˆæˆå™¨] æ–‡ä»¶å¤¹ {i+1}: {len(videos)} ä¸ªè§†é¢‘")
            
            # æ£€æŸ¥å¸ƒå±€å’Œæ–‡ä»¶å¤¹æ•°é‡åŒ¹é…
            required_folders = cls._get_required_folders(layout_mode)
            if len(folder_videos) < required_folders:
                raise ValueError(f"å¸ƒå±€ '{layout_mode}' éœ€è¦è‡³å°‘ {required_folders} ä¸ªæ–‡ä»¶å¤¹ï¼Œä½†åªæä¾›äº† {len(folder_videos)} ä¸ª")
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
            timestamp = int(time.time())
            output_folder = os.path.join(folder_paths.get_temp_directory(), f"{output_prefix}_è§†é¢‘åˆæˆ_{timestamp}")
            os.makedirs(output_folder, exist_ok=True)
            
            # è®¡ç®—å¸ƒå±€ä¿¡æ¯
            layout_info = cls._calculate_layout(layout_mode, output_width, output_height, gap_size)
            layout_desc = f"å¸ƒå±€: {layout_mode}, è¾“å‡ºå°ºå¯¸: {output_width}x{output_height}"
            if gap_size > 0:
                layout_desc += f", é—´éš™: {gap_size}px"
            if border_width > 0:
                layout_desc += f", è¾¹æ¡†: {border_width}px {border_color}"
            
            print(f"[æ‰¹é‡è§†é¢‘åˆæˆå™¨] {layout_desc}")
            
            # ç”Ÿæˆè§†é¢‘ç»„åˆ
            video_groups = cls._generate_video_groups(folder_videos, selection_mode, required_folders)
            
            composed_count = 0
            failed_count = 0
            
            print(f"[æ‰¹é‡è§†é¢‘åˆæˆå™¨] å¼€å§‹åˆæˆ {len(video_groups)} ä¸ªè§†é¢‘ç»„åˆ")
            
            for i, video_group in enumerate(video_groups):
                try:
                    output_filename = f"{output_prefix}_{i+1:03d}.mp4"
                    output_path = os.path.join(output_folder, output_filename)
                    
                    group_names = [Path(v).name for v in video_group]
                    print(f"[æ‰¹é‡è§†é¢‘åˆæˆå™¨] åˆæˆç»„åˆ {i+1}: {', '.join(group_names)}")
                    
                    # æ‰§è¡Œè§†é¢‘åˆæˆ
                    success = cls._compose_videos(
                        video_group, output_path, layout_info, 
                        output_width, output_height, audio_mode,
                        border_width, border_color, gap_size
                    )
                    
                    if success:
                        composed_count += 1
                        print(f"[æ‰¹é‡è§†é¢‘åˆæˆå™¨] å®Œæˆ: {output_filename}")
                    else:
                        failed_count += 1
                        print(f"[æ‰¹é‡è§†é¢‘åˆæˆå™¨] å¤±è´¥: {output_filename}")
                        
                except Exception as e:
                    failed_count += 1
                    print(f"[æ‰¹é‡è§†é¢‘åˆæˆå™¨] åˆæˆå¤±è´¥: ç»„åˆ {i+1}, é”™è¯¯: {str(e)}")
            
            # ç”Ÿæˆæ‘˜è¦
            summary = f"è§†é¢‘åˆæˆå®Œæˆ: æˆåŠŸ {composed_count}/{len(video_groups)} ä¸ªç»„åˆ"
            if failed_count > 0:
                summary += f", å¤±è´¥: {failed_count} ä¸ªç»„åˆ"
            
            print(f"[æ‰¹é‡è§†é¢‘åˆæˆå™¨] {summary}")
            
            return io.NodeOutput(output_folder, composed_count, layout_desc, summary)
            
        except Exception as e:
            error_msg = f"æ‰¹é‡è§†é¢‘åˆæˆå™¨æ‰§è¡Œå¤±è´¥: {str(e)}"
            print(f"[æ‰¹é‡è§†é¢‘åˆæˆå™¨] é”™è¯¯: {error_msg}")
            return io.NodeOutput("", 0, "", error_msg)
    
    @classmethod
    def _get_required_folders(cls, layout_mode):
        """è·å–å¸ƒå±€æ¨¡å¼éœ€è¦çš„æœ€å°‘æ–‡ä»¶å¤¹æ•°é‡"""
        layout_requirements = {
            "å·¦å³åˆ†å±": 2,
            "ä¸Šä¸‹åˆ†å±": 2,
            "ç”»ä¸­ç”»": 2,
            "å››å®«æ ¼": 4,
            "ä¹å®«æ ¼": 4,  # æœ€å°‘4ä¸ªï¼Œå¯ä»¥é‡å¤ä½¿ç”¨
        }
        return layout_requirements.get(layout_mode, 2)
    
    @classmethod
    def _calculate_layout(cls, layout_mode, output_w, output_h, gap_size):
        """è®¡ç®—å¸ƒå±€ä¿¡æ¯"""
        layouts = {
            "å·¦å³åˆ†å±": [
                {"x": 0, "y": 0, "w": (output_w - gap_size) // 2, "h": output_h},
                {"x": (output_w + gap_size) // 2, "y": 0, "w": (output_w - gap_size) // 2, "h": output_h}
            ],
            "ä¸Šä¸‹åˆ†å±": [
                {"x": 0, "y": 0, "w": output_w, "h": (output_h - gap_size) // 2},
                {"x": 0, "y": (output_h + gap_size) // 2, "w": output_w, "h": (output_h - gap_size) // 2}
            ],
            "ç”»ä¸­ç”»": [
                {"x": 0, "y": 0, "w": output_w, "h": output_h},  # ä¸»ç”»é¢
                {"x": output_w - 320 - 20, "y": 20, "w": 320, "h": 180}  # å°ç”»é¢
            ],
            "å››å®«æ ¼": [
                {"x": 0, "y": 0, "w": (output_w - gap_size) // 2, "h": (output_h - gap_size) // 2},
                {"x": (output_w + gap_size) // 2, "y": 0, "w": (output_w - gap_size) // 2, "h": (output_h - gap_size) // 2},
                {"x": 0, "y": (output_h + gap_size) // 2, "w": (output_w - gap_size) // 2, "h": (output_h - gap_size) // 2},
                {"x": (output_w + gap_size) // 2, "y": (output_h + gap_size) // 2, "w": (output_w - gap_size) // 2, "h": (output_h - gap_size) // 2}
            ],
            "ä¹å®«æ ¼": [
                {"x": 0, "y": 0, "w": output_w // 3, "h": output_h // 3},
                {"x": output_w // 3, "y": 0, "w": output_w // 3, "h": output_h // 3},
                {"x": 2 * output_w // 3, "y": 0, "w": output_w // 3, "h": output_h // 3},
                {"x": 0, "y": output_h // 3, "w": output_w // 3, "h": output_h // 3},
                {"x": output_w // 3, "y": output_h // 3, "w": output_w // 3, "h": output_h // 3},
                {"x": 2 * output_w // 3, "y": output_h // 3, "w": output_w // 3, "h": output_h // 3},
                {"x": 0, "y": 2 * output_h // 3, "w": output_w // 3, "h": output_h // 3},
                {"x": output_w // 3, "y": 2 * output_h // 3, "w": output_w // 3, "h": output_h // 3},
                {"x": 2 * output_w // 3, "y": 2 * output_h // 3, "w": output_w // 3, "h": output_h // 3}
            ]
        }
        return layouts.get(layout_mode, layouts["å·¦å³åˆ†å±"])
    
    @classmethod
    def _generate_video_groups(cls, folder_videos, selection_mode, required_folders):
        """ç”Ÿæˆè§†é¢‘ç»„åˆ"""
        if selection_mode == "æŒ‰é¡ºåº":
            # æŒ‰é¡ºåºç»„åˆï¼Œä»¥æœ€å°‘çš„æ–‡ä»¶å¤¹ä¸ºå‡†
            min_count = min(len(videos) for videos in folder_videos)
            groups = []
            for i in range(min_count):
                group = []
                for folder_vids in folder_videos[:required_folders]:
                    group.append(folder_vids[i])
                groups.append(group)
            return groups
            
        elif selection_mode == "éšæœºç»„åˆ":
            # éšæœºç»„åˆ
            max_combinations = 50  # é™åˆ¶æœ€å¤§ç»„åˆæ•°
            groups = []
            for _ in range(max_combinations):
                group = []
                for folder_vids in folder_videos[:required_folders]:
                    group.append(random.choice(folder_vids))
                if group not in groups:  # é¿å…é‡å¤
                    groups.append(group)
                if len(groups) >= max_combinations:
                    break
            return groups
            
        elif selection_mode == "æ—¶é•¿åŒ¹é…":
            # æŒ‰æ—¶é•¿åŒ¹é…ï¼ˆç®€åŒ–å®ç°ï¼ŒæŒ‰é¡ºåºä½†å°½é‡åŒ¹é…æ—¶é•¿ï¼‰
            return cls._generate_video_groups(folder_videos, "æŒ‰é¡ºåº", required_folders)
        
        return []
    
    @classmethod
    def _compose_videos(cls, video_group, output_path, layout_info, output_w, output_h, 
                       audio_mode, border_width, border_color, gap_size):
        """åˆæˆè§†é¢‘"""
        try:
            # åˆ›å»ºè¾“å…¥æµ
            inputs = []
            scaled_streams = []
            
            for i, video_file in enumerate(video_group):
                if i >= len(layout_info):
                    break
                    
                layout = layout_info[i]
                input_stream = ffmpeg.input(video_file)
                inputs.append(input_stream)
                
                # ç¼©æ”¾è§†é¢‘åˆ°æŒ‡å®šå°ºå¯¸
                scaled = input_stream.video.filter('scale', layout['w'], layout['h'])
                scaled_streams.append(scaled)
            
            # åˆ›å»ºèƒŒæ™¯
            if gap_size > 0 or border_width > 0:
                # åˆ›å»ºé»‘è‰²èƒŒæ™¯
                background = ffmpeg.input('color=black:size={}x{}:duration=1'.format(output_w, output_h), f='lavfi')
                base_stream = background
            else:
                base_stream = scaled_streams[0]
                scaled_streams = scaled_streams[1:]
            
            # é€ä¸ªå åŠ è§†é¢‘
            result_stream = base_stream
            for i, scaled in enumerate(scaled_streams):
                layout = layout_info[i + (1 if gap_size > 0 or border_width > 0 else 0)]
                result_stream = result_stream.overlay(scaled, x=layout['x'], y=layout['y'])
            
            # å¤„ç†éŸ³é¢‘
            if audio_mode == "ä¸»è§†é¢‘éŸ³é¢‘":
                audio_stream = inputs[0].audio
            elif audio_mode == "æ··åˆéŸ³é¢‘":
                audio_streams = [inp.audio for inp in inputs[:2]]  # æœ€å¤šæ··åˆå‰ä¸¤ä¸ª
                if len(audio_streams) > 1:
                    audio_stream = ffmpeg.filter(audio_streams, 'amix', inputs=len(audio_streams))
                else:
                    audio_stream = audio_streams[0]
            else:  # é™éŸ³
                audio_stream = None
            
            # è¾“å‡º
            output_args = {
                'vcodec': 'libx264',
                'preset': 'fast',
                **{'profile:v': 'main'}
            }
            
            if audio_stream:
                output_args['acodec'] = 'aac'
                (
                    ffmpeg
                    .output(result_stream, audio_stream, output_path, **output_args)
                    .overwrite_output()
                    .run(quiet=True)
                )
            else:
                (
                    ffmpeg
                    .output(result_stream, output_path, **output_args)
                    .overwrite_output()
                    .run(quiet=True)
                )
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            return os.path.exists(output_path) and os.path.getsize(output_path) > 0
            
        except Exception as e:
            print(f"[æ‰¹é‡è§†é¢‘åˆæˆå™¨] åˆæˆå¤±è´¥: {str(e)}")
            return False


class BatchVideoDownloader(io.ComfyNode):
    """æ‰¹é‡è§†é¢‘ä¸‹è½½å™¨ - ç®€åŒ–ç‰ˆ"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="BatchVideoDownloader",
            display_name="æ‰¹é‡ä¸‹è½½",
            category="batch_video",
            description="æ‰“åŒ…ä¸‹è½½å¤„ç†åçš„è§†é¢‘",
            inputs=[
                io.String.Input(
                    "source_folder", 
                    tooltip="æºæ–‡ä»¶å¤¹è·¯å¾„"
                ),
                io.String.Input(
                    "archive_name", 
                    default="å¤„ç†ç»“æœ", 
                    tooltip="å‹ç¼©åŒ…åç§°"
                ),
            ],
            outputs=[
                io.String.Output("download_path", display_name="ä¸‹è½½è·¯å¾„"),
                io.String.Output("archive_info", display_name="å‹ç¼©åŒ…ä¿¡æ¯"),
            ],
            is_output_node=True,
        )

    @classmethod
    def execute(cls, source_folder: str, archive_name: str) -> io.NodeOutput:
        print(f"ğŸ“¦ BatchVideoDownloaderæ‰§è¡Œå¼€å§‹ï¼Œæºæ–‡ä»¶å¤¹: '{source_folder}', å‹ç¼©åŒ…å: '{archive_name}'")
        
        if not source_folder or not source_folder.strip():
            error_msg = "é”™è¯¯ï¼šæºæ–‡ä»¶å¤¹è·¯å¾„ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ä¸Šæ¸¸èŠ‚ç‚¹è¾“å‡º"
            print(f"âŒ {error_msg}")
            return io.NodeOutput("", error_msg)
        
        if not os.path.exists(source_folder):
            error_msg = f"é”™è¯¯ï¼šæ–‡ä»¶å¤¹ä¸å­˜åœ¨ {source_folder}"
            print(f"âŒ {error_msg}")
            return io.NodeOutput("", error_msg)
        
        # æ‰«ææºæ–‡ä»¶å¤¹å†…å®¹
        all_files = []
        for root, dirs, files in os.walk(source_folder):
            for file in files:
                all_files.append(os.path.join(root, file))
        
        print(f"ğŸ“ æ‰«ææºæ–‡ä»¶å¤¹: {len(all_files)} ä¸ªæ–‡ä»¶")
        if len(all_files) <= 10:
            for file_path in all_files:
                filename = os.path.relpath(file_path, source_folder)
                file_size = os.path.getsize(file_path)
                size_str = format_file_size(file_size)
                print(f"  â€¢ {filename} ({size_str})")
        else:
            for i, file_path in enumerate(all_files[:5]):
                filename = os.path.relpath(file_path, source_folder)
                file_size = os.path.getsize(file_path)
                size_str = format_file_size(file_size)
                print(f"  â€¢ {filename} ({size_str})")
            print(f"  ... è¿˜æœ‰ {len(all_files) - 5} ä¸ªæ–‡ä»¶")
        
        # åˆ›å»ºå‹ç¼©åŒ… - å†…è”å®ç°é¿å…ç¼“å­˜é—®é¢˜
        print(f"ğŸ—œï¸ å¼€å§‹åˆ›å»ºå‹ç¼©åŒ…: {archive_name}")
        
        import zipfile
        from datetime import datetime
        
        # ç›´æ¥ä½¿ç”¨outputç›®å½•ï¼Œé¿å…å­ç›®å½•é—®é¢˜
        output_dir = folder_paths.get_output_directory()
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # ä½¿ç”¨è‹±æ–‡æ–‡ä»¶åï¼Œé¿å…ç¼–ç é—®é¢˜
        safe_archive_name = "batch_result" if any(ord(c) > 127 for c in archive_name) else archive_name
        archive_path = os.path.join(output_dir, f"{safe_archive_name}_{timestamp}.zip")
        print(f"ğŸ› è°ƒè¯•: æ–°çš„archive_path = {archive_path}")
        
        file_count = 0
        total_size = 0
        
        with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(source_folder):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, source_folder)
                    zipf.write(file_path, arcname)
                    file_count += 1
                    total_size += os.path.getsize(file_path)
        
        if not os.path.exists(archive_path):
            error_msg = "åˆ›å»ºå‹ç¼©åŒ…å¤±è´¥"
            print(f"âŒ {error_msg}")
            return io.NodeOutput("", error_msg)
        
        archive_size = os.path.getsize(archive_path)
        compression_ratio = (1 - archive_size / total_size) * 100 if total_size > 0 else 0
        
        print(f"âœ… å‹ç¼©åŒ…åˆ›å»ºæˆåŠŸ:")
        print(f"  ğŸ“ è·¯å¾„: {archive_path}")
        print(f"  ğŸ“ æ–‡ä»¶æ•°: {file_count} ä¸ª")
        print(f"  ğŸ“ åŸå§‹å¤§å°: {format_file_size(total_size)}")
        print(f"  ğŸ—œï¸ å‹ç¼©åå¤§å°: {format_file_size(archive_size)}")
        print(f"  ğŸ’¾ å‹ç¼©ç‡: {compression_ratio:.1f}%")
        
        # ç”ŸæˆComfyUIä¸‹è½½ä¿¡æ¯
        archive_filename = os.path.basename(archive_path)
        
        # ç”Ÿæˆå®Œæ•´çš„ä¸‹è½½URL
        download_url = f"http://103.231.86.148:9000/view?filename={archive_filename}&type=output"
        
        archive_info = f"""âœ… ä¸‹è½½åŒ…å·²åˆ›å»ºï¼

ğŸ“ æ–‡ä»¶å: {archive_filename}
ğŸ“ åŒ…å«æ–‡ä»¶: {file_count} ä¸ª  
ğŸ“ åŸå§‹å¤§å°: {format_file_size(total_size)}
ğŸ—œï¸ å‹ç¼©åå¤§å°: {format_file_size(archive_size)}
ğŸ’¾ å‹ç¼©ç‡: {compression_ratio:.1f}%

ğŸ”— ç›´æ¥ä¸‹è½½é“¾æ¥: 
{download_url}

ğŸ“‹ ä½¿ç”¨æ–¹æ³•:
1. å¤åˆ¶ä¸Šé¢çš„å®Œæ•´é“¾æ¥
2. åœ¨æµè§ˆå™¨æ–°æ ‡ç­¾é¡µä¸­ç²˜è´´å¹¶è®¿é—®
3. æ–‡ä»¶å°†è‡ªåŠ¨å¼€å§‹ä¸‹è½½ (1.2GB)

ğŸ’¡ æˆ–è€…ç›´æ¥ç‚¹å‡»ä¸‹æ–¹çš„ä¸‹è½½é“¾æ¥(å¦‚æœæ”¯æŒ)"""
        
        # è¿”å›ComfyUIæ ‡å‡†æ ¼å¼ï¼Œå°è¯•å¤šç§UIè¾“å‡ºæ ¼å¼
        ui_output = {
            "images": [{
                "filename": archive_filename,
                "subfolder": "",
                "type": "output"
            }],
            # æ·»åŠ æ–‡æœ¬æ ¼å¼ï¼ŒåŒ…å«å¯ç‚¹å‡»çš„HTMLé“¾æ¥
            "text": [f'<a href="{download_url}" download="{archive_filename}" style="color: #4CAF50; text-decoration: underline; font-weight: bold;">ğŸ”— ç‚¹å‡»ä¸‹è½½ {archive_filename}</a>']
        }
        
        return io.NodeOutput(download_url, archive_info, ui=ui_output)


class BatchFileManager(io.ComfyNode):
    """æ–‡ä»¶ç®¡ç†å™¨ - ç®€åŒ–ç‰ˆ"""
    
    @classmethod
    def define_schema(cls):
        return io.Schema(
            node_id="BatchFileManager",
            display_name="æ–‡ä»¶ç®¡ç†å™¨",
            category="batch_video",
            description="ç®¡ç†æ‰¹é‡å¤„ç†æ–‡ä»¶",
            inputs=[
                io.Combo.Input(
                    "action", 
                    options=["æŸ¥çœ‹åˆ—è¡¨", "æ¸…ç†æ–‡ä»¶"], 
                    default="æŸ¥çœ‹åˆ—è¡¨",
                    tooltip="ç®¡ç†æ“ä½œ"
                ),
                io.Int.Input(
                    "days_to_keep", 
                    default=7, 
                    min=1, 
                    max=30,
                    tooltip="ä¿ç•™å¤©æ•°"
                ),
            ],
            outputs=[
                io.String.Output("result", display_name="æ“ä½œç»“æœ"),
            ],
        )

    @classmethod
    def execute(cls, action: str, days_to_keep: int) -> io.NodeOutput:
        
        input_dir = folder_paths.get_input_directory()
        output_dir = folder_paths.get_output_directory()
        
        if action == "æŸ¥çœ‹åˆ—è¡¨":
            # åˆ—å‡ºæ‰¹å¤„ç†æ–‡ä»¶å¤¹
            result_lines = ["æ‰¹å¤„ç†æ–‡ä»¶å¤¹åˆ—è¡¨:\n"]
            
            # æ£€æŸ¥è¾“å…¥ç›®å½•
            batch_upload_dir = os.path.join(input_dir, "batch_uploads")
            if os.path.exists(batch_upload_dir):
                for item in os.listdir(batch_upload_dir):
                    item_path = os.path.join(batch_upload_dir, item)
                    if os.path.isdir(item_path):
                        file_count = len([f for f in os.listdir(item_path) 
                                        if os.path.isfile(os.path.join(item_path, f))])
                        result_lines.append(f"ğŸ“ ä¸Šä¼ : {item} ({file_count} æ–‡ä»¶)")
            
            # æ£€æŸ¥è¾“å‡ºç›®å½•
            batch_output_dir = os.path.join(output_dir, "processed_batches")
            if os.path.exists(batch_output_dir):
                for item in os.listdir(batch_output_dir):
                    item_path = os.path.join(batch_output_dir, item)
                    if os.path.isdir(item_path):
                        # è®¡ç®—å­æ–‡ä»¶å¤¹æ–‡ä»¶æ•°
                        total_files = 0
                        for root, dirs, files in os.walk(item_path):
                            total_files += len(files)
                        result_lines.append(f"ğŸ“ è¾“å‡º: {item} ({total_files} æ–‡ä»¶)")
            
            result = "\n".join(result_lines) if len(result_lines) > 1 else "æš‚æ— æ‰¹å¤„ç†æ–‡ä»¶"
            
        elif action == "æ¸…ç†æ–‡ä»¶":
            # æ¸…ç†æ—§æ–‡ä»¶
            cleaned_input = clean_old_batches(input_dir, days_to_keep)
            cleaned_output = clean_old_batches(output_dir, days_to_keep)
            total_cleaned = len(cleaned_input) + len(cleaned_output)
            
            result = f"æ¸…ç†å®Œæˆï¼åˆ é™¤äº† {total_cleaned} ä¸ªè¿‡æœŸæ–‡ä»¶å¤¹"
            if total_cleaned > 0:
                result += f"\nä¿ç•™äº† {days_to_keep} å¤©å†…çš„æ–‡ä»¶"
        
        else:
            result = f"æœªçŸ¥æ“ä½œ: {action}"
        
        return io.NodeOutput(result)


class BatchVideoExtension(ComfyExtension):
    """æ‰¹é‡è§†é¢‘å¤„ç†æ‰©å±• - æ”¹è¿›ç‰ˆ"""
    
    @override
    async def get_node_list(self) -> list[type[io.ComfyNode]]:
        return [
            BatchVideoLoader,
            RandomVideoConcatenator,
            TraverseVideoConcatenator,
            BatchVideoCutter,
            SmartAudioBasedCutter,      # æ–°å¢ï¼šæ™ºèƒ½éŸ³é¢‘æ—¶é•¿åˆ‡åˆ†å™¨
            VideoNormalizer,            # æ–°å¢ï¼šè§†é¢‘æ ‡å‡†åŒ–å™¨
            SmartAudioMixer,            # æ–°å¢ï¼šæ™ºèƒ½éŸ³é¢‘åˆæˆå™¨
            BatchSubtitleGenerator,     # æ–°å¢ï¼šæ‰¹é‡å­—å¹•ç”Ÿæˆå™¨
            BatchVideoCropper,          # æ–°å¢ï¼šæ‰¹é‡è§†é¢‘è£å‰ªå™¨
            BatchVideoComposer,         # æ–°å¢ï¼šæ‰¹é‡è§†é¢‘ç©ºé—´åˆæˆå™¨
            BatchLLMGenerator,          # æ–°å¢ï¼šæ‰¹é‡æ–‡æ¡ˆç”Ÿæˆå™¨
            BatchTTSGenerator,          # æ–°å¢ï¼šæ‰¹é‡TTSç”Ÿæˆå™¨
            SmartVideoCutterWithAudio,  # æ–°å¢ï¼šæ™ºèƒ½è§†é¢‘è£åˆ‡+éŸ³é¢‘èåˆå™¨
            VideoStaticCleaner,         # æ–°å¢ï¼šè§†é¢‘é™æ­¢ç‰‡æ®µæ¸…ç†å™¨
            GameHighlightExtractor,     # æ–°å¢ï¼šæ¸¸æˆç²¾å½©ç‰‡æ®µæå–å™¨
            VideoThumbnailGenerator,    # æ–°å¢ï¼šè§†é¢‘ç¼©ç•¥å›¾ç”Ÿæˆå™¨
            BatchVideoDownloader,
            BatchFileManager,
        ]